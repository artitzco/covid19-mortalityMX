{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e5c9af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not 'id_0123456789876543210' in locals():\n",
    "    os.chdir(os.path.split(os.getcwd())[0])\n",
    "    id_0123456789876543210 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73ec0d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.python.optimize.solution import intBinary, floatBinary, ndSolution, Category\n",
    "from src.python.optimize.search import SearchSpace, MarkovGeneticSearch, LocalSearch\n",
    "from src.python.training.validation import Foldify, eval_model\n",
    "from src.python.model import model_v1, model_v1_hparams\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def save_object(obj, file):\n",
    "    with open(file, \"wb\") as file:\n",
    "        pickle.dump(obj, file)\n",
    "\n",
    "def load_object(file):\n",
    "    with open(file, \"rb\") as file:\n",
    "        loaded_object = pickle.load(file)\n",
    "    return loaded_object\n",
    "\n",
    "width = 6\n",
    "high = width / 1.61803"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bae7f7",
   "metadata": {},
   "source": [
    "version `datos.modelo.search.seed`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387b3352",
   "metadata": {},
   "source": [
    "# Graves Hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4d3069",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_object(\n",
    "    'data/covid/classification/dataset/train.graves-1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63a43fc",
   "metadata": {},
   "source": [
    "## A) version 1.1\n",
    "\n",
    "### SearchSpace 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f854271",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchSpace_1(SearchSpace):\n",
    "    def __init__(self, input_dim, seed=None) -> None:\n",
    "        solution = ndSolution(\n",
    "            input_dim=intBinary(input_dim, input_dim),\n",
    "            architecture=ndSolution(Category({True, False}), dimension=3),\n",
    "            neurons=ndSolution(intBinary(1, 2**8, digits=0), dimension=3),\n",
    "            optimizer=Category({'Adam', 'Nadam', 'RMSprop', 'SGD'}),\n",
    "            learning_rate=floatBinary(0, 0.01, digits=5),  # x > 0\n",
    "            momentum=floatBinary(0, 1, digits=3),\n",
    "            activation=Category({'ELU', 'LeakyReLU'}),\n",
    "            activation_alpha=floatBinary(0, 0.5, digits=4),\n",
    "            initializer=Category({'uniform', 'normal'}),\n",
    "            batch_size=intBinary(2**3, 2**8, digits=0),\n",
    "            epochs=intBinary(2**5, 2**7, digits=0),\n",
    "            batch_normalization=Category({True, False}),\n",
    "            regularization=Category({'l1', 'l2', 'None'}),\n",
    "            regularization_factor=floatBinary(0, 0.1, digits=4),\n",
    "            dropout_rate=floatBinary(0, 0.5, digits=4))\n",
    "        super().__init__(solution, seed)\n",
    "\n",
    "    def is_feasible(self, x):\n",
    "        arch = self.solution[1].decode(x[1])\n",
    "        return (\n",
    "            # architecture\n",
    "            arch[0] > 0 and\n",
    "            all(x >= y for x, y in zip(arch, arch[1:])) and\n",
    "            # learning_rate\n",
    "            self.solution[4].decode(x[4]) > 0)\n",
    "\n",
    "search_space = SearchSpace_1(input_dim=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10eb974",
   "metadata": {},
   "source": [
    "### version 1.1.1.555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497383d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = '1.1.1'\n",
    "seed = 555\n",
    "foldify = Foldify.Random(14541,\n",
    "                         nfolds=6,\n",
    "                         val_prop=0.2,\n",
    "                         sorted=True,\n",
    "                         weight=data['sample'],\n",
    "                         group=data['label'],\n",
    "                         seed=seed,\n",
    "                         datasets=(data['x'], data['y']))\n",
    "\n",
    "eval_session = load_object(\n",
    "    f'data/covid/classification/session/eval.graves-{VERSION}.{seed}.pkl')\n",
    "\n",
    "\n",
    "def objetive(**hparam):\n",
    "    return eval_model(model_v1,\n",
    "                      hparam=model_v1_hparams(**hparam),\n",
    "                      foldify=foldify,\n",
    "                      infile=eval_session,\n",
    "                      verbose=1)['summary']['val_mae']\n",
    "\n",
    "\n",
    "search = MarkovGeneticSearch(objetive,\n",
    "                             search_space,\n",
    "                             entropy_limit=0.05,\n",
    "                             initial=(10, 1000),\n",
    "                             timemax=0,\n",
    "                             seed=seed,\n",
    "                             argstype='kwargs',\n",
    "                             infile=f'data/covid/classification/session/search.graves-{VERSION}.{seed}.pkl',\n",
    "                             verbose=0)\n",
    "print(search.__repr__())\n",
    "history = search.session.history\n",
    "iter_history = search.session.iter_history.set_index('neval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b367dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2 * width, 1 * high))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.fx, label='$f_{x}$')\n",
    "plt.plot(iter_history.fmean, label ='$f_{mean}$')\n",
    "plt.plot(iter_history.fmin, label ='$f_{min}$')\n",
    "plt.ylim((0.075,0.085))\n",
    "plt.legend()\n",
    "plt.ylabel('$f\\,(x)$')\n",
    "plt.xlabel('$n_{eval}$')\n",
    "plt.title('Aptitud')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(iter_history.initial_entropy, label='Entropía Inicial')\n",
    "plt.plot(iter_history.final_entropy, label='Entropía Final')\n",
    "plt.legend()\n",
    "plt.ylabel('$entropy$')\n",
    "plt.xlabel('$n_{eval}$')\n",
    "plt.title('Entropía')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4595405,
     "sourceId": 7839641,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4602200,
     "sourceId": 8069890,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30664,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4507.596889,
   "end_time": "2024-05-13T23:16:01.316755",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-13T22:00:53.719866",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
