{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "if not 'id_0123456789876543210' in locals():\n",
    "    _rootlevel = 1\n",
    "    _oldwd = re.sub(r'\\\\', '/', os.getcwd())\n",
    "    _spdirs = _oldwd.split('/')\n",
    "    _newwd = '/'.join(_spdirs[:(len(_spdirs)-_rootlevel)])\n",
    "    os.chdir(_newwd)\n",
    "    id_0123456789876543210 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_object(file_path):\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        loaded_object = pickle.load(file)\n",
    "    return loaded_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Itzco\\Documents\\Projects\\covid19\\env\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.python.training.validation import Foldify, eval_model\n",
    "from src.python.model import classification_model, validate_classification_model_hparams\n",
    "from src.python.minimize.binary import floatBinary, intBinary, catBinary\n",
    "from src.python.minimize.algorithms import SearchSpace, Function, random_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 214   deep: 2   optimizer: RMSprop   learning_rate: 0.040486938289690536   activation: elu   initializer: uniform   batch_size: 20   epochs: 26   batch_normalization: True   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/1 ...\n",
      "\t time: 0h 0m 3s   loss: 0.036291   mae: 0.161758   val_loss: 0.105579   val_mae: 0.294186\n",
      "Total:\n",
      "\t time: 0h 0m 3s   loss: 0.036291   mae: 0.161758   val_loss: 0.105579   val_mae: 0.294186\n",
      "\n",
      "Progress =  {\n",
      "    \"iter\": 1,\n",
      "    \"eval\": 1,\n",
      "    \"time\": 3.4428961277008057,\n",
      "    \"fmin\": 0.29418641328811646,\n",
      "    \"xmin\": {\n",
      "        \"input_dim\": 10,\n",
      "        \"neurons\": 214,\n",
      "        \"deep\": 2,\n",
      "        \"optimizer\": \"RMSprop\",\n",
      "        \"learning_rate\": 0.040486938289690536,\n",
      "        \"activation\": \"elu\",\n",
      "        \"initializer\": \"uniform\",\n",
      "        \"batch_size\": 20,\n",
      "        \"epochs\": 26,\n",
      "        \"batch_normalization\": true,\n",
      "        \"regularization\": \"None\",\n",
      "        \"dropout\": false\n",
      "    }\n",
      "} \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "iter                                                       1\n",
       "eval                                                       1\n",
       "time                                                3.442896\n",
       "fmin                                                0.294186\n",
       "xmin       [, 11010101, 001, 0010, 01100111101000, 010, 0...\n",
       "history       iter  eval      time      fmin         f  \\...\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class HparamSearchSpace(SearchSpace):\n",
    "    def __init__(self, binary, seed=None):\n",
    "        super().__init__(binary, seed)\n",
    "        binary_dict = {x.name: x for x in self.binary}\n",
    "        neurons = binary_dict['neurons']\n",
    "        deep = binary_dict['deep']\n",
    "        nofactible = [d > int(1 + np.log(n / 2.0) / np.log(2))\n",
    "                      for n in range(neurons.a, neurons.b + 1)\n",
    "                      for d in range(deep.a, deep.b + 1)]\n",
    "        self.binary.dimension -= (neurons.dimension + deep.dimension) * \\\n",
    "            (sum(nofactible) / len(nofactible))\n",
    "\n",
    "    def is_feasible(self, ndbits):\n",
    "        hparam = ndbits.value_dict\n",
    "        maxdeep = int(1 + np.log(hparam['neurons'] / 2.0) / np.log(2))\n",
    "        return hparam['deep'] <= maxdeep\n",
    "\n",
    "\n",
    "search_space = HparamSearchSpace(\n",
    "    [\n",
    "        intBinary(10, 10, name='input_dim'),\n",
    "        intBinary(1, 2**8, digits=0, name='neurons'),\n",
    "        intBinary(1, 8, digits=0, name='deep'),\n",
    "        catBinary({'Adam', 'RMSprop', 'Nadam', 'SGD'}, name='optimizer'),\n",
    "        floatBinary(0.00001, 0.1, digits=5, name='learning_rate'),\n",
    "        catBinary({'relu', 'elu', 'LeakyReLU'}, name='activation'),\n",
    "        catBinary({'uniform', 'normal'}, name='initializer'),\n",
    "        intBinary(1, 2**7, digits=0, name='batch_size'),\n",
    "        intBinary(25, 30, digits=0, name='epochs'),\n",
    "        catBinary({True, False}, name='batch_normalization'),\n",
    "        catBinary({'None'}, name='regularization'),\n",
    "        catBinary({False}, name='dropout')\n",
    "    ])\n",
    "\n",
    "\n",
    "data = load_object('data/covid/classification/datasets/graves_train-1.1.pkl')\n",
    "\n",
    "foldify = Foldify(10,  # len(data['x']),\n",
    "                  nfolds=1,  # 6,\n",
    "                  val_prop=0.2,\n",
    "                  ftype='random',\n",
    "                  sorted=True,\n",
    "                  seed=555,\n",
    "                  weight=data['sample'],\n",
    "                  label=data['label'],\n",
    "                  datasets=(data['x'], data['y']))\n",
    "\n",
    "\n",
    "def fun(**hparam):\n",
    "    validate_classification_model_hparams(hparam)\n",
    "    eval = eval_model(model=classification_model,\n",
    "                      hparam=hparam,\n",
    "                      foldify=foldify,\n",
    "                      infile='data/covid/classification/hpsearch/hpsearch_memory_graves-1.1.pkl',\n",
    "                      outfile=None,\n",
    "                      origin='dell inspiron')\n",
    "    return eval['history'][-1]['val_mae'].iloc[-1]\n",
    "\n",
    "\n",
    "random_search(Function(fun, argstype='kwargs'),\n",
    "              search_space,\n",
    "              seed=123,\n",
    "              itermax=1,\n",
    "              initialize=False,######\n",
    "              infile='data/covid/classification/hpsearch/random_search_graves-1.1.0.pkl',\n",
    "              outfile=None,\n",
    "              verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
