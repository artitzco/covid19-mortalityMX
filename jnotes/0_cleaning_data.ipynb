{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "if not 'id_0123456789876543210' in locals():\n",
    "    _rootlevel = 1\n",
    "    _oldwd = re.sub(r'\\\\', '/', os.getcwd())\n",
    "    _spdirs = _oldwd.split('/')\n",
    "    _newwd = '/'.join(_spdirs[:(len(_spdirs)-_rootlevel)])\n",
    "    os.chdir(_newwd)\n",
    "    id_0123456789876543210 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.python.dataframe import Catalogue\n",
    "from src.python.util import dict_str_hash\n",
    "from src.python.dataframe import filter\n",
    "from src.python.util import save_object\n",
    "from src.python.util import load_object\n",
    "from src.python.util import save_json\n",
    "from src.python.util import load_json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "VERSION = 1\n",
    "\n",
    "\n",
    "def newdir(path):\n",
    "    try:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "    except OSError as error:\n",
    "        print(f\"Error al crear la carpeta: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura y limpieza de datos\n",
    "\n",
    "### Catálogo\n",
    "\n",
    "Creación de catálogo para re-etiquetar los valores de las bases descargadas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "entidad = load_json(\n",
    "    path.join('data', 'covid', 'history', 'dictionary', 'entidad.json'))\n",
    "\n",
    "catalogue = Catalogue()\n",
    "SI_NO = {'1': 'SI', '2': 'NO', '97': 'NA'}\n",
    "catalogue.add(column='EDAD', name='edad',\n",
    "              function=lambda x: [int(x) for x in x])\n",
    "catalogue.add(column='SEXO', name='sexo',\n",
    "              category={'1': 'MUJER', '2': 'HOMBRE'})\n",
    "catalogue.add(column='EMBARAZO', name='embarazo',\n",
    "              category=SI_NO)\n",
    "catalogue.add(column='NACIONALIDAD', name='nacionalidad',\n",
    "              category={'1': 'MEXICANA', '2': 'EXTRANGERA'})\n",
    "catalogue.add(column='MIGRANTE', name='migrante',\n",
    "              category=SI_NO)\n",
    "catalogue.add(column='INDIGENA', name='indigena',\n",
    "              category=SI_NO)\n",
    "catalogue.add(column='HABLA_LENGUA_INDIG', name='lengua_indigena',\n",
    "              category=SI_NO)\n",
    "catalogue.add(column='DIABETES', name='diabetes',\n",
    "              category=SI_NO)\n",
    "catalogue.add(column='EPOC', name='epoc',\n",
    "              category=SI_NO)\n",
    "catalogue.add(column='ASMA', name='asma',\n",
    "              category=SI_NO)\n",
    "catalogue.add(column='INMUSUPR', name='inmunosupresion',\n",
    "              category=SI_NO)\n",
    "catalogue.add(column='HIPERTENSION', name='hipertension',\n",
    "              category=SI_NO)\n",
    "catalogue.add(column='CARDIOVASCULAR', name='cardiovascular',\n",
    "              category=SI_NO)\n",
    "catalogue.add(column='OBESIDAD', name='obesidad',\n",
    "              category=SI_NO)\n",
    "catalogue.add(column='RENAL_CRONICA', name='renal_cronica',\n",
    "              category=SI_NO)\n",
    "catalogue.add(column='TABAQUISMO', name='tabaquismo',\n",
    "              category=SI_NO)\n",
    "catalogue.add(column='OTRA_COM', name='otra_comorbilidad',\n",
    "              category=SI_NO)\n",
    "# Variables regresoras\n",
    "catalogue.add(column='TIPO_PACIENTE', name='tipo',\n",
    "              category={'1': 'AMBULATORIO', '2': 'HOSPITALIZADO'})\n",
    "catalogue.add(column='INTUBADO', name='intubado',\n",
    "              category=SI_NO)\n",
    "catalogue.add(column='NEUMONIA', name='neumonia',\n",
    "              category=SI_NO)\n",
    "catalogue.add(column='UCI', name='uci',\n",
    "              category=SI_NO)\n",
    "# Clasificación\n",
    "catalogue.add(column='OTRO_CASO', name='contacto_covid',\n",
    "              category=SI_NO)\n",
    "catalogue.add(column='RESULTADO_LAB', name='laboratorio',\n",
    "              category={'1': 'POSITIVO', '2': 'NEGATIVO', '3': 'PENDIENTE', '4': 'NO VALIDO', '97': 'NA'})\n",
    "catalogue.add(column='RESULTADO_ANTIGENO', name='antigeno',\n",
    "              category={'1': 'POSITIVO', '2': 'NEGATIVO', '97': 'NA'})\n",
    "catalogue.add(column='CLASIFICACION_FINAL', name='clasificacion',\n",
    "              category={'1': 'ASOCIACION', '2': 'DICTAMINACION', '3': 'CONFIRMACION',\n",
    "                        '4': 'NO VALIDO', '5': 'PENDIENTE', '6': 'SOSPECHOSO', '7': 'NEGATIVO'})\n",
    "# Fechas\n",
    "catalogue.add(column='FECHA_INGRESO', name='fecha_ingreso',\n",
    "              function=lambda x: pd.to_datetime(x, format='%Y-%m-%d'))\n",
    "catalogue.add(column='FECHA_SINTOMAS', name='fecha_sintomas',\n",
    "              function=lambda x: pd.to_datetime(x, format='%Y-%m-%d'))\n",
    "catalogue.add(column='FECHA_DEF', name='fecha_defuncion',\n",
    "              default=pd.NaT,\n",
    "              exception='9999-99-99',\n",
    "              function=lambda x: pd.to_datetime(x, format='%Y-%m-%d'))\n",
    "# Otros\n",
    "catalogue.add(column='ORIGEN', name='origen',\n",
    "              category={'1': 'USMER', '2': 'FUERA DE USMER'})\n",
    "catalogue.add(column='SECTOR', name='sector',\n",
    "              category={'1': 'CRUZ ROJA', '2': 'DIF', '3': 'ESTATAL', '4': 'IMSS', '5': 'IMSS-BIENESTAR',\n",
    "                        '6': 'ISSSTE', '7': 'MUNICIPAL', '8': 'PEMEX', '9': 'PRIVADA', '10': 'SEDENA',\n",
    "                        '11': 'SEMAR', '12': 'SSA', '13': 'UNIVERSITARIO'})\n",
    "catalogue.add(column='ENTIDAD_UM', name='entidad',\n",
    "              category=entidad)\n",
    "catalogue.add(column='ENTIDAD_NAC', name='entidad_nacimiento',\n",
    "              category=entidad)\n",
    "catalogue.add(column='ENTIDAD_RES', name='entidad_residencia',\n",
    "              category=entidad)\n",
    "catalogue.add(column='MUNICIPIO_RES', name='municipio_residencia',\n",
    "              function=lambda x: x)\n",
    "catalogue.add(column='PAIS_NACIONALIDAD', name='pais_nacionalidad',\n",
    "              function=lambda x: ['NE' if (x == 'SE DESCONOCE' or x == '99')\n",
    "                                  else x.upper() for x in x])\n",
    "catalogue.add(column='PAIS_ORIGEN', name='pais_origen',\n",
    "              function=lambda x: ['NE' if x == 'SE DESCONOCE'\n",
    "                                  else ('MÉXICO' if x == '97' else x.upper()) for x in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura\n",
    "\n",
    "Lectura organización y re-etiquetación de bases históricas. La hubicación de los archivos debe de ser `data/covid/history/version-{VERSION}.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_history(file):\n",
    "    return pd.read_csv(path.join('data', 'covid', 'history', f'version-{VERSION}.0', file), dtype=str)\n",
    "\n",
    "\n",
    "# Juntas bases históricas\n",
    "superdata = read_history('COVID19MEXICO2024.csv')\n",
    "for subdata in [read_history(f'COVID19MEXICO202{i}.csv') for i in [3, 2, 1, 0]]:\n",
    "    superdata = pd.concat([superdata,\n",
    "                           subdata[~subdata.ID_REGISTRO.isin(superdata.ID_REGISTRO)]])\n",
    "\n",
    "# Guardar contadores iniciales\n",
    "save_json({col: superdata[col].value_counts().to_dict()\n",
    "           for col in superdata.columns if col != 'ID_REGISTRO'},\n",
    "          path.join('data', 'covid', 'history', f'version-{VERSION}.0', 'initial_counts.json'))\n",
    "\n",
    "superdata = (filter(superdata, catalogue)\n",
    "             .sort_values('fecha_ingreso').reset_index(drop=True))\n",
    "\n",
    "# Guardar contadores finales\n",
    "save_json({col: {str(k): v for k, v in superdata[col].value_counts().to_dict().items()}\n",
    "           for col in superdata.columns},\n",
    "          path.join('data', 'covid', 'history', f'version-{VERSION}.0', 'final_counts.json'))\n",
    "\n",
    "del catalogue, subdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación\n",
    "\n",
    "Clasificación de bases en \"positivos\", \"negativos\" e \"indeterminados\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indeterminados: 877943\n",
      "Positivos: 7714858\n",
      "Negativos: 11800967\n"
     ]
    }
   ],
   "source": [
    "for name, value in {'indeterminados': ['NO VALIDO', 'PENDIENTE', 'SOSPECHOSO'],\n",
    "                    'positivos': ['ASOCIACION', 'DICTAMINACION', 'CONFIRMACION'],\n",
    "                    'negativos': ['NEGATIVO']\n",
    "                    }.items():\n",
    "    locs = superdata.clasificacion.isin(value)\n",
    "    newdir(path.join('data', 'covid', 'cleanned'))\n",
    "    save_object(superdata[locs],\n",
    "                path.join('data', 'covid', 'cleanned', f'{name}-{VERSION}.0.pkl'))\n",
    "    superdata = superdata[~locs]\n",
    "    print(f'{name[0].upper()}{name[1:]}: {sum(locs)}')\n",
    "\n",
    "del superdata, locs, name, value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de datos de entrenamiento\n",
    "\n",
    "Para red neuronal de clasificación (versión 1)\n",
    "\n",
    "\n",
    "### Variables de entrenamiento\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_object(\n",
    "    path.join('data', 'covid', 'cleanned', f'positivos-{VERSION}.0.pkl'))\n",
    "\n",
    "data['indigena'] = data.indigena + '_' + data.lengua_indigena\n",
    "\n",
    "data['dias'] = [x.days for x\n",
    "                in data.fecha_ingreso-data.fecha_sintomas]\n",
    "data['defuncion'] = ~pd.isna(data.fecha_defuncion)\n",
    "data['grave'] = (data.tipo == 'HOSPITALIZADO') | data['defuncion']\n",
    "\n",
    "fecha_etapa = np.array([data.fecha_ingreso.min()] +\n",
    "                       [pd.Timestamp(x) for x in\n",
    "                        ['2020-09-20', '2021-05-16', '2021-11-21',\n",
    "                         '2022-04-17', '2022-10-23', '2023-06-25']])\n",
    "\n",
    "etapa = pd.Series(len(fecha_etapa)-1, index=data.index)\n",
    "for i in range(len(fecha_etapa)-1):\n",
    "    etapa[(data.fecha_ingreso >= fecha_etapa[i])\n",
    "          & (data.fecha_ingreso < fecha_etapa[i+1])] = i\n",
    "data['etapa'] = etapa\n",
    "\n",
    "catalogue = Catalogue()\n",
    "catalogue.add('etapa')\n",
    "catalogue.add('dias', function=lambda x:\n",
    "              [max(0, min(16, x)) for x in x])\n",
    "catalogue.add('edad', function=lambda x:\n",
    "              [max(0, min(100, x)) for x in x])\n",
    "catalogue.add(column='sexo', name='mujer', function=lambda x:\n",
    "              [x == 'MUJER' for x in x])\n",
    "catalogue.add(column='nacionalidad', name='origen',\n",
    "              category={'MEXICANA': 'MEXICANO', 'EXTRANGERA': 'EXTRANGERO'})\n",
    "\n",
    "# catalogue.add('nacionalidad')\n",
    "catalogue.add('indigena', function=lambda x:\n",
    "              ['SI' if 'SI' in x else ('NO' if 'NO_NO' == x else 'NE') for x in x])\n",
    "\n",
    "catalogue.add('migrante', function=lambda x:\n",
    "              ['NO' if n == 'MEXICANA' else x\n",
    "                  for x, n in zip(x, data['nacionalidad'])])\n",
    "\n",
    "for col in ['embarazo', 'diabetes', 'epoc', 'asma', 'inmunosupresion',\n",
    "            'hipertension', 'cardiovascular', 'obesidad',\n",
    "            'renal_cronica', 'tabaquismo', 'otra_comorbilidad']:\n",
    "    catalogue.add(col)\n",
    "catalogue.add('grave')\n",
    "catalogue.add('defuncion')\n",
    "data = filter(data, catalogue)\n",
    "###########################\n",
    "data.loc[data.indigena == 'SI', 'origen'] = 'MEXICANO_INDIGENA'\n",
    "data.loc[data.migrante == 'SI', 'origen'] = 'EXTRANGERO_MIGRANTE'\n",
    "data.drop(['indigena',\t'migrante'], axis=1, inplace=True)\n",
    "###########################\n",
    "newdir(path.join('data', 'covid', 'classification', 'dataframe'))\n",
    "save_object(data,\n",
    "            path.join('data', 'covid', 'classification', 'dataframe', f'positivos-{VERSION}.0.pkl'))\n",
    "del data, catalogue, col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-procesamiento y hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingdata1(data, alpha=5, skip=[], drop=[]):\n",
    "    skip = skip if isinstance(skip, list) else [skip]\n",
    "    drop = drop if isinstance(drop, list) else [drop]\n",
    "    data = data.copy()\n",
    "    comorb_columns = []\n",
    "    columns = []\n",
    "    for col in data.columns:\n",
    "        if col not in skip:\n",
    "            counts = data[col].value_counts()\n",
    "            if 'SI' in counts.index:\n",
    "                prop = 100 * counts['SI'] / (counts['SI'] + counts['NO'])\n",
    "                comorb_columns.append(col) if prop < alpha else None\n",
    "                columns.append(col)\n",
    "    comorb = pd.Series(0, index=data.index)\n",
    "    comorb_ne = pd.Series(0, index=data.index)\n",
    "    for column in columns:\n",
    "        comorb_ne += (data[column] == 'NE').astype(int)\n",
    "        if column in comorb_columns:\n",
    "            comorb += (data[column] == 'SI').astype(int)\n",
    "        else:\n",
    "            data[column] = data[column] == 'SI'\n",
    "    data['comorbilidad'] = comorb\n",
    "    data['comorbilidad_ne'] = comorb_ne\n",
    "    grave = data.pop('grave') if 'grave' in data else None\n",
    "    defuncion = data.pop('defuncion') if 'defuncion' in data else None\n",
    "    if drop:\n",
    "        for dp in drop:\n",
    "            if dp in data.columns:\n",
    "                data.drop(dp, axis=1, inplace=True)\n",
    "    data.drop(comorb_columns, axis=1, inplace=True)\n",
    "    if not (grave is None or 'grave' in drop):\n",
    "        data['grave'] = grave\n",
    "    if not (defuncion is None or 'defuncion' in drop):\n",
    "        data['defuncion'] = defuncion\n",
    "    return data\n",
    "\n",
    "\n",
    "def hashing(data):\n",
    "    grave = data.pop('grave') if 'grave' in data else None\n",
    "    defuncion = data.pop('defuncion') if 'defuncion' in data else None\n",
    "    data.index = [dict_str_hash(data.iloc[i]).upper()\n",
    "                  for i in range(len(data))]\n",
    "    data.index.name = 'hash'\n",
    "    if grave is not None:\n",
    "        data['grave'] = grave.tolist()\n",
    "    if defuncion is not None:\n",
    "        data['defuncion'] = defuncion.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_object(\n",
    "    path.join('data', 'covid', 'classification', 'dataframe', f'positivos-{VERSION}.0.pkl'))\n",
    "\n",
    "# Positivos\n",
    "positivos = trainingdata1(data, drop='defuncion')\n",
    "col = positivos.comorbilidad.copy()\n",
    "col[col >= 2] = 2\n",
    "positivos.comorbilidad = col\n",
    "col = positivos.comorbilidad_ne.copy()\n",
    "col[col >= 1] = 1\n",
    "positivos.comorbilidad_ne = col\n",
    "col = positivos.origen.copy()\n",
    "col[col == 'EXTRANGERO_MIGRANTE'] = 'EXTRANGERO'\n",
    "positivos.origen = col\n",
    "col = positivos.etapa.copy()\n",
    "col[col >= 5] = 5\n",
    "positivos.etapa = col\n",
    "hashing(positivos)\n",
    "save_object(positivos,\n",
    "            path.join('data', 'covid', 'classification', 'dataframe', f'positivos_hash-{VERSION}.1.pkl'))\n",
    "\n",
    "# Graves\n",
    "graves = trainingdata1(data[data.grave],\n",
    "                       drop=['origen', 'comorbilidad_ne', 'grave'])\n",
    "col = graves.comorbilidad.copy()\n",
    "col[col >= 1] = 1\n",
    "graves.comorbilidad = col\n",
    "col = graves.etapa.copy()\n",
    "col[col >= 5] = 5\n",
    "graves.etapa = col\n",
    "hashing(graves)\n",
    "save_object(graves,\n",
    "            path.join('data', 'covid', 'classification', 'dataframe', f'graves_hash-{VERSION}.1.pkl'))\n",
    "\n",
    "del data, positivos, graves, col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sets de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets1(data, column, testprop, minsize=10, seed=555):\n",
    "    # Calcular probabilidad\n",
    "    muestra = data.index.value_counts()\n",
    "    muestra = muestra[muestra >= minsize]\n",
    "    data = data.loc[muestra.index]\n",
    "    casos = data[data[column]].index.value_counts()\n",
    "    probabilidad = pd.Series(0.0, index=muestra.index)\n",
    "    probabilidad.loc[casos.index] = casos / muestra[casos.index]\n",
    "    # Estandarizar datos\n",
    "    data = data.drop(column, axis=1).groupby(level=0).head(1)\n",
    "    data = pd.get_dummies(data.sample(\n",
    "        len(data), replace=False, random_state=seed))\n",
    "    data = data[data.columns.sort_values()]\n",
    "    etiqueta = data.etapa\n",
    "    for column in data.columns:\n",
    "        if data[column].dtype.name != 'bool':\n",
    "            mx = max(data[column])\n",
    "            if mx > 1.0:\n",
    "                data[column] = data[column] / mx\n",
    "    data = data.astype(float)\n",
    "    data['probabilidad'] = probabilidad.loc[data.index]\n",
    "    data['muestra'] = muestra.loc[data.index]\n",
    "    data['etiqueta'] = etiqueta.loc[data.index]\n",
    "    seed += 1\n",
    "    # Creación de sets\n",
    "    test = []\n",
    "    for label in etiqueta.unique():\n",
    "        subdata = data[data.etiqueta == label]\n",
    "        test.append(subdata.sample(round(testprop*len(subdata)),\n",
    "                                   replace=False,\n",
    "                                   weights=subdata.muestra,\n",
    "                                   random_state=seed))\n",
    "    seed += 1\n",
    "    test = pd.concat(test, axis=0)\n",
    "    test = test.sample(len(test), replace=False, random_state=seed)\n",
    "    train = data.drop(test.index, axis=0)\n",
    "\n",
    "    testvar = test[['probabilidad', 'muestra', 'etiqueta']]\n",
    "    trainvar = train[['probabilidad', 'muestra', 'etiqueta']]\n",
    "\n",
    "    test.drop(['probabilidad', 'muestra', 'etiqueta'], axis=1, inplace=True)\n",
    "    train.drop(['probabilidad', 'muestra', 'etiqueta'], axis=1, inplace=True)\n",
    "\n",
    "    return (dict(xtrain=train.values,\n",
    "                 ytrain=trainvar.probabilidad.to_numpy(),\n",
    "                 sample=trainvar.muestra.to_numpy(),\n",
    "                 label=trainvar.etiqueta.to_numpy(),\n",
    "                 columns=train.columns.to_numpy(),\n",
    "                 index=train.index.to_numpy()),\n",
    "            dict(xtest=test.values,\n",
    "                 ytest=testvar.probabilidad.to_numpy(),\n",
    "                 sample=testvar.muestra.to_numpy(),\n",
    "                 label=testvar.etiqueta.to_numpy(),\n",
    "                 columns=test.columns.to_numpy(),\n",
    "                 index=test.index.to_numpy()))\n",
    "\n",
    "\n",
    "newdir(path.join('data', 'covid', 'classification', 'datasets'))\n",
    "\n",
    "train, test = datasets1(data=load_object(\n",
    "    path.join('data', 'covid', 'classification', 'dataframe', f'graves_hash-{VERSION}.1.pkl')),\n",
    "    column='defuncion', testprop=0.15)\n",
    "save_object(train,\n",
    "            path.join('data', 'covid', 'classification', 'datasets', f'graves_train-{VERSION}.1.pkl'))\n",
    "save_object(test,\n",
    "            path.join('data', 'covid', 'classification', 'datasets', f'graves_test-{VERSION}.1.pkl'))\n",
    "train, test = positivos = datasets1(data=load_object(\n",
    "    path.join('data', 'covid', 'classification', 'dataframe', f'positivos_hash-{VERSION}.1.pkl')),\n",
    "    column='grave', testprop=0.2)\n",
    "save_object(train,\n",
    "            path.join('data', 'covid', 'classification', 'datasets', f'positivos_train-{VERSION}.1.pkl'))\n",
    "save_object(test,\n",
    "            path.join('data', 'covid', 'classification', 'datasets', f'positivos_test-{VERSION}.1.pkl'))\n",
    "\n",
    "del train, test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
