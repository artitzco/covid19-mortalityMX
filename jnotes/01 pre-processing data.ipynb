{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not 'id_0123456789876543210' in locals():\n",
    "    os.chdir(os.path.split(os.getcwd())[0])\n",
    "    id_0123456789876543210 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.python.dataframe import Catalogue\n",
    "from src.python.util import dict_str_hash\n",
    "from src.python.dataframe import filter\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "def save_object(obj, file):\n",
    "    with open(file, \"wb\") as file:\n",
    "        pickle.dump(obj, file)\n",
    "\n",
    "\n",
    "def load_object(file):\n",
    "    with open(file, \"rb\") as file:\n",
    "        loaded_object = pickle.load(file)\n",
    "    return loaded_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de datos de entrenamiento\n",
    "\n",
    "Para red neuronal de clasificación (versión 1)\n",
    "\n",
    "### Semanas epidemiológicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SE_inicio</th>\n",
       "      <th>SE_fin</th>\n",
       "      <th>año_inicio</th>\n",
       "      <th>año_fin</th>\n",
       "      <th>fecha_inicio</th>\n",
       "      <th>fecha_fin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ola</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020</td>\n",
       "      <td>2020-02-16</td>\n",
       "      <td>2020-09-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>2020</td>\n",
       "      <td>2021</td>\n",
       "      <td>2020-09-27</td>\n",
       "      <td>2021-04-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>42</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021</td>\n",
       "      <td>2021-05-30</td>\n",
       "      <td>2021-10-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>9</td>\n",
       "      <td>2021</td>\n",
       "      <td>2022</td>\n",
       "      <td>2021-12-12</td>\n",
       "      <td>2022-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22</td>\n",
       "      <td>33</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-05-22</td>\n",
       "      <td>2022-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>2022</td>\n",
       "      <td>2023</td>\n",
       "      <td>2022-11-27</td>\n",
       "      <td>2023-01-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SE_inicio  SE_fin  año_inicio  año_fin fecha_inicio  fecha_fin\n",
       "Ola                                                                \n",
       "1            8      39        2020     2020   2020-02-16 2020-09-26\n",
       "2           40      15        2020     2021   2020-09-27 2021-04-10\n",
       "3           23      42        2021     2021   2021-05-30 2021-10-16\n",
       "4           51       9        2021     2022   2021-12-12 2022-02-26\n",
       "5           22      33        2022     2022   2022-05-22 2022-08-13\n",
       "6           49       4        2022     2023   2022-11-27 2023-01-28"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def epidemiological_week(week, year):\n",
    "    date = pd.Timestamp(f'{year}-01-01')\n",
    "    while date.dayofweek != 6:\n",
    "        date -= pd.Timedelta(days=1)\n",
    "\n",
    "    start = date + pd.Timedelta(days=(week-1)*7)\n",
    "    end = start + pd.Timedelta(days=6)\n",
    "    return start, end\n",
    "\n",
    "\n",
    "weeks = pd.DataFrame({\n",
    "    'Ola': [1, 2, 3, 4, 5, 6],\n",
    "    'SE_inicio': [8, 40, 23, 51, 22, 49],\n",
    "    'SE_fin': [39, 15, 42, 9, 33, 4],\n",
    "    'año_inicio': [2020, 2020, 2021, 2021, 2022, 2022],\n",
    "    'año_fin': [2020, 2021, 2021, 2022, 2022, 2023]\n",
    "}).set_index('Ola')\n",
    "\n",
    "weeks['fecha_inicio'] = [epidemiological_week(week, year)[0]\n",
    "                           for week, year in zip(weeks['SE_inicio'], weeks['año_inicio'])]\n",
    "weeks['fecha_fin'] = [epidemiological_week(week, year)[1]\n",
    "                           for week, year in zip(weeks['SE_fin'], weeks['año_fin'])]\n",
    "weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Variables de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_object(\n",
    "    path.join('data', 'covid', 'cleanned', f'positivos.pkl'))\n",
    "\n",
    "data['indigena'] = data.indigena + '_' + data.lengua_indigena\n",
    "\n",
    "data['dias'] = [x.days for x\n",
    "                in data.fecha_ingreso-data.fecha_sintomas]\n",
    "data['defuncion'] = ~pd.isna(data.fecha_defuncion)\n",
    "data['grave'] = (data.tipo == 'HOSPITALIZADO') | data['defuncion']\n",
    "\n",
    "fecha_etapa = [min(data.fecha_ingreso)-pd.Timedelta(days=1),\n",
    "               *weeks.fecha_fin,\n",
    "               max(data.fecha_ingreso)]\n",
    "\n",
    "data['etapa'] = pd.cut(data.fecha_ingreso,\n",
    "                       bins=fecha_etapa,\n",
    "                       labels=[i for i in range(len(fecha_etapa)-1)],\n",
    "                       right=True).astype(int)\n",
    "\n",
    "catalogue = Catalogue()\n",
    "catalogue.add('etapa')\n",
    "catalogue.add('dias', function=lambda x:\n",
    "              [max(0, min(16, x)) for x in x])\n",
    "catalogue.add('edad', function=lambda x:\n",
    "              [max(0, min(100, x)) for x in x])\n",
    "catalogue.add(column='sexo', name='mujer', function=lambda x:\n",
    "              [x == 'MUJER' for x in x])\n",
    "catalogue.add(column='nacionalidad', name='origen',\n",
    "              category={'MEXICANA': 'MEXICANO', 'EXTRANGERA': 'EXTRANGERO'})\n",
    "\n",
    "catalogue.add('indigena', function=lambda x:\n",
    "              ['SI' if 'SI' in x else ('NO' if 'NO_NO' == x else 'NE') for x in x])\n",
    "\n",
    "catalogue.add('migrante', function=lambda x:\n",
    "              ['NO' if n == 'MEXICANA' else x\n",
    "                  for x, n in zip(x, data['nacionalidad'])])\n",
    "\n",
    "for col in ['embarazo', 'diabetes', 'epoc', 'asma', 'inmunosupresion',\n",
    "            'hipertension', 'cardiovascular', 'obesidad',\n",
    "            'renal_cronica', 'tabaquismo', 'otra_comorbilidad']:\n",
    "    catalogue.add(col)\n",
    "catalogue.add('grave')\n",
    "catalogue.add('defuncion')\n",
    "data = filter(data, catalogue)\n",
    "###########################\n",
    "data.loc[data.indigena == 'SI', 'origen'] = 'MEXICANO_INDIGENA'\n",
    "data.loc[data.migrante == 'SI', 'origen'] = 'EXTRANGERO_MIGRANTE'\n",
    "data.drop(['indigena',\t'migrante'], axis=1, inplace=True)\n",
    "###########################\n",
    "basis = path.join('data', 'covid', 'classification', 'dataframe')\n",
    "os.makedirs(basis, exist_ok=True)\n",
    "save_object(data, path.join(basis, f'positivos.pkl'))\n",
    "del data, catalogue, col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-procesamiento y hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingdata_1(data, alpha=5, skip=[], drop=[]):\n",
    "    skip = skip if isinstance(skip, list) else [skip]\n",
    "    drop = drop if isinstance(drop, list) else [drop]\n",
    "    data = data.copy()\n",
    "    comorb_columns = []\n",
    "    columns = []\n",
    "    for col in data.columns:\n",
    "        if col not in skip:\n",
    "            counts = data[col].value_counts()\n",
    "            if 'SI' in counts.index:\n",
    "                prop = 100 * counts['SI'] / (counts['SI'] + counts['NO'])\n",
    "                if prop < alpha:\n",
    "                    comorb_columns.append(col)\n",
    "                columns.append(col)\n",
    "    comorb = pd.Series(0, index=data.index)\n",
    "    comorb_ne = pd.Series(0, index=data.index)\n",
    "    for column in columns:\n",
    "        comorb_ne += (data[column] == 'NE').astype(int)\n",
    "        if column in comorb_columns:\n",
    "            comorb += (data[column] == 'SI').astype(int)\n",
    "        else:\n",
    "            data[column] = data[column] == 'SI'\n",
    "    data['comorbilidad'] = comorb\n",
    "    data['comorbilidad_ne'] = comorb_ne\n",
    "    grave = data.pop('grave') if 'grave' in data else None\n",
    "    defuncion = data.pop('defuncion') if 'defuncion' in data else None\n",
    "    if drop:\n",
    "        for dp in drop:\n",
    "            if dp in data.columns:\n",
    "                data.drop(dp, axis=1, inplace=True)\n",
    "    data.drop(comorb_columns, axis=1, inplace=True)\n",
    "    if not (grave is None or 'grave' in drop):\n",
    "        data['grave'] = grave\n",
    "    if not (defuncion is None or 'defuncion' in drop):\n",
    "        data['defuncion'] = defuncion\n",
    "    return data\n",
    "\n",
    "\n",
    "def hashing(data):\n",
    "    grave = data.pop('grave') if 'grave' in data else None\n",
    "    defuncion = data.pop('defuncion') if 'defuncion' in data else None\n",
    "    data.index = [dict_str_hash(data.iloc[i]).upper()\n",
    "                  for i in range(len(data))]\n",
    "    data.index.name = 'hash'\n",
    "    if grave is not None:\n",
    "        data['grave'] = grave.tolist()\n",
    "    if defuncion is not None:\n",
    "        data['defuncion'] = defuncion.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis = path.join('data', 'covid', 'classification', 'dataframe')\n",
    "data = load_object(path.join(basis, f'positivos.pkl'))\n",
    "\n",
    "# Positivos\n",
    "positivos = trainingdata_1(data, drop='defuncion')\n",
    "col = positivos.comorbilidad.copy()\n",
    "col[col >= 2] = 2\n",
    "positivos.comorbilidad = col\n",
    "col = positivos.comorbilidad_ne.copy()\n",
    "col[col >= 1] = 1\n",
    "positivos.comorbilidad_ne = col\n",
    "col = positivos.origen.copy()\n",
    "col[col == 'EXTRANGERO_MIGRANTE'] = 'EXTRANGERO'\n",
    "positivos.origen = col\n",
    "col = positivos.etapa.copy()\n",
    "col[col >= 5] = 5\n",
    "positivos.etapa = col\n",
    "hashing(positivos)\n",
    "save_object(positivos, path.join(basis, f'positivos_hash-1.pkl'))\n",
    "\n",
    "# Graves\n",
    "graves = trainingdata_1(data[data.grave],\n",
    "                              drop=['origen', 'comorbilidad_ne', 'grave'])\n",
    "col = graves.comorbilidad.copy()\n",
    "col[col >= 1] = 1\n",
    "graves.comorbilidad = col\n",
    "col = graves.etapa.copy()\n",
    "col[col >= 5] = 5\n",
    "graves.etapa = col\n",
    "hashing(graves)\n",
    "save_object(graves, path.join(basis, f'graves_hash-1.pkl'))\n",
    "\n",
    "del data, positivos, graves, col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sets de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasets_1(data, column, testprop, minsize=10, seed=555):\n",
    "    # Calcular probabilidad\n",
    "    muestra = data.index.value_counts()\n",
    "    muestra = muestra[muestra >= minsize]\n",
    "    data = data.loc[muestra.index]\n",
    "    casos = data[data[column]].index.value_counts()\n",
    "    probabilidad = pd.Series(0.0, index=muestra.index)\n",
    "    probabilidad.loc[casos.index] = casos / muestra[casos.index]\n",
    "    # Estandarizar datos\n",
    "    data = data.drop(column, axis=1).groupby(level=0).head(1)\n",
    "    data = pd.get_dummies(data.sample(\n",
    "        len(data), replace=False, random_state=seed))\n",
    "    data = data[data.columns.sort_values()]\n",
    "    etiqueta = data.etapa\n",
    "    for column in data.columns:\n",
    "        if data[column].dtype.name != 'bool':\n",
    "            mx = max(data[column])\n",
    "            if mx > 1.0:\n",
    "                data[column] = data[column] / mx\n",
    "    data = data.astype(float)\n",
    "    data['probabilidad'] = probabilidad.loc[data.index]\n",
    "    data['muestra'] = muestra.loc[data.index]\n",
    "    data['etiqueta'] = etiqueta.loc[data.index]\n",
    "    seed += 1\n",
    "    # Creación de sets\n",
    "    test = []\n",
    "    for label in etiqueta.unique():\n",
    "        subdata = data[data.etiqueta == label]\n",
    "        test.append(subdata.sample(round(testprop * len(subdata)),\n",
    "                                   replace=False,\n",
    "                                   weights=subdata.muestra,\n",
    "                                   random_state=seed))\n",
    "    seed += 1\n",
    "    test = pd.concat(test, axis=0)\n",
    "    test = test.sample(len(test), replace=False, random_state=seed)\n",
    "    train = data.drop(test.index, axis=0)\n",
    "\n",
    "    testvar = test[['probabilidad', 'muestra', 'etiqueta']]\n",
    "    trainvar = train[['probabilidad', 'muestra', 'etiqueta']]\n",
    "\n",
    "    test.drop(['probabilidad', 'muestra', 'etiqueta'], axis=1, inplace=True)\n",
    "    train.drop(['probabilidad', 'muestra', 'etiqueta'], axis=1, inplace=True)\n",
    "\n",
    "    return (dict(x=train.values,\n",
    "                 y=trainvar.probabilidad.to_numpy(),\n",
    "                 sample=trainvar.muestra.to_numpy(),\n",
    "                 label=trainvar.etiqueta.to_numpy(),\n",
    "                 columns=train.columns.to_numpy(),\n",
    "                 index=train.index.to_numpy()),\n",
    "            dict(x=test.values,\n",
    "                 y=testvar.probabilidad.to_numpy(),\n",
    "                 sample=testvar.muestra.to_numpy(),\n",
    "                 label=testvar.etiqueta.to_numpy(),\n",
    "                 columns=test.columns.to_numpy(),\n",
    "                 index=test.index.to_numpy()))\n",
    "\n",
    "\n",
    "basis_ds = path.join('data', 'covid', 'classification', 'dataset')\n",
    "basis_df = path.join('data', 'covid', 'classification', 'dataframe')\n",
    "\n",
    "os.makedirs(basis_ds, exist_ok=True)\n",
    "\n",
    "train, test = datasets_1(load_object(path.join(basis_df, 'graves_hash-1.pkl')),\n",
    "                         column='defuncion', testprop=0.15)\n",
    "save_object(train, path.join(basis_ds, 'train.graves-1.pkl'))\n",
    "save_object(test, path.join(basis_ds, 'test.graves-1.pkl'))\n",
    "\n",
    "train, test = datasets_1(load_object(path.join(basis_df, f'positivos_hash-1.pkl')),\n",
    "                         column='grave', testprop=0.2)\n",
    "save_object(train, path.join(basis_ds, 'train.positivos-1.pkl'))\n",
    "save_object(test, path.join(basis_ds, 'test.positivos-1.pkl'))\n",
    "\n",
    "del train, test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
