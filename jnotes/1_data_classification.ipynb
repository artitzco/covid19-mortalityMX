{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "if not 'id_0123456789876543210' in locals():\n",
    "    _rootlevel = 1\n",
    "    _oldwd = re.sub(r'\\\\', '/', os.getcwd())\n",
    "    _spdirs = _oldwd.split('/')\n",
    "    _newwd = '/'.join(_spdirs[:(len(_spdirs)-_rootlevel)])\n",
    "    os.chdir(_newwd)\n",
    "    id_0123456789876543210 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Itzco\\Documents\\Projects\\covid19\\env\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.python.model import classification_model, validate_classification_model_hparams\n",
    "\n",
    "from src.python.training.validation import Foldify, Memory, eval_model, make_grid\n",
    "\n",
    "from src.python.util import load_object, save_object\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "plt.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.031851   mae: 0.147316   val_loss: 0.027440   val_mae: 0.137132\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.025892   mae: 0.131342   val_loss: 0.023037   val_mae: 0.124266\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.028506   mae: 0.138310   val_loss: 0.024791   val_mae: 0.129884\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.026609   mae: 0.133237   val_loss: 0.023010   val_mae: 0.123557\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.031123   mae: 0.144745   val_loss: 0.026830   val_mae: 0.135287\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.031539   mae: 0.145510   val_loss: 0.028043   val_mae: 0.137325\n",
      "Total:\n",
      "\t \ttime: 0h 1m 1s   loss: 0.029253   mae: 0.140077   val_loss: 0.025525   val_mae: 0.131242\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.018966   mae: 0.109807   val_loss: 0.015121   val_mae: 0.097910\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.035722   mae: 0.152823   val_loss: 0.034076   val_mae: 0.150058\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.018502   mae: 0.108215   val_loss: 0.015186   val_mae: 0.098347\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.018565   mae: 0.108509   val_loss: 0.016164   val_mae: 0.100624\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.020641   mae: 0.114709   val_loss: 0.016944   val_mae: 0.102561\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.018305   mae: 0.107911   val_loss: 0.014929   val_mae: 0.096137\n",
      "Total:\n",
      "\t \ttime: 0h 1m 29s   loss: 0.021783   mae: 0.116996   val_loss: 0.018737   val_mae: 0.107606\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.015856   mae: 0.098584   val_loss: 0.012709   val_mae: 0.088417\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.015869   mae: 0.099188   val_loss: 0.012606   val_mae: 0.088400\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.017783   mae: 0.104482   val_loss: 0.014197   val_mae: 0.092662\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.016875   mae: 0.102711   val_loss: 0.014724   val_mae: 0.095939\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.016242   mae: 0.100463   val_loss: 0.012965   val_mae: 0.089413\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.016368   mae: 0.100905   val_loss: 0.012713   val_mae: 0.087427\n",
      "Total:\n",
      "\t \ttime: 0h 2m 11s   loss: 0.016499   mae: 0.101056   val_loss: 0.013319   val_mae: 0.090376\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.014951   mae: 0.094840   val_loss: 0.011858   val_mae: 0.084077\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 27s   loss: 0.015401   mae: 0.097456   val_loss: 0.012404   val_mae: 0.087342\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 27s   loss: 0.015689   mae: 0.098545   val_loss: 0.011515   val_mae: 0.084692\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 27s   loss: 0.015850   mae: 0.098258   val_loss: 0.013967   val_mae: 0.092359\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.016562   mae: 0.101755   val_loss: 0.013004   val_mae: 0.089779\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 27s   loss: 0.015997   mae: 0.099589   val_loss: 0.011928   val_mae: 0.085449\n",
      "Total:\n",
      "\t \ttime: 0h 2m 48s   loss: 0.015742   mae: 0.098407   val_loss: 0.012446   val_mae: 0.087283\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.015341   mae: 0.097080   val_loss: 0.012426   val_mae: 0.086903\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.015613   mae: 0.097596   val_loss: 0.012470   val_mae: 0.086684\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 33s   loss: 0.014709   mae: 0.094742   val_loss: 0.010690   val_mae: 0.079961\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.015174   mae: 0.095917   val_loss: 0.013256   val_mae: 0.089301\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.015607   mae: 0.097281   val_loss: 0.012195   val_mae: 0.085136\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.015549   mae: 0.097464   val_loss: 0.011485   val_mae: 0.082462\n",
      "Total:\n",
      "\t \ttime: 0h 3m 28s   loss: 0.015332   mae: 0.096680   val_loss: 0.012087   val_mae: 0.085074\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.038132   mae: 0.159451   val_loss: 0.034192   val_mae: 0.150953\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.030702   mae: 0.143066   val_loss: 0.027754   val_mae: 0.136744\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.040744   mae: 0.165720   val_loss: 0.038524   val_mae: 0.163428\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.033082   mae: 0.149271   val_loss: 0.029444   val_mae: 0.142329\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.037261   mae: 0.159255   val_loss: 0.033156   val_mae: 0.151458\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.030519   mae: 0.143322   val_loss: 0.025451   val_mae: 0.131013\n",
      "Total:\n",
      "\t \ttime: 0h 0m 32s   loss: 0.035073   mae: 0.153347   val_loss: 0.031420   val_mae: 0.145988\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.021074   mae: 0.116559   val_loss: 0.017362   val_mae: 0.105936\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.035255   mae: 0.155094   val_loss: 0.032771   val_mae: 0.150742\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.023595   mae: 0.124451   val_loss: 0.020328   val_mae: 0.116742\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.021023   mae: 0.116352   val_loss: 0.018788   val_mae: 0.109786\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.020881   mae: 0.116231   val_loss: 0.017081   val_mae: 0.104843\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.025912   mae: 0.129790   val_loss: 0.022861   val_mae: 0.121305\n",
      "Total:\n",
      "\t \ttime: 0h 0m 52s   loss: 0.024623   mae: 0.126413   val_loss: 0.021532   val_mae: 0.118225\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.018851   mae: 0.108700   val_loss: 0.015092   val_mae: 0.097605\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.018385   mae: 0.107823   val_loss: 0.014604   val_mae: 0.096647\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.021090   mae: 0.115096   val_loss: 0.017721   val_mae: 0.105689\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.022003   mae: 0.121072   val_loss: 0.019433   val_mae: 0.113321\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.018134   mae: 0.107754   val_loss: 0.014578   val_mae: 0.096855\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.020631   mae: 0.114521   val_loss: 0.017332   val_mae: 0.103599\n",
      "Total:\n",
      "\t \ttime: 0h 1m 13s   loss: 0.019849   mae: 0.112494   val_loss: 0.016460   val_mae: 0.102286\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.016348   mae: 0.101001   val_loss: 0.012890   val_mae: 0.090024\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.017882   mae: 0.106635   val_loss: 0.015185   val_mae: 0.098549\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.017244   mae: 0.103850   val_loss: 0.013602   val_mae: 0.092717\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.018250   mae: 0.106948   val_loss: 0.016340   val_mae: 0.101033\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.018182   mae: 0.107512   val_loss: 0.014307   val_mae: 0.095268\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.017425   mae: 0.104727   val_loss: 0.013735   val_mae: 0.091841\n",
      "Total:\n",
      "\t \ttime: 0h 1m 34s   loss: 0.017555   mae: 0.105112   val_loss: 0.014343   val_mae: 0.094905\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.016421   mae: 0.100144   val_loss: 0.013325   val_mae: 0.090849\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.016999   mae: 0.103395   val_loss: 0.014028   val_mae: 0.094372\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.019117   mae: 0.110807   val_loss: 0.015931   val_mae: 0.101363\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.018247   mae: 0.106250   val_loss: 0.015825   val_mae: 0.099383\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.015844   mae: 0.098321   val_loss: 0.012144   val_mae: 0.085437\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.017479   mae: 0.105135   val_loss: 0.013914   val_mae: 0.093132\n",
      "Total:\n",
      "\t \ttime: 0h 1m 54s   loss: 0.017351   mae: 0.104009   val_loss: 0.014195   val_mae: 0.094089\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.054194   mae: 0.188293   val_loss: 0.047804   val_mae: 0.181651\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.052034   mae: 0.191320   val_loss: 0.047721   val_mae: 0.184609\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.044131   mae: 0.170715   val_loss: 0.042700   val_mae: 0.169237\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.045220   mae: 0.177055   val_loss: 0.040775   val_mae: 0.169632\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.037856   mae: 0.158909   val_loss: 0.034562   val_mae: 0.153356\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.046642   mae: 0.176141   val_loss: 0.042322   val_mae: 0.169875\n",
      "Total:\n",
      "\t \ttime: 0h 0m 22s   loss: 0.046680   mae: 0.177072   val_loss: 0.042647   val_mae: 0.171393\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.043373   mae: 0.171391   val_loss: 0.040687   val_mae: 0.166046\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.035038   mae: 0.154033   val_loss: 0.033125   val_mae: 0.151087\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.030032   mae: 0.142226   val_loss: 0.027757   val_mae: 0.138172\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.039128   mae: 0.161765   val_loss: 0.035541   val_mae: 0.155202\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.032426   mae: 0.148307   val_loss: 0.028433   val_mae: 0.140179\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.027814   mae: 0.135852   val_loss: 0.024304   val_mae: 0.126536\n",
      "Total:\n",
      "\t \ttime: 0h 0m 33s   loss: 0.034635   mae: 0.152262   val_loss: 0.031641   val_mae: 0.146204\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.024349   mae: 0.126278   val_loss: 0.020682   val_mae: 0.117080\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.021474   mae: 0.118558   val_loss: 0.018836   val_mae: 0.112855\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.029186   mae: 0.137793   val_loss: 0.027488   val_mae: 0.135888\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.031172   mae: 0.144514   val_loss: 0.028102   val_mae: 0.138261\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.034823   mae: 0.152784   val_loss: 0.031132   val_mae: 0.145979\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.022524   mae: 0.120411   val_loss: 0.019373   val_mae: 0.112340\n",
      "Total:\n",
      "\t \ttime: 0h 0m 44s   loss: 0.027255   mae: 0.133390   val_loss: 0.024269   val_mae: 0.127067\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.020680   mae: 0.114281   val_loss: 0.017238   val_mae: 0.104710\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.025118   mae: 0.129034   val_loss: 0.021987   val_mae: 0.122002\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.021959   mae: 0.118590   val_loss: 0.018406   val_mae: 0.109560\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.021596   mae: 0.116946   val_loss: 0.019326   val_mae: 0.110124\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.018453   mae: 0.108245   val_loss: 0.014607   val_mae: 0.096414\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.019232   mae: 0.111334   val_loss: 0.015823   val_mae: 0.100894\n",
      "Total:\n",
      "\t \ttime: 0h 0m 55s   loss: 0.021173   mae: 0.116405   val_loss: 0.017898   val_mae: 0.107284\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.020641   mae: 0.115764   val_loss: 0.017838   val_mae: 0.107357\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.022554   mae: 0.121808   val_loss: 0.019872   val_mae: 0.115754\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.016921   mae: 0.103043   val_loss: 0.013348   val_mae: 0.091631\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.018835   mae: 0.109232   val_loss: 0.016515   val_mae: 0.101972\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.018021   mae: 0.107003   val_loss: 0.014562   val_mae: 0.096748\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.020834   mae: 0.116455   val_loss: 0.017197   val_mae: 0.105751\n",
      "Total:\n",
      "\t \ttime: 0h 1m 4s   loss: 0.019634   mae: 0.112218   val_loss: 0.016555   val_mae: 0.103202\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014802   mae: 0.095091   val_loss: 0.011670   val_mae: 0.084342\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014690   mae: 0.094452   val_loss: 0.011672   val_mae: 0.083660\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014492   mae: 0.093090   val_loss: 0.010937   val_mae: 0.079880\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014415   mae: 0.093379   val_loss: 0.012290   val_mae: 0.085409\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014275   mae: 0.093024   val_loss: 0.011134   val_mae: 0.081208\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014902   mae: 0.095578   val_loss: 0.010725   val_mae: 0.079477\n",
      "Total:\n",
      "\t \ttime: 0h 0m 50s   loss: 0.014596   mae: 0.094102   val_loss: 0.011404   val_mae: 0.082329\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014207   mae: 0.092499   val_loss: 0.011228   val_mae: 0.081947\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.014119   mae: 0.092263   val_loss: 0.010999   val_mae: 0.080502\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.014550   mae: 0.093880   val_loss: 0.010546   val_mae: 0.079024\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013802   mae: 0.090972   val_loss: 0.011828   val_mae: 0.083278\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013914   mae: 0.091502   val_loss: 0.010724   val_mae: 0.079480\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014393   mae: 0.093399   val_loss: 0.010252   val_mae: 0.076843\n",
      "Total:\n",
      "\t \ttime: 0h 1m 32s   loss: 0.014164   mae: 0.092419   val_loss: 0.010930   val_mae: 0.080179\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.014287   mae: 0.092750   val_loss: 0.011657   val_mae: 0.083316\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.014125   mae: 0.092098   val_loss: 0.011120   val_mae: 0.081207\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014011   mae: 0.091784   val_loss: 0.010406   val_mae: 0.077654\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013817   mae: 0.091029   val_loss: 0.011555   val_mae: 0.081891\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013815   mae: 0.091021   val_loss: 0.010564   val_mae: 0.078803\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014045   mae: 0.092071   val_loss: 0.010177   val_mae: 0.075761\n",
      "Total:\n",
      "\t \ttime: 0h 2m 10s   loss: 0.014017   mae: 0.091792   val_loss: 0.010913   val_mae: 0.079772\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013697   mae: 0.090308   val_loss: 0.010460   val_mae: 0.078010\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013763   mae: 0.090833   val_loss: 0.010572   val_mae: 0.078308\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013935   mae: 0.091556   val_loss: 0.010296   val_mae: 0.077198\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013782   mae: 0.091257   val_loss: 0.011753   val_mae: 0.083138\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 27s   loss: 0.013958   mae: 0.091899   val_loss: 0.010713   val_mae: 0.079211\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013868   mae: 0.091301   val_loss: 0.010052   val_mae: 0.075312\n",
      "Total:\n",
      "\t \ttime: 0h 2m 50s   loss: 0.013834   mae: 0.091192   val_loss: 0.010641   val_mae: 0.078529\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013673   mae: 0.090343   val_loss: 0.010596   val_mae: 0.078953\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013617   mae: 0.090084   val_loss: 0.010579   val_mae: 0.078487\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.014016   mae: 0.091817   val_loss: 0.010307   val_mae: 0.076826\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013571   mae: 0.090186   val_loss: 0.011466   val_mae: 0.081311\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013640   mae: 0.090389   val_loss: 0.010516   val_mae: 0.078518\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013838   mae: 0.091252   val_loss: 0.009847   val_mae: 0.074912\n",
      "Total:\n",
      "\t \ttime: 0h 3m 32s   loss: 0.013726   mae: 0.090678   val_loss: 0.010552   val_mae: 0.078168\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014829   mae: 0.095142   val_loss: 0.011323   val_mae: 0.082656\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014549   mae: 0.093581   val_loss: 0.011280   val_mae: 0.081885\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.015833   mae: 0.097982   val_loss: 0.011769   val_mae: 0.084288\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014629   mae: 0.094568   val_loss: 0.012271   val_mae: 0.085164\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.015276   mae: 0.096743   val_loss: 0.011953   val_mae: 0.084821\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.016399   mae: 0.100359   val_loss: 0.011971   val_mae: 0.084717\n",
      "Total:\n",
      "\t \ttime: 0h 0m 32s   loss: 0.015252   mae: 0.096396   val_loss: 0.011761   val_mae: 0.083922\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014679   mae: 0.094201   val_loss: 0.011658   val_mae: 0.083747\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014127   mae: 0.092197   val_loss: 0.010957   val_mae: 0.080347\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014164   mae: 0.092412   val_loss: 0.010884   val_mae: 0.079398\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014092   mae: 0.091845   val_loss: 0.011987   val_mae: 0.083371\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014135   mae: 0.092409   val_loss: 0.010804   val_mae: 0.080023\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014402   mae: 0.093216   val_loss: 0.010186   val_mae: 0.075939\n",
      "Total:\n",
      "\t \ttime: 0h 0m 52s   loss: 0.014267   mae: 0.092713   val_loss: 0.011079   val_mae: 0.080471\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014175   mae: 0.092176   val_loss: 0.011046   val_mae: 0.080687\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014157   mae: 0.092250   val_loss: 0.010839   val_mae: 0.079594\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014081   mae: 0.092150   val_loss: 0.010767   val_mae: 0.079427\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013865   mae: 0.091351   val_loss: 0.012019   val_mae: 0.084227\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014126   mae: 0.092428   val_loss: 0.011053   val_mae: 0.081201\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014289   mae: 0.093090   val_loss: 0.010391   val_mae: 0.077354\n",
      "Total:\n",
      "\t \ttime: 0h 1m 12s   loss: 0.014116   mae: 0.092241   val_loss: 0.011019   val_mae: 0.080415\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013866   mae: 0.090955   val_loss: 0.010631   val_mae: 0.078625\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013888   mae: 0.091296   val_loss: 0.010625   val_mae: 0.079091\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013861   mae: 0.091165   val_loss: 0.010357   val_mae: 0.077193\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013688   mae: 0.090564   val_loss: 0.011616   val_mae: 0.082187\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013838   mae: 0.090991   val_loss: 0.010608   val_mae: 0.078603\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013867   mae: 0.091263   val_loss: 0.010073   val_mae: 0.075530\n",
      "Total:\n",
      "\t \ttime: 0h 1m 34s   loss: 0.013835   mae: 0.091039   val_loss: 0.010652   val_mae: 0.078538\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013833   mae: 0.091220   val_loss: 0.010624   val_mae: 0.078824\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013903   mae: 0.091680   val_loss: 0.010986   val_mae: 0.080747\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.014154   mae: 0.092532   val_loss: 0.010607   val_mae: 0.079150\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013577   mae: 0.090239   val_loss: 0.011469   val_mae: 0.081808\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013729   mae: 0.090695   val_loss: 0.010825   val_mae: 0.079573\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013869   mae: 0.091169   val_loss: 0.010077   val_mae: 0.076183\n",
      "Total:\n",
      "\t \ttime: 0h 1m 53s   loss: 0.013844   mae: 0.091256   val_loss: 0.010765   val_mae: 0.079381\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.015694   mae: 0.098151   val_loss: 0.011839   val_mae: 0.085242\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.016240   mae: 0.099990   val_loss: 0.012401   val_mae: 0.087854\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.017582   mae: 0.103423   val_loss: 0.012768   val_mae: 0.087535\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014916   mae: 0.095649   val_loss: 0.012478   val_mae: 0.086168\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.016214   mae: 0.100045   val_loss: 0.012527   val_mae: 0.088554\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.016380   mae: 0.101222   val_loss: 0.012059   val_mae: 0.085309\n",
      "Total:\n",
      "\t \ttime: 0h 0m 23s   loss: 0.016171   mae: 0.099747   val_loss: 0.012345   val_mae: 0.086777\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014793   mae: 0.094747   val_loss: 0.012008   val_mae: 0.084887\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014829   mae: 0.094813   val_loss: 0.011484   val_mae: 0.082775\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014269   mae: 0.092901   val_loss: 0.010671   val_mae: 0.079468\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014810   mae: 0.094628   val_loss: 0.012816   val_mae: 0.087569\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014850   mae: 0.095148   val_loss: 0.011494   val_mae: 0.083631\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014507   mae: 0.093671   val_loss: 0.010613   val_mae: 0.077996\n",
      "Total:\n",
      "\t \ttime: 0h 0m 33s   loss: 0.014676   mae: 0.094318   val_loss: 0.011514   val_mae: 0.082721\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013985   mae: 0.091570   val_loss: 0.010975   val_mae: 0.080544\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013917   mae: 0.091534   val_loss: 0.011111   val_mae: 0.081064\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014063   mae: 0.092044   val_loss: 0.010634   val_mae: 0.078647\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013895   mae: 0.091289   val_loss: 0.011916   val_mae: 0.083232\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014260   mae: 0.092635   val_loss: 0.011063   val_mae: 0.081160\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014217   mae: 0.092719   val_loss: 0.010189   val_mae: 0.076541\n",
      "Total:\n",
      "\t \ttime: 0h 0m 44s   loss: 0.014056   mae: 0.091965   val_loss: 0.010981   val_mae: 0.080198\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014127   mae: 0.092100   val_loss: 0.011009   val_mae: 0.080460\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014168   mae: 0.092475   val_loss: 0.010835   val_mae: 0.080389\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013893   mae: 0.091624   val_loss: 0.010627   val_mae: 0.078566\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013736   mae: 0.090675   val_loss: 0.012373   val_mae: 0.085886\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013989   mae: 0.091873   val_loss: 0.010756   val_mae: 0.080258\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.015423   mae: 0.099314   val_loss: 0.011572   val_mae: 0.085201\n",
      "Total:\n",
      "\t \ttime: 0h 0m 55s   loss: 0.014223   mae: 0.093010   val_loss: 0.011195   val_mae: 0.081793\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013816   mae: 0.090891   val_loss: 0.010947   val_mae: 0.079930\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013659   mae: 0.090336   val_loss: 0.010731   val_mae: 0.079407\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013949   mae: 0.091614   val_loss: 0.010294   val_mae: 0.077420\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013595   mae: 0.089969   val_loss: 0.011534   val_mae: 0.081864\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013724   mae: 0.090442   val_loss: 0.010396   val_mae: 0.077949\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013905   mae: 0.091687   val_loss: 0.010098   val_mae: 0.075385\n",
      "Total:\n",
      "\t \ttime: 0h 1m 5s   loss: 0.013774   mae: 0.090823   val_loss: 0.010667   val_mae: 0.078659\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014385   mae: 0.092741   val_loss: 0.010559   val_mae: 0.079173\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014254   mae: 0.092767   val_loss: 0.010837   val_mae: 0.079025\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014654   mae: 0.094081   val_loss: 0.010313   val_mae: 0.077178\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014278   mae: 0.092628   val_loss: 0.011606   val_mae: 0.082304\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014205   mae: 0.092145   val_loss: 0.011308   val_mae: 0.080424\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014461   mae: 0.093244   val_loss: 0.010199   val_mae: 0.076612\n",
      "Total:\n",
      "\t \ttime: 0h 0m 52s   loss: 0.014373   mae: 0.092934   val_loss: 0.010804   val_mae: 0.079119\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013969   mae: 0.091260   val_loss: 0.012080   val_mae: 0.085219\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014079   mae: 0.091918   val_loss: 0.010908   val_mae: 0.078963\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.014257   mae: 0.092527   val_loss: 0.012056   val_mae: 0.084955\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013927   mae: 0.090905   val_loss: 0.011574   val_mae: 0.081885\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.014072   mae: 0.091523   val_loss: 0.010778   val_mae: 0.078842\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014205   mae: 0.092297   val_loss: 0.011018   val_mae: 0.079235\n",
      "Total:\n",
      "\t \ttime: 0h 1m 31s   loss: 0.014085   mae: 0.091739   val_loss: 0.011402   val_mae: 0.081516\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.014014   mae: 0.091501   val_loss: 0.010435   val_mae: 0.077753\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.014037   mae: 0.091655   val_loss: 0.010594   val_mae: 0.077823\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.014232   mae: 0.092418   val_loss: 0.010443   val_mae: 0.076482\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013837   mae: 0.091056   val_loss: 0.011569   val_mae: 0.082580\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014154   mae: 0.091801   val_loss: 0.011545   val_mae: 0.083408\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.014111   mae: 0.092137   val_loss: 0.009965   val_mae: 0.074572\n",
      "Total:\n",
      "\t \ttime: 0h 2m 9s   loss: 0.014064   mae: 0.091761   val_loss: 0.010759   val_mae: 0.078769\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013801   mae: 0.090369   val_loss: 0.010455   val_mae: 0.078434\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.014005   mae: 0.091623   val_loss: 0.010476   val_mae: 0.077648\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013995   mae: 0.091518   val_loss: 0.010111   val_mae: 0.075456\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013792   mae: 0.090746   val_loss: 0.011440   val_mae: 0.081030\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.014029   mae: 0.091556   val_loss: 0.010387   val_mae: 0.077123\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013992   mae: 0.091715   val_loss: 0.010570   val_mae: 0.077551\n",
      "Total:\n",
      "\t \ttime: 0h 2m 51s   loss: 0.013936   mae: 0.091255   val_loss: 0.010573   val_mae: 0.077874\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013989   mae: 0.091340   val_loss: 0.010448   val_mae: 0.077741\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013842   mae: 0.090851   val_loss: 0.010797   val_mae: 0.078953\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.014061   mae: 0.091771   val_loss: 0.010409   val_mae: 0.077115\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013705   mae: 0.090533   val_loss: 0.011658   val_mae: 0.082069\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013890   mae: 0.090923   val_loss: 0.010874   val_mae: 0.080042\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.014038   mae: 0.091813   val_loss: 0.010194   val_mae: 0.076032\n",
      "Total:\n",
      "\t \ttime: 0h 3m 31s   loss: 0.013921   mae: 0.091205   val_loss: 0.010730   val_mae: 0.078659\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014209   mae: 0.092009   val_loss: 0.011095   val_mae: 0.081193\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014236   mae: 0.092453   val_loss: 0.010998   val_mae: 0.080271\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014149   mae: 0.092162   val_loss: 0.010448   val_mae: 0.077815\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014060   mae: 0.091686   val_loss: 0.012618   val_mae: 0.085797\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014434   mae: 0.093043   val_loss: 0.011249   val_mae: 0.082119\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014305   mae: 0.093048   val_loss: 0.010080   val_mae: 0.075966\n",
      "Total:\n",
      "\t \ttime: 0h 0m 31s   loss: 0.014232   mae: 0.092400   val_loss: 0.011082   val_mae: 0.080527\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014152   mae: 0.091915   val_loss: 0.010592   val_mae: 0.079288\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013903   mae: 0.091304   val_loss: 0.011061   val_mae: 0.080255\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014104   mae: 0.092110   val_loss: 0.012149   val_mae: 0.084409\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013812   mae: 0.090917   val_loss: 0.011475   val_mae: 0.081176\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014003   mae: 0.091532   val_loss: 0.010621   val_mae: 0.078868\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014245   mae: 0.092669   val_loss: 0.010199   val_mae: 0.076968\n",
      "Total:\n",
      "\t \ttime: 0h 0m 54s   loss: 0.014036   mae: 0.091741   val_loss: 0.011016   val_mae: 0.080161\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014058   mae: 0.091604   val_loss: 0.012391   val_mae: 0.085735\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014001   mae: 0.091673   val_loss: 0.010658   val_mae: 0.079397\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014148   mae: 0.092384   val_loss: 0.010439   val_mae: 0.077764\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013688   mae: 0.090433   val_loss: 0.011383   val_mae: 0.081008\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013938   mae: 0.091344   val_loss: 0.011202   val_mae: 0.081228\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014072   mae: 0.092111   val_loss: 0.010607   val_mae: 0.077748\n",
      "Total:\n",
      "\t \ttime: 0h 1m 11s   loss: 0.013984   mae: 0.091591   val_loss: 0.011113   val_mae: 0.080480\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013842   mae: 0.090836   val_loss: 0.011036   val_mae: 0.080116\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013777   mae: 0.090502   val_loss: 0.010623   val_mae: 0.078047\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013918   mae: 0.091224   val_loss: 0.010456   val_mae: 0.077805\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013633   mae: 0.090436   val_loss: 0.011332   val_mae: 0.080931\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013855   mae: 0.090904   val_loss: 0.010693   val_mae: 0.079115\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014088   mae: 0.092164   val_loss: 0.009857   val_mae: 0.074762\n",
      "Total:\n",
      "\t \ttime: 0h 1m 34s   loss: 0.013852   mae: 0.091011   val_loss: 0.010666   val_mae: 0.078463\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013753   mae: 0.090551   val_loss: 0.010493   val_mae: 0.077656\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013745   mae: 0.090520   val_loss: 0.010731   val_mae: 0.079455\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013978   mae: 0.091675   val_loss: 0.010147   val_mae: 0.076009\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013635   mae: 0.090124   val_loss: 0.011701   val_mae: 0.082721\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013796   mae: 0.090540   val_loss: 0.011366   val_mae: 0.081674\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.014028   mae: 0.091712   val_loss: 0.010123   val_mae: 0.075032\n",
      "Total:\n",
      "\t \ttime: 0h 1m 54s   loss: 0.013822   mae: 0.090854   val_loss: 0.010760   val_mae: 0.078758\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014258   mae: 0.092904   val_loss: 0.011102   val_mae: 0.080394\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014119   mae: 0.092200   val_loss: 0.011957   val_mae: 0.084230\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014355   mae: 0.092833   val_loss: 0.010556   val_mae: 0.077232\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.013950   mae: 0.091344   val_loss: 0.011386   val_mae: 0.081513\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014556   mae: 0.093351   val_loss: 0.011394   val_mae: 0.082297\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014523   mae: 0.093771   val_loss: 0.010657   val_mae: 0.079284\n",
      "Total:\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014293   mae: 0.092734   val_loss: 0.011175   val_mae: 0.080825\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013968   mae: 0.091203   val_loss: 0.010844   val_mae: 0.079593\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014065   mae: 0.092016   val_loss: 0.012090   val_mae: 0.084221\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014124   mae: 0.092103   val_loss: 0.010308   val_mae: 0.077095\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013689   mae: 0.090307   val_loss: 0.012050   val_mae: 0.083750\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014011   mae: 0.091564   val_loss: 0.010590   val_mae: 0.079183\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014074   mae: 0.092077   val_loss: 0.010161   val_mae: 0.076025\n",
      "Total:\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013989   mae: 0.091545   val_loss: 0.011007   val_mae: 0.079978\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013812   mae: 0.090814   val_loss: 0.010620   val_mae: 0.077980\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013826   mae: 0.090933   val_loss: 0.011309   val_mae: 0.081397\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013824   mae: 0.091050   val_loss: 0.010292   val_mae: 0.076202\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013523   mae: 0.089757   val_loss: 0.011561   val_mae: 0.081324\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014013   mae: 0.091350   val_loss: 0.010387   val_mae: 0.078173\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014140   mae: 0.091929   val_loss: 0.009945   val_mae: 0.075222\n",
      "Total:\n",
      "\t \ttime: 0h 0m 45s   loss: 0.013856   mae: 0.090972   val_loss: 0.010686   val_mae: 0.078383\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013886   mae: 0.091433   val_loss: 0.010973   val_mae: 0.079522\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013836   mae: 0.091034   val_loss: 0.010826   val_mae: 0.079419\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013821   mae: 0.091232   val_loss: 0.010132   val_mae: 0.075900\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013518   mae: 0.089976   val_loss: 0.011610   val_mae: 0.081642\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013693   mae: 0.090430   val_loss: 0.010362   val_mae: 0.077840\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014131   mae: 0.092117   val_loss: 0.009995   val_mae: 0.074963\n",
      "Total:\n",
      "\t \ttime: 0h 0m 54s   loss: 0.013814   mae: 0.091037   val_loss: 0.010650   val_mae: 0.078214\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013654   mae: 0.090360   val_loss: 0.010768   val_mae: 0.078882\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013874   mae: 0.091344   val_loss: 0.010900   val_mae: 0.079572\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013812   mae: 0.090929   val_loss: 0.010580   val_mae: 0.078596\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013589   mae: 0.089917   val_loss: 0.013229   val_mae: 0.089194\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013735   mae: 0.090711   val_loss: 0.010300   val_mae: 0.077747\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013730   mae: 0.090943   val_loss: 0.009884   val_mae: 0.075255\n",
      "Total:\n",
      "\t \ttime: 0h 1m 5s   loss: 0.013732   mae: 0.090700   val_loss: 0.010943   val_mae: 0.079874\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.039320   mae: 0.160641   val_loss: 0.035744   val_mae: 0.153349\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.030730   mae: 0.144036   val_loss: 0.026939   val_mae: 0.135801\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.032184   mae: 0.147060   val_loss: 0.029114   val_mae: 0.140724\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.038419   mae: 0.160409   val_loss: 0.034448   val_mae: 0.152484\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.026627   mae: 0.132722   val_loss: 0.021623   val_mae: 0.119318\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.029352   mae: 0.139699   val_loss: 0.025883   val_mae: 0.130653\n",
      "Total:\n",
      "\t \ttime: 0h 0m 56s   loss: 0.032772   mae: 0.147428   val_loss: 0.028959   val_mae: 0.138722\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.018658   mae: 0.108819   val_loss: 0.014841   val_mae: 0.096722\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.018710   mae: 0.109650   val_loss: 0.015270   val_mae: 0.099082\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.018832   mae: 0.109825   val_loss: 0.015349   val_mae: 0.099623\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.017556   mae: 0.104642   val_loss: 0.015178   val_mae: 0.097148\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.018466   mae: 0.107492   val_loss: 0.014468   val_mae: 0.094879\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.020175   mae: 0.112772   val_loss: 0.016597   val_mae: 0.100899\n",
      "Total:\n",
      "\t \ttime: 0h 1m 37s   loss: 0.018733   mae: 0.108867   val_loss: 0.015284   val_mae: 0.098059\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.017295   mae: 0.102809   val_loss: 0.013606   val_mae: 0.091139\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.016556   mae: 0.101632   val_loss: 0.014056   val_mae: 0.093883\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.016131   mae: 0.098984   val_loss: 0.012334   val_mae: 0.086494\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.016012   mae: 0.099360   val_loss: 0.013798   val_mae: 0.091784\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.017174   mae: 0.102240   val_loss: 0.013531   val_mae: 0.089732\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.017034   mae: 0.102255   val_loss: 0.012938   val_mae: 0.088266\n",
      "Total:\n",
      "\t \ttime: 0h 2m 17s   loss: 0.016700   mae: 0.101213   val_loss: 0.013377   val_mae: 0.090216\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.014886   mae: 0.095261   val_loss: 0.011651   val_mae: 0.084398\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.015536   mae: 0.097345   val_loss: 0.012965   val_mae: 0.088322\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.016689   mae: 0.101236   val_loss: 0.013081   val_mae: 0.088979\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.014998   mae: 0.095511   val_loss: 0.013207   val_mae: 0.089148\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.016660   mae: 0.101226   val_loss: 0.012976   val_mae: 0.089054\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.018967   mae: 0.107245   val_loss: 0.014881   val_mae: 0.093764\n",
      "Total:\n",
      "\t \ttime: 0h 3m 3s   loss: 0.016289   mae: 0.099637   val_loss: 0.013127   val_mae: 0.088944\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.015572   mae: 0.096935   val_loss: 0.012134   val_mae: 0.086120\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.016280   mae: 0.101688   val_loss: 0.013199   val_mae: 0.091645\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.015501   mae: 0.097490   val_loss: 0.011997   val_mae: 0.085430\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.014777   mae: 0.094905   val_loss: 0.012863   val_mae: 0.088211\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.015901   mae: 0.098763   val_loss: 0.012378   val_mae: 0.086645\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.015489   mae: 0.097082   val_loss: 0.011890   val_mae: 0.083678\n",
      "Total:\n",
      "\t \ttime: 0h 3m 47s   loss: 0.015586   mae: 0.097811   val_loss: 0.012410   val_mae: 0.086955\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.044492   mae: 0.173697   val_loss: 0.040941   val_mae: 0.167816\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.039953   mae: 0.162024   val_loss: 0.037055   val_mae: 0.156818\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.025467   mae: 0.130693   val_loss: 0.021071   val_mae: 0.118998\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.032003   mae: 0.146512   val_loss: 0.026474   val_mae: 0.133337\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.033111   mae: 0.149209   val_loss: 0.028693   val_mae: 0.139621\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.029076   mae: 0.138922   val_loss: 0.025428   val_mae: 0.129969\n",
      "Total:\n",
      "\t \ttime: 0h 0m 37s   loss: 0.034017   mae: 0.150176   val_loss: 0.029944   val_mae: 0.141093\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.037671   mae: 0.158942   val_loss: 0.034147   val_mae: 0.152396\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.026143   mae: 0.130559   val_loss: 0.022910   val_mae: 0.122231\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.042089   mae: 0.165459   val_loss: 0.042333   val_mae: 0.166578\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.021162   mae: 0.117420   val_loss: 0.017964   val_mae: 0.108252\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.026089   mae: 0.131386   val_loss: 0.022256   val_mae: 0.121396\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.031750   mae: 0.145573   val_loss: 0.027995   val_mae: 0.136529\n",
      "Total:\n",
      "\t \ttime: 0h 0m 58s   loss: 0.030817   mae: 0.141557   val_loss: 0.027934   val_mae: 0.134564\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.018421   mae: 0.107131   val_loss: 0.014835   val_mae: 0.096328\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.020280   mae: 0.112845   val_loss: 0.017088   val_mae: 0.104016\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.021956   mae: 0.117818   val_loss: 0.017622   val_mae: 0.105589\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.026682   mae: 0.131252   val_loss: 0.023815   val_mae: 0.125521\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.034976   mae: 0.149807   val_loss: 0.032936   val_mae: 0.144386\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.021624   mae: 0.116885   val_loss: 0.017583   val_mae: 0.105288\n",
      "Total:\n",
      "\t \ttime: 0h 1m 18s   loss: 0.023990   mae: 0.122623   val_loss: 0.020646   val_mae: 0.113521\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.016004   mae: 0.099257   val_loss: 0.012774   val_mae: 0.088385\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.016899   mae: 0.102387   val_loss: 0.014001   val_mae: 0.093638\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.019483   mae: 0.109728   val_loss: 0.016060   val_mae: 0.099757\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.016018   mae: 0.099108   val_loss: 0.014106   val_mae: 0.093065\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.017036   mae: 0.102087   val_loss: 0.013369   val_mae: 0.089707\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.015877   mae: 0.099170   val_loss: 0.011948   val_mae: 0.085119\n",
      "Total:\n",
      "\t \ttime: 0h 1m 41s   loss: 0.016886   mae: 0.101956   val_loss: 0.013709   val_mae: 0.091612\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.018073   mae: 0.104205   val_loss: 0.014160   val_mae: 0.092502\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.015175   mae: 0.095758   val_loss: 0.011887   val_mae: 0.084066\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.017291   mae: 0.102991   val_loss: 0.013420   val_mae: 0.089812\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.016697   mae: 0.100041   val_loss: 0.013629   val_mae: 0.089580\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.017754   mae: 0.105745   val_loss: 0.014294   val_mae: 0.094547\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.017141   mae: 0.102447   val_loss: 0.013101   val_mae: 0.088804\n",
      "Total:\n",
      "\t \ttime: 0h 2m 4s   loss: 0.017022   mae: 0.101864   val_loss: 0.013415   val_mae: 0.089885\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.043017   mae: 0.171558   val_loss: 0.039956   val_mae: 0.167148\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.042659   mae: 0.170102   val_loss: 0.040612   val_mae: 0.166897\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.038743   mae: 0.162862   val_loss: 0.036674   val_mae: 0.160571\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.046816   mae: 0.174078   val_loss: 0.043137   val_mae: 0.168577\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.043855   mae: 0.173065   val_loss: 0.040849   val_mae: 0.169256\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.040150   mae: 0.164191   val_loss: 0.036266   val_mae: 0.156594\n",
      "Total:\n",
      "\t \ttime: 0h 0m 26s   loss: 0.042540   mae: 0.169309   val_loss: 0.039582   val_mae: 0.164840\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.035906   mae: 0.155513   val_loss: 0.031277   val_mae: 0.146273\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.036360   mae: 0.156669   val_loss: 0.034320   val_mae: 0.153242\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.030925   mae: 0.144634   val_loss: 0.027627   val_mae: 0.137207\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.027065   mae: 0.134040   val_loss: 0.023690   val_mae: 0.125128\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.037219   mae: 0.158241   val_loss: 0.031357   val_mae: 0.146922\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.037481   mae: 0.159292   val_loss: 0.034094   val_mae: 0.152295\n",
      "Total:\n",
      "\t \ttime: 0h 0m 37s   loss: 0.034159   mae: 0.151398   val_loss: 0.030394   val_mae: 0.143511\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.029059   mae: 0.137807   val_loss: 0.024728   val_mae: 0.128076\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.024472   mae: 0.127080   val_loss: 0.020433   val_mae: 0.116896\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.034418   mae: 0.152114   val_loss: 0.031301   val_mae: 0.146314\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.047049   mae: 0.175618   val_loss: 0.044651   val_mae: 0.172257\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.021056   mae: 0.116898   val_loss: 0.016915   val_mae: 0.105043\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.025458   mae: 0.129828   val_loss: 0.021574   val_mae: 0.119890\n",
      "Total:\n",
      "\t \ttime: 0h 0m 47s   loss: 0.030252   mae: 0.139891   val_loss: 0.026600   val_mae: 0.131413\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.023857   mae: 0.123648   val_loss: 0.020907   val_mae: 0.115855\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.016602   mae: 0.101343   val_loss: 0.013684   val_mae: 0.092866\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.020383   mae: 0.112471   val_loss: 0.016868   val_mae: 0.102824\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.022740   mae: 0.120585   val_loss: 0.019997   val_mae: 0.113408\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.028330   mae: 0.138000   val_loss: 0.023928   val_mae: 0.127716\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.022794   mae: 0.121014   val_loss: 0.019349   val_mae: 0.111053\n",
      "Total:\n",
      "\t \ttime: 0h 1m 0s   loss: 0.022451   mae: 0.119510   val_loss: 0.019122   val_mae: 0.110620\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.015678   mae: 0.098097   val_loss: 0.012886   val_mae: 0.088725\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.024360   mae: 0.125031   val_loss: 0.022335   val_mae: 0.121359\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.025440   mae: 0.129460   val_loss: 0.022036   val_mae: 0.121349\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.020082   mae: 0.112903   val_loss: 0.017130   val_mae: 0.104719\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.019667   mae: 0.113361   val_loss: 0.015646   val_mae: 0.101926\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.021891   mae: 0.118341   val_loss: 0.018228   val_mae: 0.107596\n",
      "Total:\n",
      "\t \ttime: 0h 1m 11s   loss: 0.021186   mae: 0.116199   val_loss: 0.018043   val_mae: 0.107612\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014595   mae: 0.093578   val_loss: 0.011378   val_mae: 0.082562\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014941   mae: 0.095052   val_loss: 0.011472   val_mae: 0.082569\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014820   mae: 0.095157   val_loss: 0.011948   val_mae: 0.084392\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014069   mae: 0.091901   val_loss: 0.011885   val_mae: 0.083337\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014315   mae: 0.092957   val_loss: 0.011026   val_mae: 0.080624\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.015357   mae: 0.096986   val_loss: 0.011728   val_mae: 0.083216\n",
      "Total:\n",
      "\t \ttime: 0h 0m 55s   loss: 0.014683   mae: 0.094272   val_loss: 0.011573   val_mae: 0.082783\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014164   mae: 0.092275   val_loss: 0.011104   val_mae: 0.080820\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014266   mae: 0.092510   val_loss: 0.011121   val_mae: 0.080875\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014245   mae: 0.092816   val_loss: 0.010575   val_mae: 0.078505\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014126   mae: 0.092367   val_loss: 0.012158   val_mae: 0.084900\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014081   mae: 0.091870   val_loss: 0.010815   val_mae: 0.079362\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014411   mae: 0.093446   val_loss: 0.010457   val_mae: 0.077869\n",
      "Total:\n",
      "\t \ttime: 0h 1m 37s   loss: 0.014216   mae: 0.092548   val_loss: 0.011038   val_mae: 0.080389\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014222   mae: 0.092474   val_loss: 0.011126   val_mae: 0.081138\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014189   mae: 0.093666   val_loss: 0.011254   val_mae: 0.083393\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014046   mae: 0.091850   val_loss: 0.010680   val_mae: 0.078587\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013739   mae: 0.090740   val_loss: 0.011879   val_mae: 0.083050\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013893   mae: 0.091106   val_loss: 0.011109   val_mae: 0.080778\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.014005   mae: 0.091839   val_loss: 0.010100   val_mae: 0.076169\n",
      "Total:\n",
      "\t \ttime: 0h 2m 18s   loss: 0.014016   mae: 0.091946   val_loss: 0.011025   val_mae: 0.080519\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.014014   mae: 0.092448   val_loss: 0.010756   val_mae: 0.080292\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013810   mae: 0.091115   val_loss: 0.010662   val_mae: 0.078522\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013862   mae: 0.091175   val_loss: 0.010766   val_mae: 0.079098\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.013674   mae: 0.090690   val_loss: 0.011713   val_mae: 0.082642\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013772   mae: 0.090724   val_loss: 0.010677   val_mae: 0.079067\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013925   mae: 0.091557   val_loss: 0.010004   val_mae: 0.075602\n",
      "Total:\n",
      "\t \ttime: 0h 3m 2s   loss: 0.013843   mae: 0.091285   val_loss: 0.010763   val_mae: 0.079204\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013699   mae: 0.090708   val_loss: 0.010543   val_mae: 0.078629\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013715   mae: 0.090643   val_loss: 0.010918   val_mae: 0.079846\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013921   mae: 0.091589   val_loss: 0.010562   val_mae: 0.078463\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013334   mae: 0.089319   val_loss: 0.011543   val_mae: 0.082018\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013822   mae: 0.091058   val_loss: 0.010659   val_mae: 0.078924\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013908   mae: 0.091395   val_loss: 0.010110   val_mae: 0.075568\n",
      "Total:\n",
      "\t \ttime: 0h 3m 42s   loss: 0.013733   mae: 0.090785   val_loss: 0.010722   val_mae: 0.078908\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.015126   mae: 0.095388   val_loss: 0.012156   val_mae: 0.085140\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.015050   mae: 0.095107   val_loss: 0.011812   val_mae: 0.084070\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.015104   mae: 0.096573   val_loss: 0.011026   val_mae: 0.081703\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.015253   mae: 0.096500   val_loss: 0.012670   val_mae: 0.087220\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014761   mae: 0.094965   val_loss: 0.011343   val_mae: 0.082527\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.019808   mae: 0.113918   val_loss: 0.014994   val_mae: 0.097002\n",
      "Total:\n",
      "\t \ttime: 0h 0m 36s   loss: 0.015850   mae: 0.098742   val_loss: 0.012334   val_mae: 0.086277\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014620   mae: 0.094008   val_loss: 0.011411   val_mae: 0.082877\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014489   mae: 0.093648   val_loss: 0.011773   val_mae: 0.083373\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014224   mae: 0.092963   val_loss: 0.010912   val_mae: 0.079641\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013606   mae: 0.090107   val_loss: 0.011429   val_mae: 0.081554\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013911   mae: 0.091320   val_loss: 0.010811   val_mae: 0.079575\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014210   mae: 0.092646   val_loss: 0.010610   val_mae: 0.078293\n",
      "Total:\n",
      "\t \ttime: 0h 0m 57s   loss: 0.014177   mae: 0.092449   val_loss: 0.011158   val_mae: 0.080886\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013981   mae: 0.091435   val_loss: 0.010558   val_mae: 0.078562\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.014121   mae: 0.092437   val_loss: 0.011098   val_mae: 0.081249\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014168   mae: 0.092307   val_loss: 0.010721   val_mae: 0.079002\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013748   mae: 0.090894   val_loss: 0.011680   val_mae: 0.082327\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013826   mae: 0.091414   val_loss: 0.010501   val_mae: 0.078593\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014134   mae: 0.092440   val_loss: 0.010243   val_mae: 0.076869\n",
      "Total:\n",
      "\t \ttime: 0h 1m 17s   loss: 0.013996   mae: 0.091821   val_loss: 0.010800   val_mae: 0.079434\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013828   mae: 0.090856   val_loss: 0.010628   val_mae: 0.078879\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013836   mae: 0.091118   val_loss: 0.010803   val_mae: 0.079827\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013927   mae: 0.091442   val_loss: 0.010319   val_mae: 0.077196\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013749   mae: 0.091047   val_loss: 0.011539   val_mae: 0.081372\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014001   mae: 0.091808   val_loss: 0.010836   val_mae: 0.079717\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014014   mae: 0.092147   val_loss: 0.010080   val_mae: 0.076386\n",
      "Total:\n",
      "\t \ttime: 0h 1m 41s   loss: 0.013892   mae: 0.091403   val_loss: 0.010701   val_mae: 0.078896\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013818   mae: 0.090891   val_loss: 0.011210   val_mae: 0.080951\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013676   mae: 0.090354   val_loss: 0.010687   val_mae: 0.078998\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013896   mae: 0.092368   val_loss: 0.010715   val_mae: 0.080180\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013597   mae: 0.090079   val_loss: 0.011550   val_mae: 0.081624\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013719   mae: 0.090552   val_loss: 0.010646   val_mae: 0.078905\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013857   mae: 0.091400   val_loss: 0.010133   val_mae: 0.076126\n",
      "Total:\n",
      "\t \ttime: 0h 2m 1s   loss: 0.013760   mae: 0.090941   val_loss: 0.010823   val_mae: 0.079464\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014881   mae: 0.095113   val_loss: 0.011694   val_mae: 0.084089\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.016678   mae: 0.100710   val_loss: 0.012687   val_mae: 0.087872\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.015268   mae: 0.096510   val_loss: 0.011276   val_mae: 0.082096\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014408   mae: 0.093258   val_loss: 0.012517   val_mae: 0.086083\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.018539   mae: 0.105274   val_loss: 0.014248   val_mae: 0.091505\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.015869   mae: 0.098523   val_loss: 0.011841   val_mae: 0.083863\n",
      "Total:\n",
      "\t \ttime: 0h 0m 26s   loss: 0.015941   mae: 0.098231   val_loss: 0.012377   val_mae: 0.085918\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014774   mae: 0.094019   val_loss: 0.011445   val_mae: 0.082151\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014677   mae: 0.094269   val_loss: 0.011562   val_mae: 0.083391\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014234   mae: 0.092867   val_loss: 0.010568   val_mae: 0.078504\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014007   mae: 0.092128   val_loss: 0.011728   val_mae: 0.082674\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014390   mae: 0.093176   val_loss: 0.011256   val_mae: 0.082026\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014269   mae: 0.093304   val_loss: 0.010408   val_mae: 0.077344\n",
      "Total:\n",
      "\t \ttime: 0h 0m 38s   loss: 0.014392   mae: 0.093294   val_loss: 0.011161   val_mae: 0.081015\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013956   mae: 0.091651   val_loss: 0.010845   val_mae: 0.079844\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014933   mae: 0.095456   val_loss: 0.011615   val_mae: 0.083596\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014185   mae: 0.092608   val_loss: 0.010571   val_mae: 0.078414\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.015824   mae: 0.100752   val_loss: 0.013693   val_mae: 0.092513\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014493   mae: 0.093542   val_loss: 0.011515   val_mae: 0.083089\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014210   mae: 0.092358   val_loss: 0.010231   val_mae: 0.076127\n",
      "Total:\n",
      "\t \ttime: 0h 0m 48s   loss: 0.014600   mae: 0.094394   val_loss: 0.011412   val_mae: 0.082264\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014072   mae: 0.092501   val_loss: 0.010883   val_mae: 0.080683\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014704   mae: 0.096455   val_loss: 0.011690   val_mae: 0.085327\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013937   mae: 0.091628   val_loss: 0.010359   val_mae: 0.077536\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013976   mae: 0.091882   val_loss: 0.011891   val_mae: 0.083870\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013955   mae: 0.091482   val_loss: 0.010832   val_mae: 0.079779\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014087   mae: 0.091778   val_loss: 0.010452   val_mae: 0.077824\n",
      "Total:\n",
      "\t \ttime: 0h 1m 1s   loss: 0.014122   mae: 0.092621   val_loss: 0.011018   val_mae: 0.080837\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014924   mae: 0.095018   val_loss: 0.012218   val_mae: 0.085599\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013656   mae: 0.090527   val_loss: 0.010578   val_mae: 0.078869\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013848   mae: 0.091304   val_loss: 0.010385   val_mae: 0.077352\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014205   mae: 0.094417   val_loss: 0.012136   val_mae: 0.085996\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013705   mae: 0.090520   val_loss: 0.010511   val_mae: 0.079027\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013933   mae: 0.091618   val_loss: 0.009968   val_mae: 0.075568\n",
      "Total:\n",
      "\t \ttime: 0h 1m 10s   loss: 0.014045   mae: 0.092234   val_loss: 0.010966   val_mae: 0.080402\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014304   mae: 0.092414   val_loss: 0.011119   val_mae: 0.082116\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014407   mae: 0.092929   val_loss: 0.010891   val_mae: 0.078613\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014886   mae: 0.095393   val_loss: 0.011532   val_mae: 0.083008\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014331   mae: 0.092961   val_loss: 0.012381   val_mae: 0.084980\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014382   mae: 0.093127   val_loss: 0.010666   val_mae: 0.078222\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014465   mae: 0.093435   val_loss: 0.010115   val_mae: 0.076627\n",
      "Total:\n",
      "\t \ttime: 0h 0m 58s   loss: 0.014462   mae: 0.093376   val_loss: 0.011117   val_mae: 0.080594\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014188   mae: 0.092297   val_loss: 0.010750   val_mae: 0.078818\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014247   mae: 0.092342   val_loss: 0.010790   val_mae: 0.079164\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.014677   mae: 0.094105   val_loss: 0.010491   val_mae: 0.077808\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013961   mae: 0.091356   val_loss: 0.012557   val_mae: 0.085933\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014167   mae: 0.092094   val_loss: 0.010704   val_mae: 0.078607\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014301   mae: 0.092978   val_loss: 0.010346   val_mae: 0.076453\n",
      "Total:\n",
      "\t \ttime: 0h 1m 41s   loss: 0.014257   mae: 0.092529   val_loss: 0.010940   val_mae: 0.079464\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014016   mae: 0.091682   val_loss: 0.011004   val_mae: 0.080232\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013951   mae: 0.091196   val_loss: 0.012107   val_mae: 0.084433\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014157   mae: 0.092192   val_loss: 0.010171   val_mae: 0.076187\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013930   mae: 0.091356   val_loss: 0.011736   val_mae: 0.082100\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014016   mae: 0.091831   val_loss: 0.010802   val_mae: 0.078656\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014222   mae: 0.092472   val_loss: 0.010251   val_mae: 0.076437\n",
      "Total:\n",
      "\t \ttime: 0h 2m 19s   loss: 0.014049   mae: 0.091788   val_loss: 0.011012   val_mae: 0.079674\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.014150   mae: 0.092326   val_loss: 0.010522   val_mae: 0.078808\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013842   mae: 0.091011   val_loss: 0.010581   val_mae: 0.078626\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013991   mae: 0.091886   val_loss: 0.010383   val_mae: 0.077825\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.013806   mae: 0.090945   val_loss: 0.011717   val_mae: 0.082518\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.014035   mae: 0.091608   val_loss: 0.010586   val_mae: 0.077973\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.014020   mae: 0.091881   val_loss: 0.010625   val_mae: 0.079016\n",
      "Total:\n",
      "\t \ttime: 0h 2m 59s   loss: 0.013974   mae: 0.091610   val_loss: 0.010736   val_mae: 0.079128\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013869   mae: 0.091173   val_loss: 0.010566   val_mae: 0.078647\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013906   mae: 0.091377   val_loss: 0.010789   val_mae: 0.079227\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.014032   mae: 0.091823   val_loss: 0.010987   val_mae: 0.079922\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013926   mae: 0.091688   val_loss: 0.011523   val_mae: 0.082315\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013901   mae: 0.091209   val_loss: 0.011775   val_mae: 0.082943\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.014034   mae: 0.091818   val_loss: 0.010175   val_mae: 0.075477\n",
      "Total:\n",
      "\t \ttime: 0h 3m 43s   loss: 0.013945   mae: 0.091515   val_loss: 0.010969   val_mae: 0.079755\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014452   mae: 0.093006   val_loss: 0.010899   val_mae: 0.080762\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014176   mae: 0.092510   val_loss: 0.010862   val_mae: 0.080140\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014370   mae: 0.093085   val_loss: 0.010361   val_mae: 0.078090\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014408   mae: 0.093725   val_loss: 0.014026   val_mae: 0.090386\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014302   mae: 0.092803   val_loss: 0.010990   val_mae: 0.080439\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014495   mae: 0.093660   val_loss: 0.010332   val_mae: 0.077189\n",
      "Total:\n",
      "\t \ttime: 0h 0m 38s   loss: 0.014367   mae: 0.093132   val_loss: 0.011245   val_mae: 0.081168\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014048   mae: 0.091610   val_loss: 0.010665   val_mae: 0.079325\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014047   mae: 0.091613   val_loss: 0.010655   val_mae: 0.078949\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014135   mae: 0.092074   val_loss: 0.010575   val_mae: 0.078485\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013731   mae: 0.090661   val_loss: 0.011588   val_mae: 0.081266\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014106   mae: 0.091766   val_loss: 0.011283   val_mae: 0.081320\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014179   mae: 0.092391   val_loss: 0.010606   val_mae: 0.078385\n",
      "Total:\n",
      "\t \ttime: 0h 0m 59s   loss: 0.014041   mae: 0.091686   val_loss: 0.010896   val_mae: 0.079622\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013859   mae: 0.090839   val_loss: 0.010537   val_mae: 0.078026\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013933   mae: 0.091420   val_loss: 0.011209   val_mae: 0.081241\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.014182   mae: 0.092417   val_loss: 0.010614   val_mae: 0.078735\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013867   mae: 0.091103   val_loss: 0.012644   val_mae: 0.086276\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014032   mae: 0.091532   val_loss: 0.011358   val_mae: 0.082102\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013991   mae: 0.091648   val_loss: 0.010509   val_mae: 0.076577\n",
      "Total:\n",
      "\t \ttime: 0h 1m 19s   loss: 0.013978   mae: 0.091493   val_loss: 0.011145   val_mae: 0.080493\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013911   mae: 0.091164   val_loss: 0.010750   val_mae: 0.078817\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013901   mae: 0.090898   val_loss: 0.011074   val_mae: 0.079858\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013931   mae: 0.091583   val_loss: 0.010603   val_mae: 0.077816\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013818   mae: 0.090842   val_loss: 0.011634   val_mae: 0.081473\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013860   mae: 0.090924   val_loss: 0.010736   val_mae: 0.080236\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014077   mae: 0.092177   val_loss: 0.010086   val_mae: 0.075456\n",
      "Total:\n",
      "\t \ttime: 0h 1m 39s   loss: 0.013916   mae: 0.091265   val_loss: 0.010814   val_mae: 0.078943\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013871   mae: 0.090908   val_loss: 0.010536   val_mae: 0.077541\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013675   mae: 0.090551   val_loss: 0.011791   val_mae: 0.083249\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.014135   mae: 0.092469   val_loss: 0.010492   val_mae: 0.077895\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013749   mae: 0.090575   val_loss: 0.011907   val_mae: 0.083059\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013792   mae: 0.090717   val_loss: 0.010358   val_mae: 0.077946\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.014001   mae: 0.091705   val_loss: 0.009981   val_mae: 0.075309\n",
      "Total:\n",
      "\t \ttime: 0h 2m 2s   loss: 0.013870   mae: 0.091154   val_loss: 0.010844   val_mae: 0.079166\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014833   mae: 0.094488   val_loss: 0.011655   val_mae: 0.083438\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014574   mae: 0.093638   val_loss: 0.010995   val_mae: 0.080665\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014599   mae: 0.093987   val_loss: 0.010226   val_mae: 0.076716\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014141   mae: 0.091984   val_loss: 0.013004   val_mae: 0.087463\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014510   mae: 0.093321   val_loss: 0.011199   val_mae: 0.081673\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014346   mae: 0.093028   val_loss: 0.010515   val_mae: 0.078051\n",
      "Total:\n",
      "\t \ttime: 0h 0m 26s   loss: 0.014500   mae: 0.093408   val_loss: 0.011266   val_mae: 0.081334\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013922   mae: 0.091299   val_loss: 0.010626   val_mae: 0.078175\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014086   mae: 0.091900   val_loss: 0.011355   val_mae: 0.081359\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014380   mae: 0.093899   val_loss: 0.010871   val_mae: 0.080228\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013823   mae: 0.090889   val_loss: 0.012587   val_mae: 0.085871\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014168   mae: 0.092193   val_loss: 0.010345   val_mae: 0.078150\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014142   mae: 0.092467   val_loss: 0.010559   val_mae: 0.077683\n",
      "Total:\n",
      "\t \ttime: 0h 0m 37s   loss: 0.014087   mae: 0.092108   val_loss: 0.011057   val_mae: 0.080244\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014007   mae: 0.091616   val_loss: 0.010653   val_mae: 0.078126\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013907   mae: 0.091131   val_loss: 0.011226   val_mae: 0.080756\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014020   mae: 0.091785   val_loss: 0.010150   val_mae: 0.075845\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.052254   mae: 0.189886   val_loss: 0.049281   val_mae: 0.186043\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013843   mae: 0.090992   val_loss: 0.010592   val_mae: 0.078771\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014047   mae: 0.091970   val_loss: 0.010679   val_mae: 0.078543\n",
      "Total:\n",
      "\t \ttime: 0h 0m 48s   loss: 0.020347   mae: 0.107897   val_loss: 0.017097   val_mae: 0.096347\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013882   mae: 0.090962   val_loss: 0.010586   val_mae: 0.078397\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013935   mae: 0.091228   val_loss: 0.011393   val_mae: 0.082149\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013849   mae: 0.091048   val_loss: 0.010131   val_mae: 0.075964\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013875   mae: 0.090781   val_loss: 0.011843   val_mae: 0.082408\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013792   mae: 0.090749   val_loss: 0.010222   val_mae: 0.077406\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013930   mae: 0.091440   val_loss: 0.009936   val_mae: 0.074729\n",
      "Total:\n",
      "\t \ttime: 0h 0m 59s   loss: 0.013877   mae: 0.091035   val_loss: 0.010685   val_mae: 0.078509\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013979   mae: 0.091382   val_loss: 0.010725   val_mae: 0.078561\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013953   mae: 0.091654   val_loss: 0.012486   val_mae: 0.086416\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013855   mae: 0.091389   val_loss: 0.010496   val_mae: 0.077551\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013556   mae: 0.090183   val_loss: 0.011306   val_mae: 0.080606\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013864   mae: 0.090802   val_loss: 0.010481   val_mae: 0.078433\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013923   mae: 0.091392   val_loss: 0.009953   val_mae: 0.074612\n",
      "Total:\n",
      "\t \ttime: 0h 1m 10s   loss: 0.013855   mae: 0.091133   val_loss: 0.010908   val_mae: 0.079363\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.044939   mae: 0.170073   val_loss: 0.042355   val_mae: 0.166611\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.025712   mae: 0.127967   val_loss: 0.021858   val_mae: 0.117580\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.024857   mae: 0.126615   val_loss: 0.020977   val_mae: 0.116286\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.040538   mae: 0.159479   val_loss: 0.038272   val_mae: 0.155171\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.032127   mae: 0.146816   val_loss: 0.027494   val_mae: 0.136419\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.032726   mae: 0.149697   val_loss: 0.028194   val_mae: 0.139119\n",
      "Total:\n",
      "\t \ttime: 0h 1m 4s   loss: 0.033483   mae: 0.146774   val_loss: 0.029859   val_mae: 0.138531\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.032697   mae: 0.144610   val_loss: 0.029454   val_mae: 0.137364\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.042232   mae: 0.167393   val_loss: 0.039915   val_mae: 0.162893\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.021775   mae: 0.116668   val_loss: 0.018037   val_mae: 0.106082\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.021801   mae: 0.117822   val_loss: 0.018630   val_mae: 0.108547\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.024382   mae: 0.125940   val_loss: 0.019593   val_mae: 0.112875\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.035598   mae: 0.152980   val_loss: 0.032630   val_mae: 0.145453\n",
      "Total:\n",
      "\t \ttime: 0h 1m 46s   loss: 0.029748   mae: 0.137569   val_loss: 0.026377   val_mae: 0.128869\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.017981   mae: 0.104993   val_loss: 0.014389   val_mae: 0.094498\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.052074   mae: 0.189472   val_loss: 0.050664   val_mae: 0.187183\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.024796   mae: 0.126508   val_loss: 0.022094   val_mae: 0.118090\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 25s   loss: 0.017877   mae: 0.104253   val_loss: 0.015145   val_mae: 0.094924\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.018368   mae: 0.105919   val_loss: 0.014320   val_mae: 0.092843\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.020146   mae: 0.113143   val_loss: 0.016163   val_mae: 0.100823\n",
      "Total:\n",
      "\t \ttime: 0h 2m 27s   loss: 0.025207   mae: 0.124048   val_loss: 0.022129   val_mae: 0.114727\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.022179   mae: 0.120052   val_loss: 0.018348   val_mae: 0.108710\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.051403   mae: 0.188573   val_loss: 0.050000   val_mae: 0.186287\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.051660   mae: 0.188493   val_loss: 0.052286   val_mae: 0.190828\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.014972   mae: 0.095784   val_loss: 0.012758   val_mae: 0.087593\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.019693   mae: 0.111049   val_loss: 0.015860   val_mae: 0.098662\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.017874   mae: 0.107753   val_loss: 0.013758   val_mae: 0.093369\n",
      "Total:\n",
      "\t \ttime: 0h 3m 11s   loss: 0.029630   mae: 0.135284   val_loss: 0.027168   val_mae: 0.127575\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 40s   loss: 0.014274   mae: 0.092928   val_loss: 0.011085   val_mae: 0.081206\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 41s   loss: 0.020891   mae: 0.110800   val_loss: 0.016235   val_mae: 0.097320\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.015514   mae: 0.096941   val_loss: 0.011713   val_mae: 0.083500\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.017537   mae: 0.102371   val_loss: 0.014620   val_mae: 0.092932\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.014669   mae: 0.094192   val_loss: 0.011576   val_mae: 0.082896\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.015665   mae: 0.097605   val_loss: 0.011970   val_mae: 0.084099\n",
      "Total:\n",
      "\t \ttime: 0h 3m 58s   loss: 0.016425   mae: 0.099140   val_loss: 0.012866   val_mae: 0.086992\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.040134   mae: 0.166104   val_loss: 0.036523   val_mae: 0.159791\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.049229   mae: 0.177778   val_loss: 0.047529   val_mae: 0.174318\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.036862   mae: 0.159120   val_loss: 0.033805   val_mae: 0.153373\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.028866   mae: 0.136738   val_loss: 0.024672   val_mae: 0.126037\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.049204   mae: 0.178296   val_loss: 0.047816   val_mae: 0.176264\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.043600   mae: 0.168978   val_loss: 0.040096   val_mae: 0.162411\n",
      "Total:\n",
      "\t \ttime: 0h 0m 46s   loss: 0.041316   mae: 0.164502   val_loss: 0.038407   val_mae: 0.158699\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.023707   mae: 0.121846   val_loss: 0.020088   val_mae: 0.112236\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.021172   mae: 0.117778   val_loss: 0.017186   val_mae: 0.107058\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.026493   mae: 0.132000   val_loss: 0.022534   val_mae: 0.122138\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.024319   mae: 0.124633   val_loss: 0.020996   val_mae: 0.115710\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.023438   mae: 0.122272   val_loss: 0.018902   val_mae: 0.109790\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.027434   mae: 0.133619   val_loss: 0.023802   val_mae: 0.123757\n",
      "Total:\n",
      "\t \ttime: 0h 1m 7s   loss: 0.024427   mae: 0.125358   val_loss: 0.020585   val_mae: 0.115115\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.036181   mae: 0.152962   val_loss: 0.033629   val_mae: 0.148184\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.021642   mae: 0.117612   val_loss: 0.018031   val_mae: 0.108239\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.020684   mae: 0.113283   val_loss: 0.017011   val_mae: 0.102601\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.022900   mae: 0.122053   val_loss: 0.019706   val_mae: 0.113634\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.031717   mae: 0.147280   val_loss: 0.026464   val_mae: 0.134483\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.052305   mae: 0.189579   val_loss: 0.049581   val_mae: 0.185557\n",
      "Total:\n",
      "\t \ttime: 0h 1m 30s   loss: 0.030905   mae: 0.140461   val_loss: 0.027404   val_mae: 0.132116\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.029761   mae: 0.137551   val_loss: 0.027152   val_mae: 0.131420\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.033252   mae: 0.147289   val_loss: 0.031692   val_mae: 0.143748\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.029653   mae: 0.138298   val_loss: 0.028307   val_mae: 0.134464\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.019770   mae: 0.111402   val_loss: 0.016953   val_mae: 0.103255\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.027904   mae: 0.133308   val_loss: 0.025660   val_mae: 0.127403\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.018503   mae: 0.107316   val_loss: 0.014682   val_mae: 0.095577\n",
      "Total:\n",
      "\t \ttime: 0h 1m 50s   loss: 0.026474   mae: 0.129194   val_loss: 0.024075   val_mae: 0.122644\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.029833   mae: 0.140041   val_loss: 0.026622   val_mae: 0.133098\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.015781   mae: 0.098303   val_loss: 0.013236   val_mae: 0.089150\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.016405   mae: 0.099736   val_loss: 0.012624   val_mae: 0.086445\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.032067   mae: 0.143854   val_loss: 0.028349   val_mae: 0.134967\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.025754   mae: 0.128552   val_loss: 0.023027   val_mae: 0.120492\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.025566   mae: 0.128325   val_loss: 0.022116   val_mae: 0.117946\n",
      "Total:\n",
      "\t \ttime: 0h 2m 15s   loss: 0.024235   mae: 0.123135   val_loss: 0.020996   val_mae: 0.113683\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.054594   mae: 0.186768   val_loss: 0.052933   val_mae: 0.185611\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.047159   mae: 0.179561   val_loss: 0.044564   val_mae: 0.175701\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.046193   mae: 0.175946   val_loss: 0.044792   val_mae: 0.174671\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.053800   mae: 0.188640   val_loss: 0.051579   val_mae: 0.186903\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.053819   mae: 0.184656   val_loss: 0.052682   val_mae: 0.183589\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.041165   mae: 0.168222   val_loss: 0.036765   val_mae: 0.161398\n",
      "Total:\n",
      "\t \ttime: 0h 0m 33s   loss: 0.049455   mae: 0.180632   val_loss: 0.047219   val_mae: 0.177979\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.042765   mae: 0.167586   val_loss: 0.040806   val_mae: 0.165010\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.052622   mae: 0.188175   val_loss: 0.051806   val_mae: 0.187218\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.049311   mae: 0.179032   val_loss: 0.050732   val_mae: 0.182026\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.024674   mae: 0.125589   val_loss: 0.021321   val_mae: 0.117869\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.030362   mae: 0.142013   val_loss: 0.026010   val_mae: 0.132863\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.040211   mae: 0.164224   val_loss: 0.037550   val_mae: 0.159499\n",
      "Total:\n",
      "\t \ttime: 0h 0m 45s   loss: 0.039991   mae: 0.161103   val_loss: 0.038037   val_mae: 0.157414\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.022309   mae: 0.120349   val_loss: 0.018968   val_mae: 0.111054\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.040191   mae: 0.158724   val_loss: 0.039045   val_mae: 0.156017\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.042361   mae: 0.165251   val_loss: 0.042982   val_mae: 0.166404\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.025770   mae: 0.129735   val_loss: 0.021688   val_mae: 0.119201\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.025399   mae: 0.127697   val_loss: 0.019902   val_mae: 0.112477\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.026768   mae: 0.132347   val_loss: 0.022928   val_mae: 0.122973\n",
      "Total:\n",
      "\t \ttime: 0h 0m 55s   loss: 0.030466   mae: 0.139017   val_loss: 0.027585   val_mae: 0.131354\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.042778   mae: 0.165761   val_loss: 0.041133   val_mae: 0.163827\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.024807   mae: 0.128261   val_loss: 0.020814   val_mae: 0.118496\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.026867   mae: 0.133803   val_loss: 0.023484   val_mae: 0.126182\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.024988   mae: 0.127875   val_loss: 0.021558   val_mae: 0.119756\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.038151   mae: 0.155266   val_loss: 0.036036   val_mae: 0.150491\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.023921   mae: 0.123427   val_loss: 0.020546   val_mae: 0.113955\n",
      "Total:\n",
      "\t \ttime: 0h 1m 7s   loss: 0.030252   mae: 0.139066   val_loss: 0.027262   val_mae: 0.132118\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.024150   mae: 0.124872   val_loss: 0.020453   val_mae: 0.114874\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.033672   mae: 0.145275   val_loss: 0.032613   val_mae: 0.142454\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.021531   mae: 0.117284   val_loss: 0.017707   val_mae: 0.106726\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.021166   mae: 0.115494   val_loss: 0.018355   val_mae: 0.108738\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.023952   mae: 0.123860   val_loss: 0.019788   val_mae: 0.112614\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.017575   mae: 0.104053   val_loss: 0.013656   val_mae: 0.090556\n",
      "Total:\n",
      "\t \ttime: 0h 1m 20s   loss: 0.023674   mae: 0.121806   val_loss: 0.020429   val_mae: 0.112660\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.018714   mae: 0.105526   val_loss: 0.014497   val_mae: 0.092355\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.015842   mae: 0.100758   val_loss: 0.012377   val_mae: 0.088572\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.015722   mae: 0.097589   val_loss: 0.011358   val_mae: 0.082025\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014620   mae: 0.093926   val_loss: 0.012360   val_mae: 0.085621\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.015715   mae: 0.097901   val_loss: 0.011757   val_mae: 0.083720\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.052307   mae: 0.190068   val_loss: 0.049667   val_mae: 0.185642\n",
      "Total:\n",
      "\t \ttime: 0h 1m 4s   loss: 0.022154   mae: 0.114295   val_loss: 0.018670   val_mae: 0.102989\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014263   mae: 0.092639   val_loss: 0.011249   val_mae: 0.081445\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014217   mae: 0.092394   val_loss: 0.010853   val_mae: 0.079973\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014585   mae: 0.095581   val_loss: 0.011192   val_mae: 0.083243\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013772   mae: 0.090890   val_loss: 0.011477   val_mae: 0.081671\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014627   mae: 0.095297   val_loss: 0.011469   val_mae: 0.083821\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014383   mae: 0.093145   val_loss: 0.010368   val_mae: 0.077463\n",
      "Total:\n",
      "\t \ttime: 0h 1m 47s   loss: 0.014308   mae: 0.093324   val_loss: 0.011101   val_mae: 0.081269\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013873   mae: 0.091372   val_loss: 0.010750   val_mae: 0.079908\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.014130   mae: 0.093398   val_loss: 0.011284   val_mae: 0.083026\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014284   mae: 0.093942   val_loss: 0.010756   val_mae: 0.080920\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013906   mae: 0.091448   val_loss: 0.011426   val_mae: 0.081813\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014086   mae: 0.093072   val_loss: 0.010876   val_mae: 0.081247\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014343   mae: 0.094327   val_loss: 0.010321   val_mae: 0.078695\n",
      "Total:\n",
      "\t \ttime: 0h 2m 26s   loss: 0.014104   mae: 0.092927   val_loss: 0.010902   val_mae: 0.080935\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013929   mae: 0.091229   val_loss: 0.010671   val_mae: 0.078909\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013921   mae: 0.092098   val_loss: 0.010968   val_mae: 0.081475\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.014145   mae: 0.092481   val_loss: 0.010637   val_mae: 0.078804\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 33s   loss: 0.013697   mae: 0.091409   val_loss: 0.012006   val_mae: 0.084266\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.014004   mae: 0.092388   val_loss: 0.011120   val_mae: 0.081859\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.014164   mae: 0.092658   val_loss: 0.010377   val_mae: 0.077510\n",
      "Total:\n",
      "\t \ttime: 0h 3m 14s   loss: 0.013977   mae: 0.092044   val_loss: 0.010963   val_mae: 0.080471\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013715   mae: 0.090562   val_loss: 0.010532   val_mae: 0.078027\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 41s   loss: 0.013883   mae: 0.091791   val_loss: 0.010856   val_mae: 0.080707\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013998   mae: 0.092388   val_loss: 0.010494   val_mae: 0.078739\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013463   mae: 0.089797   val_loss: 0.011386   val_mae: 0.080633\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.052080   mae: 0.189627   val_loss: 0.050530   val_mae: 0.187326\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013953   mae: 0.091598   val_loss: 0.010047   val_mae: 0.075651\n",
      "Total:\n",
      "\t \ttime: 0h 3m 55s   loss: 0.020182   mae: 0.107627   val_loss: 0.017307   val_mae: 0.096847\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.015293   mae: 0.095962   val_loss: 0.011739   val_mae: 0.083941\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.052040   mae: 0.189413   val_loss: 0.050555   val_mae: 0.187284\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.016482   mae: 0.101856   val_loss: 0.012777   val_mae: 0.090394\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.015099   mae: 0.096340   val_loss: 0.012687   val_mae: 0.087230\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.015756   mae: 0.097928   val_loss: 0.012000   val_mae: 0.084991\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.020068   mae: 0.114438   val_loss: 0.015504   val_mae: 0.099300\n",
      "Total:\n",
      "\t \ttime: 0h 0m 44s   loss: 0.022456   mae: 0.115990   val_loss: 0.019211   val_mae: 0.105523\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014283   mae: 0.092829   val_loss: 0.011267   val_mae: 0.081136\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014072   mae: 0.092058   val_loss: 0.011142   val_mae: 0.080586\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014726   mae: 0.094398   val_loss: 0.011674   val_mae: 0.083603\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013917   mae: 0.091380   val_loss: 0.011938   val_mae: 0.083376\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.015312   mae: 0.098727   val_loss: 0.011827   val_mae: 0.086493\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014643   mae: 0.094193   val_loss: 0.011063   val_mae: 0.080585\n",
      "Total:\n",
      "\t \ttime: 0h 1m 7s   loss: 0.014492   mae: 0.093931   val_loss: 0.011485   val_mae: 0.082630\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.014265   mae: 0.092303   val_loss: 0.010733   val_mae: 0.079364\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.014960   mae: 0.096866   val_loss: 0.012034   val_mae: 0.085899\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014156   mae: 0.092415   val_loss: 0.010619   val_mae: 0.078615\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.018218   mae: 0.103704   val_loss: 0.014629   val_mae: 0.092580\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.018182   mae: 0.103859   val_loss: 0.014315   val_mae: 0.091422\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.018270   mae: 0.104223   val_loss: 0.013866   val_mae: 0.088474\n",
      "Total:\n",
      "\t \ttime: 0h 1m 27s   loss: 0.016342   mae: 0.098895   val_loss: 0.012699   val_mae: 0.086059\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.014397   mae: 0.094472   val_loss: 0.011335   val_mae: 0.083501\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013617   mae: 0.090255   val_loss: 0.010675   val_mae: 0.078979\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.014097   mae: 0.092313   val_loss: 0.010521   val_mae: 0.078161\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013947   mae: 0.091603   val_loss: 0.011977   val_mae: 0.083557\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.052077   mae: 0.189472   val_loss: 0.050459   val_mae: 0.187295\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013994   mae: 0.091887   val_loss: 0.010358   val_mae: 0.076880\n",
      "Total:\n",
      "\t \ttime: 0h 1m 51s   loss: 0.020355   mae: 0.108334   val_loss: 0.017554   val_mae: 0.098062\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.014402   mae: 0.094293   val_loss: 0.011077   val_mae: 0.082397\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014124   mae: 0.093068   val_loss: 0.011649   val_mae: 0.084583\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014232   mae: 0.093696   val_loss: 0.010772   val_mae: 0.080869\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013553   mae: 0.089971   val_loss: 0.011576   val_mae: 0.081437\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013930   mae: 0.091399   val_loss: 0.010801   val_mae: 0.079690\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014306   mae: 0.094085   val_loss: 0.010455   val_mae: 0.078509\n",
      "Total:\n",
      "\t \ttime: 0h 2m 15s   loss: 0.014091   mae: 0.092752   val_loss: 0.011055   val_mae: 0.081248\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.015480   mae: 0.097227   val_loss: 0.012480   val_mae: 0.086720\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.015436   mae: 0.096856   val_loss: 0.011945   val_mae: 0.084520\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.020325   mae: 0.111160   val_loss: 0.015766   val_mae: 0.095644\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.027814   mae: 0.132850   val_loss: 0.023363   val_mae: 0.120814\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.016917   mae: 0.101254   val_loss: 0.012532   val_mae: 0.086249\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.027097   mae: 0.132491   val_loss: 0.021820   val_mae: 0.116613\n",
      "Total:\n",
      "\t \ttime: 0h 0m 32s   loss: 0.020512   mae: 0.111973   val_loss: 0.016318   val_mae: 0.098427\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014688   mae: 0.094345   val_loss: 0.011303   val_mae: 0.082191\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.019620   mae: 0.113143   val_loss: 0.016112   val_mae: 0.102849\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.015216   mae: 0.096300   val_loss: 0.011413   val_mae: 0.082298\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.018574   mae: 0.109701   val_loss: 0.015888   val_mae: 0.100427\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.019483   mae: 0.112724   val_loss: 0.015872   val_mae: 0.100997\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.052285   mae: 0.189974   val_loss: 0.049206   val_mae: 0.185694\n",
      "Total:\n",
      "\t \ttime: 0h 0m 44s   loss: 0.023311   mae: 0.119365   val_loss: 0.019966   val_mae: 0.109076\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.051966   mae: 0.189039   val_loss: 0.050780   val_mae: 0.189555\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.015519   mae: 0.099484   val_loss: 0.012402   val_mae: 0.088162\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.015874   mae: 0.101092   val_loss: 0.012573   val_mae: 0.089069\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014579   mae: 0.093875   val_loss: 0.012440   val_mae: 0.085562\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013959   mae: 0.091504   val_loss: 0.010879   val_mae: 0.079683\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014532   mae: 0.093225   val_loss: 0.010788   val_mae: 0.078317\n",
      "Total:\n",
      "\t \ttime: 0h 0m 55s   loss: 0.021072   mae: 0.111370   val_loss: 0.018310   val_mae: 0.101725\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014947   mae: 0.097252   val_loss: 0.011801   val_mae: 0.085543\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014170   mae: 0.092131   val_loss: 0.011059   val_mae: 0.080883\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.015019   mae: 0.097688   val_loss: 0.011803   val_mae: 0.085519\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014005   mae: 0.092170   val_loss: 0.011887   val_mae: 0.083595\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014107   mae: 0.092365   val_loss: 0.010951   val_mae: 0.081006\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014624   mae: 0.094194   val_loss: 0.011027   val_mae: 0.080566\n",
      "Total:\n",
      "\t \ttime: 0h 1m 8s   loss: 0.014479   mae: 0.094300   val_loss: 0.011421   val_mae: 0.082852\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.014105   mae: 0.091679   val_loss: 0.010789   val_mae: 0.079235\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013992   mae: 0.091685   val_loss: 0.010787   val_mae: 0.079595\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.014637   mae: 0.096001   val_loss: 0.011331   val_mae: 0.083381\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013569   mae: 0.089968   val_loss: 0.011684   val_mae: 0.082085\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013664   mae: 0.090517   val_loss: 0.010777   val_mae: 0.079459\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013786   mae: 0.091011   val_loss: 0.010080   val_mae: 0.075321\n",
      "Total:\n",
      "\t \ttime: 0h 1m 19s   loss: 0.013959   mae: 0.091810   val_loss: 0.010908   val_mae: 0.079846\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014886   mae: 0.095572   val_loss: 0.010975   val_mae: 0.081443\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014719   mae: 0.094854   val_loss: 0.011302   val_mae: 0.082755\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014567   mae: 0.093752   val_loss: 0.011142   val_mae: 0.079301\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014530   mae: 0.093484   val_loss: 0.011540   val_mae: 0.082088\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014304   mae: 0.092733   val_loss: 0.010471   val_mae: 0.077886\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014779   mae: 0.094558   val_loss: 0.010494   val_mae: 0.077535\n",
      "Total:\n",
      "\t \ttime: 0h 1m 3s   loss: 0.014631   mae: 0.094159   val_loss: 0.010987   val_mae: 0.080168\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.014470   mae: 0.093503   val_loss: 0.011051   val_mae: 0.081224\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014291   mae: 0.092878   val_loss: 0.010618   val_mae: 0.079013\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014295   mae: 0.092769   val_loss: 0.011422   val_mae: 0.081997\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.014090   mae: 0.092054   val_loss: 0.012183   val_mae: 0.084072\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014173   mae: 0.092334   val_loss: 0.011380   val_mae: 0.082233\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014366   mae: 0.093302   val_loss: 0.010490   val_mae: 0.077361\n",
      "Total:\n",
      "\t \ttime: 0h 1m 48s   loss: 0.014281   mae: 0.092807   val_loss: 0.011191   val_mae: 0.080983\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014149   mae: 0.092042   val_loss: 0.010271   val_mae: 0.077469\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014016   mae: 0.091542   val_loss: 0.010817   val_mae: 0.080005\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014214   mae: 0.092802   val_loss: 0.010640   val_mae: 0.078115\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.052254   mae: 0.189924   val_loss: 0.049722   val_mae: 0.186181\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014151   mae: 0.092144   val_loss: 0.012842   val_mae: 0.087721\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014113   mae: 0.092258   val_loss: 0.010147   val_mae: 0.075736\n",
      "Total:\n",
      "\t \ttime: 0h 2m 26s   loss: 0.020483   mae: 0.108452   val_loss: 0.017407   val_mae: 0.097538\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.014030   mae: 0.091498   val_loss: 0.011006   val_mae: 0.080871\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 33s   loss: 0.014167   mae: 0.092522   val_loss: 0.010704   val_mae: 0.079129\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013998   mae: 0.091681   val_loss: 0.010380   val_mae: 0.076508\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013965   mae: 0.091383   val_loss: 0.011575   val_mae: 0.082038\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013932   mae: 0.091182   val_loss: 0.010645   val_mae: 0.078464\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.052337   mae: 0.190134   val_loss: 0.049762   val_mae: 0.185518\n",
      "Total:\n",
      "\t \ttime: 0h 3m 12s   loss: 0.020405   mae: 0.108067   val_loss: 0.017345   val_mae: 0.097088\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.014002   mae: 0.091599   val_loss: 0.010346   val_mae: 0.077756\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013902   mae: 0.091085   val_loss: 0.011125   val_mae: 0.082000\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.051742   mae: 0.188451   val_loss: 0.051850   val_mae: 0.191101\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.014179   mae: 0.092513   val_loss: 0.011372   val_mae: 0.081638\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 40s   loss: 0.013964   mae: 0.091454   val_loss: 0.010554   val_mae: 0.078156\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.014492   mae: 0.093966   val_loss: 0.010271   val_mae: 0.077119\n",
      "Total:\n",
      "\t \ttime: 0h 3m 57s   loss: 0.020380   mae: 0.108178   val_loss: 0.017586   val_mae: 0.097962\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.052079   mae: 0.189156   val_loss: 0.050730   val_mae: 0.189866\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014269   mae: 0.092719   val_loss: 0.010957   val_mae: 0.079364\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014318   mae: 0.092863   val_loss: 0.010488   val_mae: 0.077976\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014343   mae: 0.092719   val_loss: 0.011690   val_mae: 0.082118\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014516   mae: 0.093533   val_loss: 0.011711   val_mae: 0.083715\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014709   mae: 0.094899   val_loss: 0.010392   val_mae: 0.078582\n",
      "Total:\n",
      "\t \ttime: 0h 0m 45s   loss: 0.020706   mae: 0.109315   val_loss: 0.017661   val_mae: 0.098603\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014004   mae: 0.091430   val_loss: 0.011240   val_mae: 0.080224\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014102   mae: 0.091864   val_loss: 0.011208   val_mae: 0.081919\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014411   mae: 0.093378   val_loss: 0.010351   val_mae: 0.077021\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.052304   mae: 0.189934   val_loss: 0.049583   val_mae: 0.186108\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014342   mae: 0.093080   val_loss: 0.010539   val_mae: 0.079333\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014302   mae: 0.092756   val_loss: 0.010070   val_mae: 0.075914\n",
      "Total:\n",
      "\t \ttime: 0h 1m 8s   loss: 0.020578   mae: 0.108740   val_loss: 0.017165   val_mae: 0.096753\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.052077   mae: 0.189163   val_loss: 0.051034   val_mae: 0.189098\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.014002   mae: 0.091571   val_loss: 0.011286   val_mae: 0.080607\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014063   mae: 0.092025   val_loss: 0.010114   val_mae: 0.076335\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.014041   mae: 0.091689   val_loss: 0.011499   val_mae: 0.081901\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013946   mae: 0.091285   val_loss: 0.010420   val_mae: 0.077851\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.052372   mae: 0.190068   val_loss: 0.049418   val_mae: 0.185889\n",
      "Total:\n",
      "\t \ttime: 0h 1m 27s   loss: 0.026750   mae: 0.124300   val_loss: 0.023962   val_mae: 0.115280\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013964   mae: 0.091361   val_loss: 0.010524   val_mae: 0.078332\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013912   mae: 0.090958   val_loss: 0.012304   val_mae: 0.085486\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.014082   mae: 0.091881   val_loss: 0.012300   val_mae: 0.086853\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013993   mae: 0.091684   val_loss: 0.012273   val_mae: 0.083994\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.014265   mae: 0.092959   val_loss: 0.011203   val_mae: 0.082096\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.014134   mae: 0.092401   val_loss: 0.010008   val_mae: 0.075876\n",
      "Total:\n",
      "\t \ttime: 0h 1m 51s   loss: 0.014058   mae: 0.091874   val_loss: 0.011435   val_mae: 0.082106\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013942   mae: 0.091101   val_loss: 0.010996   val_mae: 0.079989\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013889   mae: 0.091169   val_loss: 0.011081   val_mae: 0.082138\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013983   mae: 0.091625   val_loss: 0.010267   val_mae: 0.076306\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013827   mae: 0.091403   val_loss: 0.011282   val_mae: 0.081156\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013802   mae: 0.090961   val_loss: 0.010554   val_mae: 0.078485\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013952   mae: 0.091601   val_loss: 0.010140   val_mae: 0.076247\n",
      "Total:\n",
      "\t \ttime: 0h 2m 13s   loss: 0.013899   mae: 0.091310   val_loss: 0.010720   val_mae: 0.079053\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014415   mae: 0.092876   val_loss: 0.010609   val_mae: 0.078774\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014310   mae: 0.092753   val_loss: 0.010875   val_mae: 0.079579\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.018564   mae: 0.105252   val_loss: 0.014450   val_mae: 0.091594\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014143   mae: 0.092110   val_loss: 0.014576   val_mae: 0.094091\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014626   mae: 0.093775   val_loss: 0.010496   val_mae: 0.078540\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014509   mae: 0.093671   val_loss: 0.013390   val_mae: 0.088647\n",
      "Total:\n",
      "\t \ttime: 0h 0m 33s   loss: 0.015094   mae: 0.095073   val_loss: 0.012399   val_mae: 0.085204\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014442   mae: 0.093210   val_loss: 0.011153   val_mae: 0.080390\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014099   mae: 0.092081   val_loss: 0.011010   val_mae: 0.080466\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014074   mae: 0.091890   val_loss: 0.010476   val_mae: 0.077283\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.052300   mae: 0.189704   val_loss: 0.049177   val_mae: 0.186978\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014164   mae: 0.092378   val_loss: 0.010717   val_mae: 0.079437\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.052343   mae: 0.190103   val_loss: 0.049103   val_mae: 0.186175\n",
      "Total:\n",
      "\t \ttime: 0h 0m 44s   loss: 0.026904   mae: 0.124894   val_loss: 0.023606   val_mae: 0.115121\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014097   mae: 0.092428   val_loss: 0.010943   val_mae: 0.080620\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014053   mae: 0.092191   val_loss: 0.010964   val_mae: 0.080175\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014172   mae: 0.092940   val_loss: 0.011440   val_mae: 0.082157\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013969   mae: 0.091919   val_loss: 0.013873   val_mae: 0.091929\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013989   mae: 0.091573   val_loss: 0.010470   val_mae: 0.078726\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.052274   mae: 0.190022   val_loss: 0.049295   val_mae: 0.185550\n",
      "Total:\n",
      "\t \ttime: 0h 0m 56s   loss: 0.020426   mae: 0.108512   val_loss: 0.017831   val_mae: 0.099859\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013805   mae: 0.090992   val_loss: 0.011324   val_mae: 0.080923\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013978   mae: 0.092007   val_loss: 0.010609   val_mae: 0.079155\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014061   mae: 0.092103   val_loss: 0.010353   val_mae: 0.077148\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013708   mae: 0.090591   val_loss: 0.012622   val_mae: 0.086004\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013904   mae: 0.091631   val_loss: 0.010558   val_mae: 0.079906\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014115   mae: 0.092749   val_loss: 0.010239   val_mae: 0.076534\n",
      "Total:\n",
      "\t \ttime: 0h 1m 6s   loss: 0.013928   mae: 0.091679   val_loss: 0.010951   val_mae: 0.079945\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 16   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013716   mae: 0.090417   val_loss: 0.010871   val_mae: 0.079622\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013819   mae: 0.090873   val_loss: 0.010653   val_mae: 0.079735\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013918   mae: 0.091679   val_loss: 0.010363   val_mae: 0.077755\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.052329   mae: 0.190115   val_loss: 0.049351   val_mae: 0.185959\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013941   mae: 0.091504   val_loss: 0.010441   val_mae: 0.079239\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013752   mae: 0.090916   val_loss: 0.010041   val_mae: 0.074954\n",
      "Total:\n",
      "\t \ttime: 0h 1m 18s   loss: 0.020246   mae: 0.107584   val_loss: 0.016953   val_mae: 0.096211\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.021907   mae: 0.119061   val_loss: 0.017643   val_mae: 0.106967\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.019921   mae: 0.112375   val_loss: 0.017097   val_mae: 0.104085\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.021765   mae: 0.117061   val_loss: 0.018452   val_mae: 0.108005\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.024304   mae: 0.126317   val_loss: 0.020858   val_mae: 0.116935\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.020140   mae: 0.112415   val_loss: 0.016217   val_mae: 0.100176\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.020160   mae: 0.113568   val_loss: 0.017088   val_mae: 0.102792\n",
      "Total:\n",
      "\t \ttime: 0h 0m 52s   loss: 0.021366   mae: 0.116800   val_loss: 0.017893   val_mae: 0.106493\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.015837   mae: 0.098668   val_loss: 0.012971   val_mae: 0.089655\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.015869   mae: 0.098998   val_loss: 0.012547   val_mae: 0.087919\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.016393   mae: 0.101467   val_loss: 0.012586   val_mae: 0.088840\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.016757   mae: 0.102070   val_loss: 0.014317   val_mae: 0.094523\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.016589   mae: 0.101707   val_loss: 0.013237   val_mae: 0.090434\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.016622   mae: 0.101901   val_loss: 0.012947   val_mae: 0.088547\n",
      "Total:\n",
      "\t \ttime: 0h 1m 30s   loss: 0.016344   mae: 0.100802   val_loss: 0.013101   val_mae: 0.089986\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.015078   mae: 0.096297   val_loss: 0.012258   val_mae: 0.086347\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.015118   mae: 0.096256   val_loss: 0.012456   val_mae: 0.087612\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.015539   mae: 0.097572   val_loss: 0.011989   val_mae: 0.085332\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.014992   mae: 0.095626   val_loss: 0.013344   val_mae: 0.089977\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.015045   mae: 0.096253   val_loss: 0.011652   val_mae: 0.084136\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.015193   mae: 0.097239   val_loss: 0.011857   val_mae: 0.084421\n",
      "Total:\n",
      "\t \ttime: 0h 2m 9s   loss: 0.015161   mae: 0.096541   val_loss: 0.012259   val_mae: 0.086304\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.014571   mae: 0.093809   val_loss: 0.011537   val_mae: 0.083398\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.014547   mae: 0.093823   val_loss: 0.011683   val_mae: 0.083959\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.014403   mae: 0.093243   val_loss: 0.010762   val_mae: 0.079157\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.014512   mae: 0.094114   val_loss: 0.012756   val_mae: 0.087675\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 27s   loss: 0.014726   mae: 0.094286   val_loss: 0.011741   val_mae: 0.083345\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 27s   loss: 0.014516   mae: 0.094176   val_loss: 0.010743   val_mae: 0.079250\n",
      "Total:\n",
      "\t \ttime: 0h 2m 52s   loss: 0.014546   mae: 0.093909   val_loss: 0.011537   val_mae: 0.082797\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.014772   mae: 0.094498   val_loss: 0.011657   val_mae: 0.083556\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.014491   mae: 0.093458   val_loss: 0.011367   val_mae: 0.082298\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.014351   mae: 0.093201   val_loss: 0.010647   val_mae: 0.079385\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013965   mae: 0.091960   val_loss: 0.012150   val_mae: 0.085234\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.014152   mae: 0.092487   val_loss: 0.010923   val_mae: 0.080580\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.014222   mae: 0.092902   val_loss: 0.010431   val_mae: 0.077652\n",
      "Total:\n",
      "\t \ttime: 0h 3m 32s   loss: 0.014325   mae: 0.093084   val_loss: 0.011196   val_mae: 0.081451\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.025055   mae: 0.126600   val_loss: 0.021046   val_mae: 0.116414\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.028831   mae: 0.139425   val_loss: 0.025633   val_mae: 0.132294\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.026146   mae: 0.131672   val_loss: 0.023140   val_mae: 0.124401\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.023613   mae: 0.124277   val_loss: 0.020704   val_mae: 0.115780\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.029630   mae: 0.140169   val_loss: 0.025283   val_mae: 0.130060\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.029003   mae: 0.139423   val_loss: 0.024891   val_mae: 0.129749\n",
      "Total:\n",
      "\t \ttime: 0h 0m 34s   loss: 0.027046   mae: 0.133594   val_loss: 0.023449   val_mae: 0.124783\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.017591   mae: 0.104978   val_loss: 0.013974   val_mae: 0.093382\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.019005   mae: 0.109704   val_loss: 0.017325   val_mae: 0.105337\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.018778   mae: 0.109573   val_loss: 0.015405   val_mae: 0.099670\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.019040   mae: 0.109803   val_loss: 0.016535   val_mae: 0.102257\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.018064   mae: 0.106072   val_loss: 0.014853   val_mae: 0.096278\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.019765   mae: 0.113233   val_loss: 0.016049   val_mae: 0.101579\n",
      "Total:\n",
      "\t \ttime: 0h 0m 52s   loss: 0.018707   mae: 0.108894   val_loss: 0.015690   val_mae: 0.099751\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.017423   mae: 0.104693   val_loss: 0.014614   val_mae: 0.095300\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.016467   mae: 0.101254   val_loss: 0.013528   val_mae: 0.092457\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.016712   mae: 0.102061   val_loss: 0.013684   val_mae: 0.092427\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.015560   mae: 0.097676   val_loss: 0.013579   val_mae: 0.091701\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.015626   mae: 0.098162   val_loss: 0.012559   val_mae: 0.087920\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.015888   mae: 0.099196   val_loss: 0.012505   val_mae: 0.086642\n",
      "Total:\n",
      "\t \ttime: 0h 1m 13s   loss: 0.016279   mae: 0.100507   val_loss: 0.013411   val_mae: 0.091075\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.016010   mae: 0.099626   val_loss: 0.012904   val_mae: 0.089183\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.015790   mae: 0.098004   val_loss: 0.012670   val_mae: 0.087230\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.015534   mae: 0.097710   val_loss: 0.012603   val_mae: 0.088314\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014579   mae: 0.094124   val_loss: 0.012273   val_mae: 0.086187\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.015262   mae: 0.096931   val_loss: 0.011711   val_mae: 0.084265\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.015330   mae: 0.097345   val_loss: 0.011282   val_mae: 0.082359\n",
      "Total:\n",
      "\t \ttime: 0h 1m 34s   loss: 0.015417   mae: 0.097290   val_loss: 0.012241   val_mae: 0.086256\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.015358   mae: 0.097279   val_loss: 0.012188   val_mae: 0.086582\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.014633   mae: 0.094292   val_loss: 0.011569   val_mae: 0.083845\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.015359   mae: 0.096365   val_loss: 0.011914   val_mae: 0.083885\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.014351   mae: 0.093501   val_loss: 0.012576   val_mae: 0.086954\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.014987   mae: 0.095843   val_loss: 0.011702   val_mae: 0.084358\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.015042   mae: 0.095811   val_loss: 0.011307   val_mae: 0.081257\n",
      "Total:\n",
      "\t \ttime: 0h 1m 56s   loss: 0.014955   mae: 0.095515   val_loss: 0.011876   val_mae: 0.084480\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.033306   mae: 0.150159   val_loss: 0.029557   val_mae: 0.142549\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.034060   mae: 0.151501   val_loss: 0.031464   val_mae: 0.146007\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.033156   mae: 0.149580   val_loss: 0.030019   val_mae: 0.143814\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.035473   mae: 0.155301   val_loss: 0.031071   val_mae: 0.145916\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.036153   mae: 0.155367   val_loss: 0.032230   val_mae: 0.147944\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.036440   mae: 0.157655   val_loss: 0.032047   val_mae: 0.148855\n",
      "Total:\n",
      "\t \ttime: 0h 0m 24s   loss: 0.034765   mae: 0.153261   val_loss: 0.031065   val_mae: 0.145847\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.023949   mae: 0.125040   val_loss: 0.020372   val_mae: 0.115093\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.020344   mae: 0.114496   val_loss: 0.018304   val_mae: 0.110132\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.024539   mae: 0.126329   val_loss: 0.021330   val_mae: 0.119113\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.023144   mae: 0.122565   val_loss: 0.020833   val_mae: 0.116004\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.020502   mae: 0.115645   val_loss: 0.016839   val_mae: 0.104806\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.023260   mae: 0.123745   val_loss: 0.019751   val_mae: 0.113760\n",
      "Total:\n",
      "\t \ttime: 0h 0m 33s   loss: 0.022623   mae: 0.121303   val_loss: 0.019571   val_mae: 0.113151\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.018839   mae: 0.108966   val_loss: 0.016484   val_mae: 0.101492\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.019832   mae: 0.111684   val_loss: 0.017475   val_mae: 0.105098\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.020546   mae: 0.115023   val_loss: 0.017569   val_mae: 0.107530\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.016698   mae: 0.101806   val_loss: 0.015051   val_mae: 0.096796\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.019703   mae: 0.111192   val_loss: 0.016546   val_mae: 0.101843\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.018512   mae: 0.108147   val_loss: 0.015315   val_mae: 0.097520\n",
      "Total:\n",
      "\t \ttime: 0h 0m 44s   loss: 0.019022   mae: 0.109470   val_loss: 0.016406   val_mae: 0.101713\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.016895   mae: 0.102367   val_loss: 0.013820   val_mae: 0.092222\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.016567   mae: 0.101206   val_loss: 0.014060   val_mae: 0.093915\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.017934   mae: 0.107305   val_loss: 0.014539   val_mae: 0.097451\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.016669   mae: 0.101982   val_loss: 0.014580   val_mae: 0.095469\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.016691   mae: 0.102762   val_loss: 0.013101   val_mae: 0.091139\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.016321   mae: 0.100577   val_loss: 0.013074   val_mae: 0.088933\n",
      "Total:\n",
      "\t \ttime: 0h 0m 56s   loss: 0.016846   mae: 0.102700   val_loss: 0.013862   val_mae: 0.093188\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.016344   mae: 0.100882   val_loss: 0.013703   val_mae: 0.092175\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.016386   mae: 0.100365   val_loss: 0.013809   val_mae: 0.092992\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.017596   mae: 0.104789   val_loss: 0.013801   val_mae: 0.093660\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.015182   mae: 0.096237   val_loss: 0.013616   val_mae: 0.091365\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.015577   mae: 0.097901   val_loss: 0.012088   val_mae: 0.085974\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.016053   mae: 0.099649   val_loss: 0.012659   val_mae: 0.087127\n",
      "Total:\n",
      "\t \ttime: 0h 1m 6s   loss: 0.016190   mae: 0.099971   val_loss: 0.013279   val_mae: 0.090549\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013980   mae: 0.091454   val_loss: 0.010833   val_mae: 0.080036\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014095   mae: 0.091868   val_loss: 0.012716   val_mae: 0.086303\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014238   mae: 0.092596   val_loss: 0.010532   val_mae: 0.078206\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013802   mae: 0.090943   val_loss: 0.011579   val_mae: 0.082396\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014106   mae: 0.092067   val_loss: 0.011043   val_mae: 0.080577\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014511   mae: 0.093762   val_loss: 0.010458   val_mae: 0.077441\n",
      "Total:\n",
      "\t \ttime: 0h 0m 52s   loss: 0.014122   mae: 0.092115   val_loss: 0.011193   val_mae: 0.080827\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013868   mae: 0.090954   val_loss: 0.011291   val_mae: 0.081374\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013848   mae: 0.091390   val_loss: 0.011028   val_mae: 0.080365\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013876   mae: 0.091374   val_loss: 0.010499   val_mae: 0.077397\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013677   mae: 0.090692   val_loss: 0.011465   val_mae: 0.081553\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013667   mae: 0.090520   val_loss: 0.010518   val_mae: 0.078098\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014020   mae: 0.091970   val_loss: 0.010032   val_mae: 0.075439\n",
      "Total:\n",
      "\t \ttime: 0h 1m 33s   loss: 0.013826   mae: 0.091150   val_loss: 0.010806   val_mae: 0.079038\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013769   mae: 0.090805   val_loss: 0.010465   val_mae: 0.078180\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014055   mae: 0.092023   val_loss: 0.010670   val_mae: 0.079596\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013985   mae: 0.091563   val_loss: 0.011148   val_mae: 0.080424\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013513   mae: 0.089924   val_loss: 0.011325   val_mae: 0.080907\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013846   mae: 0.090888   val_loss: 0.010773   val_mae: 0.078826\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013924   mae: 0.091548   val_loss: 0.010080   val_mae: 0.076055\n",
      "Total:\n",
      "\t \ttime: 0h 2m 12s   loss: 0.013849   mae: 0.091125   val_loss: 0.010743   val_mae: 0.078998\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013715   mae: 0.090609   val_loss: 0.010628   val_mae: 0.078657\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013525   mae: 0.089897   val_loss: 0.010793   val_mae: 0.078989\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013776   mae: 0.090973   val_loss: 0.010244   val_mae: 0.076676\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 27s   loss: 0.013483   mae: 0.089772   val_loss: 0.011336   val_mae: 0.080598\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 27s   loss: 0.013651   mae: 0.090303   val_loss: 0.010437   val_mae: 0.077788\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 27s   loss: 0.013745   mae: 0.090758   val_loss: 0.010112   val_mae: 0.075667\n",
      "Total:\n",
      "\t \ttime: 0h 2m 47s   loss: 0.013649   mae: 0.090385   val_loss: 0.010592   val_mae: 0.078062\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013723   mae: 0.090644   val_loss: 0.010866   val_mae: 0.080177\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013588   mae: 0.090191   val_loss: 0.010473   val_mae: 0.077891\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013749   mae: 0.090942   val_loss: 0.010575   val_mae: 0.078036\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013333   mae: 0.089249   val_loss: 0.012085   val_mae: 0.083503\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013564   mae: 0.089966   val_loss: 0.010541   val_mae: 0.078255\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013656   mae: 0.090707   val_loss: 0.009972   val_mae: 0.075251\n",
      "Total:\n",
      "\t \ttime: 0h 3m 32s   loss: 0.013602   mae: 0.090283   val_loss: 0.010752   val_mae: 0.078852\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014402   mae: 0.093201   val_loss: 0.011353   val_mae: 0.082000\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014132   mae: 0.091980   val_loss: 0.011019   val_mae: 0.080759\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014577   mae: 0.094180   val_loss: 0.010659   val_mae: 0.079619\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014622   mae: 0.094015   val_loss: 0.012275   val_mae: 0.085520\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014336   mae: 0.093024   val_loss: 0.010986   val_mae: 0.080709\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014495   mae: 0.093931   val_loss: 0.010432   val_mae: 0.077620\n",
      "Total:\n",
      "\t \ttime: 0h 0m 32s   loss: 0.014427   mae: 0.093389   val_loss: 0.011120   val_mae: 0.081038\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013988   mae: 0.091848   val_loss: 0.010726   val_mae: 0.079306\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013969   mae: 0.091440   val_loss: 0.010968   val_mae: 0.080381\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013952   mae: 0.091550   val_loss: 0.010324   val_mae: 0.077038\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013598   mae: 0.090463   val_loss: 0.011698   val_mae: 0.082258\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013999   mae: 0.091787   val_loss: 0.010718   val_mae: 0.079603\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014081   mae: 0.092321   val_loss: 0.010291   val_mae: 0.077151\n",
      "Total:\n",
      "\t \ttime: 0h 0m 53s   loss: 0.013931   mae: 0.091568   val_loss: 0.010788   val_mae: 0.079290\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013679   mae: 0.090427   val_loss: 0.010535   val_mae: 0.078377\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013705   mae: 0.090789   val_loss: 0.010757   val_mae: 0.079642\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013818   mae: 0.091229   val_loss: 0.010413   val_mae: 0.077561\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013777   mae: 0.091155   val_loss: 0.011837   val_mae: 0.083193\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013759   mae: 0.090586   val_loss: 0.010391   val_mae: 0.077815\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013900   mae: 0.091650   val_loss: 0.009906   val_mae: 0.075010\n",
      "Total:\n",
      "\t \ttime: 0h 1m 13s   loss: 0.013773   mae: 0.090973   val_loss: 0.010640   val_mae: 0.078600\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013596   mae: 0.090124   val_loss: 0.011290   val_mae: 0.081173\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013502   mae: 0.089680   val_loss: 0.010626   val_mae: 0.078740\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013686   mae: 0.090633   val_loss: 0.010469   val_mae: 0.077301\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013477   mae: 0.090035   val_loss: 0.011511   val_mae: 0.081671\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013543   mae: 0.089888   val_loss: 0.010221   val_mae: 0.077064\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013653   mae: 0.090570   val_loss: 0.010177   val_mae: 0.076220\n",
      "Total:\n",
      "\t \ttime: 0h 1m 33s   loss: 0.013576   mae: 0.090155   val_loss: 0.010716   val_mae: 0.078695\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013598   mae: 0.090158   val_loss: 0.010795   val_mae: 0.079448\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013628   mae: 0.090382   val_loss: 0.010400   val_mae: 0.077713\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013723   mae: 0.090786   val_loss: 0.010720   val_mae: 0.078323\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013323   mae: 0.089472   val_loss: 0.011398   val_mae: 0.081132\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013607   mae: 0.090306   val_loss: 0.010523   val_mae: 0.078112\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013643   mae: 0.090417   val_loss: 0.009868   val_mae: 0.074815\n",
      "Total:\n",
      "\t \ttime: 0h 1m 54s   loss: 0.013587   mae: 0.090253   val_loss: 0.010617   val_mae: 0.078257\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014810   mae: 0.095236   val_loss: 0.011685   val_mae: 0.083431\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014463   mae: 0.093422   val_loss: 0.011072   val_mae: 0.081109\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014892   mae: 0.095174   val_loss: 0.011209   val_mae: 0.082078\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014532   mae: 0.093711   val_loss: 0.012223   val_mae: 0.085486\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014626   mae: 0.094034   val_loss: 0.011047   val_mae: 0.081399\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014597   mae: 0.094129   val_loss: 0.010393   val_mae: 0.077279\n",
      "Total:\n",
      "\t \ttime: 0h 0m 23s   loss: 0.014653   mae: 0.094284   val_loss: 0.011271   val_mae: 0.081797\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013889   mae: 0.091211   val_loss: 0.010977   val_mae: 0.080705\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014046   mae: 0.092058   val_loss: 0.011070   val_mae: 0.081674\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014120   mae: 0.092255   val_loss: 0.010452   val_mae: 0.078790\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013869   mae: 0.091223   val_loss: 0.011802   val_mae: 0.083147\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013921   mae: 0.091570   val_loss: 0.010601   val_mae: 0.079369\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014188   mae: 0.092563   val_loss: 0.010118   val_mae: 0.076409\n",
      "Total:\n",
      "\t \ttime: 0h 0m 33s   loss: 0.014006   mae: 0.091813   val_loss: 0.010837   val_mae: 0.080016\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013651   mae: 0.090162   val_loss: 0.010609   val_mae: 0.078621\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013719   mae: 0.090640   val_loss: 0.011141   val_mae: 0.081108\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013845   mae: 0.091402   val_loss: 0.010341   val_mae: 0.077165\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013531   mae: 0.090027   val_loss: 0.011646   val_mae: 0.082199\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013684   mae: 0.090509   val_loss: 0.010375   val_mae: 0.078028\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013986   mae: 0.091891   val_loss: 0.011036   val_mae: 0.080249\n",
      "Total:\n",
      "\t \ttime: 0h 0m 45s   loss: 0.013736   mae: 0.090772   val_loss: 0.010858   val_mae: 0.079562\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013899   mae: 0.091358   val_loss: 0.011125   val_mae: 0.080217\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013695   mae: 0.090649   val_loss: 0.010723   val_mae: 0.079727\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013755   mae: 0.090736   val_loss: 0.010260   val_mae: 0.076918\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013465   mae: 0.089764   val_loss: 0.011942   val_mae: 0.083401\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013576   mae: 0.090013   val_loss: 0.010402   val_mae: 0.077979\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013796   mae: 0.091355   val_loss: 0.010225   val_mae: 0.076234\n",
      "Total:\n",
      "\t \ttime: 0h 0m 57s   loss: 0.013697   mae: 0.090646   val_loss: 0.010779   val_mae: 0.079079\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013715   mae: 0.090445   val_loss: 0.010719   val_mae: 0.078670\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013624   mae: 0.090251   val_loss: 0.010422   val_mae: 0.078243\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013900   mae: 0.091469   val_loss: 0.010528   val_mae: 0.078491\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013480   mae: 0.089649   val_loss: 0.011371   val_mae: 0.081008\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013680   mae: 0.090492   val_loss: 0.010455   val_mae: 0.079155\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013635   mae: 0.090526   val_loss: 0.009963   val_mae: 0.074789\n",
      "Total:\n",
      "\t \ttime: 0h 1m 6s   loss: 0.013672   mae: 0.090472   val_loss: 0.010576   val_mae: 0.078393\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014374   mae: 0.092746   val_loss: 0.010812   val_mae: 0.078855\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014272   mae: 0.092415   val_loss: 0.011250   val_mae: 0.080376\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014466   mae: 0.093095   val_loss: 0.011182   val_mae: 0.080954\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014163   mae: 0.092221   val_loss: 0.012495   val_mae: 0.084751\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014264   mae: 0.092646   val_loss: 0.010994   val_mae: 0.079642\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014415   mae: 0.093371   val_loss: 0.010213   val_mae: 0.076050\n",
      "Total:\n",
      "\t \ttime: 0h 0m 50s   loss: 0.014326   mae: 0.092749   val_loss: 0.011158   val_mae: 0.080105\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014313   mae: 0.092635   val_loss: 0.011087   val_mae: 0.081389\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014069   mae: 0.091707   val_loss: 0.010687   val_mae: 0.079336\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014299   mae: 0.092795   val_loss: 0.010144   val_mae: 0.076424\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013791   mae: 0.090910   val_loss: 0.011715   val_mae: 0.081672\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014172   mae: 0.092151   val_loss: 0.010775   val_mae: 0.079791\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014210   mae: 0.092404   val_loss: 0.010419   val_mae: 0.077591\n",
      "Total:\n",
      "\t \ttime: 0h 1m 34s   loss: 0.014142   mae: 0.092100   val_loss: 0.010805   val_mae: 0.079367\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.014025   mae: 0.091411   val_loss: 0.010631   val_mae: 0.079335\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013999   mae: 0.091367   val_loss: 0.010471   val_mae: 0.077550\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.014013   mae: 0.091458   val_loss: 0.010743   val_mae: 0.078274\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013725   mae: 0.090574   val_loss: 0.011845   val_mae: 0.082842\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013920   mae: 0.091259   val_loss: 0.010439   val_mae: 0.077939\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.014133   mae: 0.092277   val_loss: 0.010277   val_mae: 0.076306\n",
      "Total:\n",
      "\t \ttime: 0h 2m 12s   loss: 0.013969   mae: 0.091391   val_loss: 0.010734   val_mae: 0.078708\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013879   mae: 0.091112   val_loss: 0.010681   val_mae: 0.079041\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 27s   loss: 0.013867   mae: 0.091010   val_loss: 0.010477   val_mae: 0.077602\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 27s   loss: 0.014010   mae: 0.091474   val_loss: 0.010310   val_mae: 0.076296\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 27s   loss: 0.013707   mae: 0.090364   val_loss: 0.011385   val_mae: 0.080671\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013898   mae: 0.090768   val_loss: 0.010490   val_mae: 0.077672\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013973   mae: 0.091552   val_loss: 0.010237   val_mae: 0.076613\n",
      "Total:\n",
      "\t \ttime: 0h 2m 48s   loss: 0.013889   mae: 0.091047   val_loss: 0.010597   val_mae: 0.077983\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013776   mae: 0.090541   val_loss: 0.010590   val_mae: 0.078702\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013824   mae: 0.090737   val_loss: 0.010625   val_mae: 0.078535\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013946   mae: 0.091298   val_loss: 0.010537   val_mae: 0.077451\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013542   mae: 0.089898   val_loss: 0.011695   val_mae: 0.082172\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013836   mae: 0.091114   val_loss: 0.010571   val_mae: 0.078856\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013858   mae: 0.091252   val_loss: 0.010054   val_mae: 0.075277\n",
      "Total:\n",
      "\t \ttime: 0h 3m 32s   loss: 0.013797   mae: 0.090806   val_loss: 0.010679   val_mae: 0.078499\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014176   mae: 0.091902   val_loss: 0.010911   val_mae: 0.079913\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014428   mae: 0.092964   val_loss: 0.011042   val_mae: 0.079657\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014347   mae: 0.092770   val_loss: 0.010519   val_mae: 0.077890\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013954   mae: 0.091385   val_loss: 0.011810   val_mae: 0.083049\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014236   mae: 0.092311   val_loss: 0.010806   val_mae: 0.079423\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014450   mae: 0.093184   val_loss: 0.010144   val_mae: 0.075384\n",
      "Total:\n",
      "\t \ttime: 0h 0m 32s   loss: 0.014265   mae: 0.092419   val_loss: 0.010872   val_mae: 0.079219\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014039   mae: 0.091568   val_loss: 0.011118   val_mae: 0.080489\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013920   mae: 0.091424   val_loss: 0.011163   val_mae: 0.079678\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014090   mae: 0.091988   val_loss: 0.010524   val_mae: 0.078607\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013746   mae: 0.090777   val_loss: 0.011599   val_mae: 0.082290\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013875   mae: 0.091135   val_loss: 0.010687   val_mae: 0.079330\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014052   mae: 0.091895   val_loss: 0.010014   val_mae: 0.075372\n",
      "Total:\n",
      "\t \ttime: 0h 0m 53s   loss: 0.013954   mae: 0.091464   val_loss: 0.010851   val_mae: 0.079294\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013798   mae: 0.090612   val_loss: 0.010511   val_mae: 0.077656\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013961   mae: 0.091356   val_loss: 0.010569   val_mae: 0.077916\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014031   mae: 0.091928   val_loss: 0.010287   val_mae: 0.076178\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013590   mae: 0.089903   val_loss: 0.011284   val_mae: 0.080013\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013888   mae: 0.091056   val_loss: 0.011536   val_mae: 0.082567\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014027   mae: 0.091910   val_loss: 0.010848   val_mae: 0.077590\n",
      "Total:\n",
      "\t \ttime: 0h 1m 13s   loss: 0.013882   mae: 0.091127   val_loss: 0.010839   val_mae: 0.078653\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013783   mae: 0.090708   val_loss: 0.010688   val_mae: 0.077943\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013776   mae: 0.090804   val_loss: 0.010769   val_mae: 0.079352\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013941   mae: 0.091634   val_loss: 0.010855   val_mae: 0.079301\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013600   mae: 0.089875   val_loss: 0.011807   val_mae: 0.082135\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013706   mae: 0.090720   val_loss: 0.010934   val_mae: 0.080096\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013941   mae: 0.091328   val_loss: 0.010096   val_mae: 0.075627\n",
      "Total:\n",
      "\t \ttime: 0h 1m 33s   loss: 0.013791   mae: 0.090845   val_loss: 0.010858   val_mae: 0.079076\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013691   mae: 0.090415   val_loss: 0.010698   val_mae: 0.078931\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013679   mae: 0.090402   val_loss: 0.010812   val_mae: 0.079170\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013854   mae: 0.091138   val_loss: 0.010448   val_mae: 0.077137\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013451   mae: 0.089531   val_loss: 0.011408   val_mae: 0.080802\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013667   mae: 0.090309   val_loss: 0.011598   val_mae: 0.082957\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013756   mae: 0.090821   val_loss: 0.010054   val_mae: 0.076312\n",
      "Total:\n",
      "\t \ttime: 0h 1m 54s   loss: 0.013683   mae: 0.090436   val_loss: 0.010836   val_mae: 0.079218\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014116   mae: 0.091796   val_loss: 0.010703   val_mae: 0.079335\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014285   mae: 0.092728   val_loss: 0.012612   val_mae: 0.087325\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014078   mae: 0.092159   val_loss: 0.010438   val_mae: 0.077284\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.013974   mae: 0.091649   val_loss: 0.012571   val_mae: 0.085551\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014431   mae: 0.093029   val_loss: 0.010712   val_mae: 0.079837\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014280   mae: 0.092881   val_loss: 0.010302   val_mae: 0.076124\n",
      "Total:\n",
      "\t \ttime: 0h 0m 23s   loss: 0.014194   mae: 0.092374   val_loss: 0.011223   val_mae: 0.080909\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013910   mae: 0.091017   val_loss: 0.010593   val_mae: 0.077897\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013942   mae: 0.091287   val_loss: 0.010561   val_mae: 0.078549\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013883   mae: 0.091151   val_loss: 0.010949   val_mae: 0.079883\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013690   mae: 0.090514   val_loss: 0.011501   val_mae: 0.081223\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013980   mae: 0.091465   val_loss: 0.010726   val_mae: 0.079697\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013894   mae: 0.091468   val_loss: 0.010170   val_mae: 0.076221\n",
      "Total:\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013883   mae: 0.091150   val_loss: 0.010750   val_mae: 0.078912\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013704   mae: 0.090309   val_loss: 0.010537   val_mae: 0.077893\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013734   mae: 0.090727   val_loss: 0.011170   val_mae: 0.081213\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014033   mae: 0.091786   val_loss: 0.010391   val_mae: 0.077715\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013619   mae: 0.090043   val_loss: 0.011678   val_mae: 0.082257\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013802   mae: 0.090834   val_loss: 0.010613   val_mae: 0.078624\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013917   mae: 0.091612   val_loss: 0.010402   val_mae: 0.076696\n",
      "Total:\n",
      "\t \ttime: 0h 0m 44s   loss: 0.013802   mae: 0.090885   val_loss: 0.010799   val_mae: 0.079066\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013755   mae: 0.090955   val_loss: 0.010894   val_mae: 0.079755\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013517   mae: 0.089840   val_loss: 0.010449   val_mae: 0.077784\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013707   mae: 0.090631   val_loss: 0.010198   val_mae: 0.076470\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013554   mae: 0.090016   val_loss: 0.011417   val_mae: 0.081350\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013823   mae: 0.091024   val_loss: 0.010373   val_mae: 0.078151\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013962   mae: 0.091539   val_loss: 0.009979   val_mae: 0.074684\n",
      "Total:\n",
      "\t \ttime: 0h 0m 56s   loss: 0.013720   mae: 0.090668   val_loss: 0.010552   val_mae: 0.078032\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013640   mae: 0.090221   val_loss: 0.010476   val_mae: 0.077494\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013683   mae: 0.090281   val_loss: 0.011099   val_mae: 0.079715\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013711   mae: 0.091081   val_loss: 0.010349   val_mae: 0.077200\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013435   mae: 0.089847   val_loss: 0.011367   val_mae: 0.080760\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013678   mae: 0.090327   val_loss: 0.010163   val_mae: 0.077211\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013669   mae: 0.090580   val_loss: 0.010359   val_mae: 0.076263\n",
      "Total:\n",
      "\t \ttime: 0h 1m 6s   loss: 0.013636   mae: 0.090390   val_loss: 0.010636   val_mae: 0.078107\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.021111   mae: 0.115745   val_loss: 0.016417   val_mae: 0.102204\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.021355   mae: 0.117170   val_loss: 0.017630   val_mae: 0.106989\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.021828   mae: 0.118730   val_loss: 0.017890   val_mae: 0.108007\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.017924   mae: 0.105812   val_loss: 0.015460   val_mae: 0.098029\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.019248   mae: 0.110554   val_loss: 0.015329   val_mae: 0.098218\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.040283   mae: 0.159033   val_loss: 0.037049   val_mae: 0.151285\n",
      "Total:\n",
      "\t \ttime: 0h 0m 58s   loss: 0.023625   mae: 0.121174   val_loss: 0.019963   val_mae: 0.110789\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.016593   mae: 0.100313   val_loss: 0.013228   val_mae: 0.089279\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.015696   mae: 0.098812   val_loss: 0.013219   val_mae: 0.090990\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.015766   mae: 0.098888   val_loss: 0.012048   val_mae: 0.086862\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.015999   mae: 0.099253   val_loss: 0.014040   val_mae: 0.092602\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.016176   mae: 0.099756   val_loss: 0.012964   val_mae: 0.088727\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.015830   mae: 0.098639   val_loss: 0.012158   val_mae: 0.084608\n",
      "Total:\n",
      "\t \ttime: 0h 1m 39s   loss: 0.016010   mae: 0.099277   val_loss: 0.012943   val_mae: 0.088845\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.014722   mae: 0.094173   val_loss: 0.011669   val_mae: 0.083492\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.014616   mae: 0.094213   val_loss: 0.011675   val_mae: 0.083715\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014715   mae: 0.094825   val_loss: 0.010717   val_mae: 0.080276\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014710   mae: 0.094455   val_loss: 0.012795   val_mae: 0.087175\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014824   mae: 0.094839   val_loss: 0.011711   val_mae: 0.083893\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.014609   mae: 0.094603   val_loss: 0.011072   val_mae: 0.080724\n",
      "Total:\n",
      "\t \ttime: 0h 2m 17s   loss: 0.014699   mae: 0.094518   val_loss: 0.011606   val_mae: 0.083213\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.014214   mae: 0.092263   val_loss: 0.011240   val_mae: 0.081693\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.014317   mae: 0.092928   val_loss: 0.011337   val_mae: 0.081990\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.014676   mae: 0.094174   val_loss: 0.011097   val_mae: 0.080801\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.014160   mae: 0.092211   val_loss: 0.012165   val_mae: 0.084604\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.014249   mae: 0.092915   val_loss: 0.011248   val_mae: 0.081769\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.014431   mae: 0.093412   val_loss: 0.010666   val_mae: 0.078852\n",
      "Total:\n",
      "\t \ttime: 0h 3m 3s   loss: 0.014341   mae: 0.092984   val_loss: 0.011292   val_mae: 0.081618\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013849   mae: 0.091291   val_loss: 0.010881   val_mae: 0.080169\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.014192   mae: 0.092738   val_loss: 0.011206   val_mae: 0.081579\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013915   mae: 0.091579   val_loss: 0.010447   val_mae: 0.077915\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.014426   mae: 0.093224   val_loss: 0.012417   val_mae: 0.085417\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.015053   mae: 0.095635   val_loss: 0.011959   val_mae: 0.084661\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.014448   mae: 0.093667   val_loss: 0.010417   val_mae: 0.077926\n",
      "Total:\n",
      "\t \ttime: 0h 3m 42s   loss: 0.014314   mae: 0.093022   val_loss: 0.011221   val_mae: 0.081278\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.025485   mae: 0.130440   val_loss: 0.020899   val_mae: 0.118642\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.024053   mae: 0.125275   val_loss: 0.020762   val_mae: 0.116299\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.024963   mae: 0.126723   val_loss: 0.021153   val_mae: 0.116888\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.023862   mae: 0.125638   val_loss: 0.020508   val_mae: 0.115847\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.025554   mae: 0.129523   val_loss: 0.020888   val_mae: 0.117226\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.028454   mae: 0.138464   val_loss: 0.023323   val_mae: 0.125377\n",
      "Total:\n",
      "\t \ttime: 0h 0m 36s   loss: 0.025395   mae: 0.129344   val_loss: 0.021255   val_mae: 0.118380\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.015978   mae: 0.098896   val_loss: 0.012384   val_mae: 0.086695\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.025332   mae: 0.129707   val_loss: 0.023066   val_mae: 0.124811\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.023152   mae: 0.123657   val_loss: 0.019565   val_mae: 0.113708\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.017888   mae: 0.105681   val_loss: 0.015964   val_mae: 0.098986\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.017128   mae: 0.103270   val_loss: 0.013691   val_mae: 0.092710\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.017577   mae: 0.104181   val_loss: 0.014026   val_mae: 0.091931\n",
      "Total:\n",
      "\t \ttime: 0h 0m 57s   loss: 0.019509   mae: 0.110899   val_loss: 0.016450   val_mae: 0.101474\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.014996   mae: 0.095258   val_loss: 0.011662   val_mae: 0.083638\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.014719   mae: 0.094338   val_loss: 0.011770   val_mae: 0.084232\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.015121   mae: 0.095809   val_loss: 0.011898   val_mae: 0.084365\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.014941   mae: 0.095330   val_loss: 0.013203   val_mae: 0.089341\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014987   mae: 0.095432   val_loss: 0.011809   val_mae: 0.084053\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.015680   mae: 0.098216   val_loss: 0.011666   val_mae: 0.083273\n",
      "Total:\n",
      "\t \ttime: 0h 1m 20s   loss: 0.015074   mae: 0.095731   val_loss: 0.012001   val_mae: 0.084817\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014287   mae: 0.092388   val_loss: 0.011194   val_mae: 0.081030\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014498   mae: 0.093775   val_loss: 0.011604   val_mae: 0.083659\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014654   mae: 0.094634   val_loss: 0.011185   val_mae: 0.081944\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014298   mae: 0.092998   val_loss: 0.012251   val_mae: 0.085507\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.015237   mae: 0.096328   val_loss: 0.011791   val_mae: 0.084176\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.015127   mae: 0.095806   val_loss: 0.011539   val_mae: 0.082416\n",
      "Total:\n",
      "\t \ttime: 0h 1m 42s   loss: 0.014684   mae: 0.094321   val_loss: 0.011594   val_mae: 0.083122\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.014623   mae: 0.093873   val_loss: 0.011690   val_mae: 0.083271\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.014744   mae: 0.094267   val_loss: 0.011777   val_mae: 0.084181\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.015610   mae: 0.098260   val_loss: 0.011694   val_mae: 0.085136\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.014110   mae: 0.092226   val_loss: 0.012140   val_mae: 0.084711\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.014433   mae: 0.093605   val_loss: 0.011259   val_mae: 0.082246\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.015802   mae: 0.097873   val_loss: 0.011996   val_mae: 0.083957\n",
      "Total:\n",
      "\t \ttime: 0h 2m 3s   loss: 0.014887   mae: 0.095017   val_loss: 0.011759   val_mae: 0.083917\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.030906   mae: 0.144062   val_loss: 0.025458   val_mae: 0.131220\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.042986   mae: 0.168747   val_loss: 0.040277   val_mae: 0.163521\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.044874   mae: 0.173402   val_loss: 0.043524   val_mae: 0.171397\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.028012   mae: 0.135860   val_loss: 0.024834   val_mae: 0.128279\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.038112   mae: 0.160995   val_loss: 0.033527   val_mae: 0.153020\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.031640   mae: 0.145962   val_loss: 0.027481   val_mae: 0.136686\n",
      "Total:\n",
      "\t \ttime: 0h 0m 27s   loss: 0.036088   mae: 0.154838   val_loss: 0.032517   val_mae: 0.147354\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.028030   mae: 0.137317   val_loss: 0.023523   val_mae: 0.126744\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.021927   mae: 0.118844   val_loss: 0.019068   val_mae: 0.111609\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.026093   mae: 0.131442   val_loss: 0.023285   val_mae: 0.125096\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.021496   mae: 0.118582   val_loss: 0.019026   val_mae: 0.111808\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.035216   mae: 0.151468   val_loss: 0.031810   val_mae: 0.144320\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.029852   mae: 0.142060   val_loss: 0.025811   val_mae: 0.132255\n",
      "Total:\n",
      "\t \ttime: 0h 0m 38s   loss: 0.027102   mae: 0.133285   val_loss: 0.023754   val_mae: 0.125305\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.018124   mae: 0.108117   val_loss: 0.015023   val_mae: 0.098262\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.019592   mae: 0.111565   val_loss: 0.016322   val_mae: 0.102457\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.016954   mae: 0.103207   val_loss: 0.013369   val_mae: 0.091896\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.017408   mae: 0.104278   val_loss: 0.015299   val_mae: 0.097989\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.015798   mae: 0.098546   val_loss: 0.012985   val_mae: 0.089481\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.020449   mae: 0.114009   val_loss: 0.016800   val_mae: 0.102335\n",
      "Total:\n",
      "\t \ttime: 0h 0m 48s   loss: 0.018054   mae: 0.106620   val_loss: 0.014966   val_mae: 0.097070\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.015929   mae: 0.098616   val_loss: 0.012572   val_mae: 0.087407\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.015793   mae: 0.098486   val_loss: 0.012897   val_mae: 0.088772\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.016204   mae: 0.101034   val_loss: 0.012928   val_mae: 0.090418\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.018304   mae: 0.107245   val_loss: 0.015469   val_mae: 0.097800\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.016902   mae: 0.102744   val_loss: 0.013344   val_mae: 0.091711\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.016038   mae: 0.099191   val_loss: 0.012031   val_mae: 0.084392\n",
      "Total:\n",
      "\t \ttime: 0h 1m 1s   loss: 0.016528   mae: 0.101219   val_loss: 0.013207   val_mae: 0.090083\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014793   mae: 0.094629   val_loss: 0.011725   val_mae: 0.083909\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014954   mae: 0.095556   val_loss: 0.012112   val_mae: 0.086004\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014900   mae: 0.094950   val_loss: 0.011477   val_mae: 0.083554\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014915   mae: 0.095504   val_loss: 0.012889   val_mae: 0.088381\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.015234   mae: 0.096857   val_loss: 0.011829   val_mae: 0.085422\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.015792   mae: 0.098242   val_loss: 0.011899   val_mae: 0.083991\n",
      "Total:\n",
      "\t \ttime: 0h 1m 12s   loss: 0.015098   mae: 0.095956   val_loss: 0.011989   val_mae: 0.085210\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014173   mae: 0.092178   val_loss: 0.010852   val_mae: 0.080349\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014305   mae: 0.092669   val_loss: 0.010901   val_mae: 0.080587\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014142   mae: 0.092283   val_loss: 0.010705   val_mae: 0.078337\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013939   mae: 0.091566   val_loss: 0.011734   val_mae: 0.082578\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014443   mae: 0.092900   val_loss: 0.011021   val_mae: 0.079774\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014234   mae: 0.092468   val_loss: 0.010462   val_mae: 0.077297\n",
      "Total:\n",
      "\t \ttime: 0h 1m 0s   loss: 0.014206   mae: 0.092344   val_loss: 0.010946   val_mae: 0.079820\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013842   mae: 0.091034   val_loss: 0.010597   val_mae: 0.078236\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013955   mae: 0.091402   val_loss: 0.011248   val_mae: 0.081323\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013923   mae: 0.091533   val_loss: 0.010518   val_mae: 0.077568\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013691   mae: 0.090744   val_loss: 0.011636   val_mae: 0.082538\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014031   mae: 0.091751   val_loss: 0.010615   val_mae: 0.078704\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013958   mae: 0.091920   val_loss: 0.010201   val_mae: 0.076478\n",
      "Total:\n",
      "\t \ttime: 0h 1m 39s   loss: 0.013900   mae: 0.091397   val_loss: 0.010803   val_mae: 0.079141\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013633   mae: 0.090199   val_loss: 0.010557   val_mae: 0.078098\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013759   mae: 0.090627   val_loss: 0.012004   val_mae: 0.084578\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013810   mae: 0.091091   val_loss: 0.010653   val_mae: 0.078710\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013430   mae: 0.089559   val_loss: 0.011494   val_mae: 0.081223\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013844   mae: 0.091005   val_loss: 0.010681   val_mae: 0.078946\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013823   mae: 0.091287   val_loss: 0.009930   val_mae: 0.075128\n",
      "Total:\n",
      "\t \ttime: 0h 2m 19s   loss: 0.013717   mae: 0.090628   val_loss: 0.010886   val_mae: 0.079447\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013625   mae: 0.090283   val_loss: 0.010461   val_mae: 0.077629\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.013642   mae: 0.090471   val_loss: 0.010415   val_mae: 0.077680\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013758   mae: 0.090968   val_loss: 0.010121   val_mae: 0.076371\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013351   mae: 0.089215   val_loss: 0.011514   val_mae: 0.081559\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.013550   mae: 0.089983   val_loss: 0.010688   val_mae: 0.078507\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.013817   mae: 0.091365   val_loss: 0.010217   val_mae: 0.076202\n",
      "Total:\n",
      "\t \ttime: 0h 3m 3s   loss: 0.013624   mae: 0.090381   val_loss: 0.010569   val_mae: 0.077991\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013542   mae: 0.089970   val_loss: 0.010555   val_mae: 0.078387\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013607   mae: 0.090389   val_loss: 0.010722   val_mae: 0.078885\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013648   mae: 0.090433   val_loss: 0.010361   val_mae: 0.076718\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013338   mae: 0.089275   val_loss: 0.011604   val_mae: 0.081503\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013562   mae: 0.089949   val_loss: 0.010475   val_mae: 0.077801\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013709   mae: 0.090705   val_loss: 0.010185   val_mae: 0.075802\n",
      "Total:\n",
      "\t \ttime: 0h 3m 46s   loss: 0.013568   mae: 0.090120   val_loss: 0.010650   val_mae: 0.078183\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014331   mae: 0.092509   val_loss: 0.011402   val_mae: 0.081683\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014668   mae: 0.094301   val_loss: 0.011429   val_mae: 0.082007\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014409   mae: 0.093147   val_loss: 0.011058   val_mae: 0.080678\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013873   mae: 0.090947   val_loss: 0.011595   val_mae: 0.081788\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014242   mae: 0.092709   val_loss: 0.010820   val_mae: 0.080072\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014632   mae: 0.094039   val_loss: 0.010516   val_mae: 0.078097\n",
      "Total:\n",
      "\t \ttime: 0h 0m 36s   loss: 0.014359   mae: 0.092942   val_loss: 0.011137   val_mae: 0.080721\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014095   mae: 0.092064   val_loss: 0.010847   val_mae: 0.079984\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014125   mae: 0.092120   val_loss: 0.010932   val_mae: 0.080260\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013939   mae: 0.091649   val_loss: 0.010581   val_mae: 0.077967\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013479   mae: 0.089628   val_loss: 0.011683   val_mae: 0.082094\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013832   mae: 0.091026   val_loss: 0.010669   val_mae: 0.079487\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013890   mae: 0.091480   val_loss: 0.010125   val_mae: 0.075936\n",
      "Total:\n",
      "\t \ttime: 0h 0m 57s   loss: 0.013893   mae: 0.091328   val_loss: 0.010806   val_mae: 0.079288\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013639   mae: 0.090343   val_loss: 0.010608   val_mae: 0.078443\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013698   mae: 0.090326   val_loss: 0.010655   val_mae: 0.078560\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013686   mae: 0.090768   val_loss: 0.010121   val_mae: 0.075918\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013574   mae: 0.090356   val_loss: 0.011520   val_mae: 0.081785\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013794   mae: 0.090764   val_loss: 0.010421   val_mae: 0.077782\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014101   mae: 0.092337   val_loss: 0.010213   val_mae: 0.076571\n",
      "Total:\n",
      "\t \ttime: 0h 1m 19s   loss: 0.013749   mae: 0.090816   val_loss: 0.010590   val_mae: 0.078176\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013602   mae: 0.090067   val_loss: 0.010593   val_mae: 0.078182\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013657   mae: 0.090321   val_loss: 0.010749   val_mae: 0.079527\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013666   mae: 0.090507   val_loss: 0.010767   val_mae: 0.078785\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013346   mae: 0.089227   val_loss: 0.011519   val_mae: 0.081573\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013793   mae: 0.090834   val_loss: 0.010395   val_mae: 0.077607\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013663   mae: 0.090469   val_loss: 0.010068   val_mae: 0.075509\n",
      "Total:\n",
      "\t \ttime: 0h 1m 41s   loss: 0.013621   mae: 0.090238   val_loss: 0.010682   val_mae: 0.078531\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013560   mae: 0.089891   val_loss: 0.010636   val_mae: 0.078302\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013525   mae: 0.089960   val_loss: 0.011148   val_mae: 0.080946\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013534   mae: 0.090227   val_loss: 0.010435   val_mae: 0.077450\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013391   mae: 0.089310   val_loss: 0.011411   val_mae: 0.080458\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013702   mae: 0.090518   val_loss: 0.010836   val_mae: 0.079433\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013776   mae: 0.091178   val_loss: 0.010019   val_mae: 0.075432\n",
      "Total:\n",
      "\t \ttime: 0h 2m 2s   loss: 0.013581   mae: 0.090181   val_loss: 0.010748   val_mae: 0.078670\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014546   mae: 0.093832   val_loss: 0.011189   val_mae: 0.080909\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014487   mae: 0.093767   val_loss: 0.011337   val_mae: 0.082685\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014963   mae: 0.095381   val_loss: 0.011118   val_mae: 0.081355\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014148   mae: 0.092213   val_loss: 0.012266   val_mae: 0.084411\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014474   mae: 0.093644   val_loss: 0.011185   val_mae: 0.082081\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014875   mae: 0.095098   val_loss: 0.010920   val_mae: 0.079899\n",
      "Total:\n",
      "\t \ttime: 0h 0m 26s   loss: 0.014582   mae: 0.093989   val_loss: 0.011336   val_mae: 0.081890\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013877   mae: 0.091389   val_loss: 0.010740   val_mae: 0.079480\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014069   mae: 0.092086   val_loss: 0.011285   val_mae: 0.081946\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013876   mae: 0.091472   val_loss: 0.010150   val_mae: 0.076423\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013816   mae: 0.090991   val_loss: 0.011737   val_mae: 0.082588\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013816   mae: 0.090789   val_loss: 0.010410   val_mae: 0.077914\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014000   mae: 0.091932   val_loss: 0.010226   val_mae: 0.076657\n",
      "Total:\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013909   mae: 0.091443   val_loss: 0.010758   val_mae: 0.079168\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013634   mae: 0.090375   val_loss: 0.010588   val_mae: 0.078364\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013762   mae: 0.090937   val_loss: 0.010734   val_mae: 0.080076\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014013   mae: 0.091916   val_loss: 0.010815   val_mae: 0.079807\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013515   mae: 0.089991   val_loss: 0.011788   val_mae: 0.082678\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013694   mae: 0.090298   val_loss: 0.010638   val_mae: 0.079141\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014040   mae: 0.091965   val_loss: 0.010034   val_mae: 0.075354\n",
      "Total:\n",
      "\t \ttime: 0h 0m 49s   loss: 0.013776   mae: 0.090914   val_loss: 0.010766   val_mae: 0.079237\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013722   mae: 0.090423   val_loss: 0.010478   val_mae: 0.077905\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013660   mae: 0.090508   val_loss: 0.010517   val_mae: 0.078945\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013665   mae: 0.090829   val_loss: 0.010196   val_mae: 0.076114\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013354   mae: 0.089294   val_loss: 0.011617   val_mae: 0.081860\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013833   mae: 0.091085   val_loss: 0.010630   val_mae: 0.079280\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013957   mae: 0.091758   val_loss: 0.010024   val_mae: 0.075584\n",
      "Total:\n",
      "\t \ttime: 0h 1m 0s   loss: 0.013699   mae: 0.090649   val_loss: 0.010577   val_mae: 0.078281\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013564   mae: 0.090011   val_loss: 0.010496   val_mae: 0.078014\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013664   mae: 0.090339   val_loss: 0.011241   val_mae: 0.081843\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013597   mae: 0.090421   val_loss: 0.010441   val_mae: 0.077846\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013304   mae: 0.089209   val_loss: 0.011443   val_mae: 0.081164\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013461   mae: 0.089647   val_loss: 0.010374   val_mae: 0.077981\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013669   mae: 0.090566   val_loss: 0.009925   val_mae: 0.075200\n",
      "Total:\n",
      "\t \ttime: 0h 1m 11s   loss: 0.013543   mae: 0.090032   val_loss: 0.010653   val_mae: 0.078675\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014361   mae: 0.092571   val_loss: 0.010997   val_mae: 0.081442\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014335   mae: 0.092833   val_loss: 0.011565   val_mae: 0.082827\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014430   mae: 0.093051   val_loss: 0.011662   val_mae: 0.084845\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014066   mae: 0.091730   val_loss: 0.012042   val_mae: 0.083839\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014421   mae: 0.092964   val_loss: 0.012259   val_mae: 0.085003\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014545   mae: 0.093617   val_loss: 0.010168   val_mae: 0.076436\n",
      "Total:\n",
      "\t \ttime: 0h 0m 57s   loss: 0.014360   mae: 0.092794   val_loss: 0.011449   val_mae: 0.082399\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014038   mae: 0.091476   val_loss: 0.011053   val_mae: 0.080070\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014074   mae: 0.091799   val_loss: 0.010500   val_mae: 0.077620\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014286   mae: 0.092774   val_loss: 0.010761   val_mae: 0.078247\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013783   mae: 0.090678   val_loss: 0.012056   val_mae: 0.083305\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014126   mae: 0.092098   val_loss: 0.011430   val_mae: 0.081859\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014193   mae: 0.092275   val_loss: 0.009856   val_mae: 0.074723\n",
      "Total:\n",
      "\t \ttime: 0h 1m 37s   loss: 0.014083   mae: 0.091850   val_loss: 0.010943   val_mae: 0.079304\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.014022   mae: 0.091466   val_loss: 0.011081   val_mae: 0.080417\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014089   mae: 0.091822   val_loss: 0.010822   val_mae: 0.078639\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.014047   mae: 0.092198   val_loss: 0.010444   val_mae: 0.077115\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013790   mae: 0.090722   val_loss: 0.011479   val_mae: 0.081880\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013945   mae: 0.091450   val_loss: 0.010616   val_mae: 0.078531\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014100   mae: 0.091989   val_loss: 0.010088   val_mae: 0.076352\n",
      "Total:\n",
      "\t \ttime: 0h 2m 19s   loss: 0.013999   mae: 0.091608   val_loss: 0.010755   val_mae: 0.078822\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013936   mae: 0.091203   val_loss: 0.010792   val_mae: 0.079799\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.014098   mae: 0.091849   val_loss: 0.010714   val_mae: 0.078358\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013954   mae: 0.091501   val_loss: 0.010649   val_mae: 0.078152\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.013676   mae: 0.090408   val_loss: 0.011411   val_mae: 0.081286\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013907   mae: 0.091346   val_loss: 0.011993   val_mae: 0.083816\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.014064   mae: 0.091886   val_loss: 0.010189   val_mae: 0.076180\n",
      "Total:\n",
      "\t \ttime: 0h 3m 5s   loss: 0.013939   mae: 0.091366   val_loss: 0.010958   val_mae: 0.079599\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013886   mae: 0.090879   val_loss: 0.010492   val_mae: 0.077712\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013745   mae: 0.090597   val_loss: 0.010669   val_mae: 0.078202\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.014014   mae: 0.091757   val_loss: 0.010458   val_mae: 0.077591\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013547   mae: 0.089901   val_loss: 0.012220   val_mae: 0.084160\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013988   mae: 0.091581   val_loss: 0.010648   val_mae: 0.078342\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013915   mae: 0.091239   val_loss: 0.010529   val_mae: 0.076714\n",
      "Total:\n",
      "\t \ttime: 0h 3m 40s   loss: 0.013849   mae: 0.090992   val_loss: 0.010836   val_mae: 0.078787\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014176   mae: 0.091920   val_loss: 0.011024   val_mae: 0.079584\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014299   mae: 0.092794   val_loss: 0.010909   val_mae: 0.080178\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014397   mae: 0.093082   val_loss: 0.011330   val_mae: 0.082500\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014188   mae: 0.092159   val_loss: 0.012025   val_mae: 0.083567\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014228   mae: 0.092510   val_loss: 0.012563   val_mae: 0.087459\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014660   mae: 0.094334   val_loss: 0.010570   val_mae: 0.077255\n",
      "Total:\n",
      "\t \ttime: 0h 0m 36s   loss: 0.014325   mae: 0.092800   val_loss: 0.011403   val_mae: 0.081757\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014004   mae: 0.091637   val_loss: 0.010547   val_mae: 0.078481\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013917   mae: 0.091257   val_loss: 0.010639   val_mae: 0.078980\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014093   mae: 0.092135   val_loss: 0.010579   val_mae: 0.078277\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013815   mae: 0.090987   val_loss: 0.011696   val_mae: 0.083144\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013995   mae: 0.091382   val_loss: 0.011767   val_mae: 0.083309\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014199   mae: 0.092612   val_loss: 0.010501   val_mae: 0.076989\n",
      "Total:\n",
      "\t \ttime: 0h 0m 57s   loss: 0.014004   mae: 0.091668   val_loss: 0.010955   val_mae: 0.079863\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013840   mae: 0.090978   val_loss: 0.010837   val_mae: 0.079833\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013929   mae: 0.091177   val_loss: 0.010686   val_mae: 0.078859\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013937   mae: 0.091237   val_loss: 0.010541   val_mae: 0.078072\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013648   mae: 0.090391   val_loss: 0.011825   val_mae: 0.083486\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013921   mae: 0.091325   val_loss: 0.011675   val_mae: 0.084501\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013936   mae: 0.091575   val_loss: 0.009912   val_mae: 0.074444\n",
      "Total:\n",
      "\t \ttime: 0h 1m 19s   loss: 0.013868   mae: 0.091114   val_loss: 0.010913   val_mae: 0.079866\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013816   mae: 0.090690   val_loss: 0.010772   val_mae: 0.079269\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013905   mae: 0.091245   val_loss: 0.010605   val_mae: 0.078642\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013886   mae: 0.091167   val_loss: 0.010206   val_mae: 0.076798\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013658   mae: 0.090195   val_loss: 0.014299   val_mae: 0.092193\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014026   mae: 0.091731   val_loss: 0.010500   val_mae: 0.077622\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013988   mae: 0.091654   val_loss: 0.010311   val_mae: 0.076544\n",
      "Total:\n",
      "\t \ttime: 0h 1m 40s   loss: 0.013880   mae: 0.091114   val_loss: 0.011116   val_mae: 0.080178\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013741   mae: 0.090505   val_loss: 0.010681   val_mae: 0.078048\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013674   mae: 0.090321   val_loss: 0.010814   val_mae: 0.080654\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013835   mae: 0.090996   val_loss: 0.010417   val_mae: 0.076882\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013625   mae: 0.090297   val_loss: 0.012301   val_mae: 0.084881\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013721   mae: 0.090612   val_loss: 0.010619   val_mae: 0.079319\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013795   mae: 0.091042   val_loss: 0.010844   val_mae: 0.078375\n",
      "Total:\n",
      "\t \ttime: 0h 2m 3s   loss: 0.013732   mae: 0.090629   val_loss: 0.010946   val_mae: 0.079693\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014294   mae: 0.092386   val_loss: 0.011066   val_mae: 0.080358\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014939   mae: 0.094808   val_loss: 0.012058   val_mae: 0.084048\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014240   mae: 0.092402   val_loss: 0.011620   val_mae: 0.083270\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.013952   mae: 0.091264   val_loss: 0.011976   val_mae: 0.082795\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014348   mae: 0.092643   val_loss: 0.010991   val_mae: 0.081325\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014540   mae: 0.093538   val_loss: 0.010157   val_mae: 0.075673\n",
      "Total:\n",
      "\t \ttime: 0h 0m 26s   loss: 0.014385   mae: 0.092840   val_loss: 0.011311   val_mae: 0.081245\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013911   mae: 0.091534   val_loss: 0.011123   val_mae: 0.080861\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013926   mae: 0.091198   val_loss: 0.010857   val_mae: 0.079697\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013994   mae: 0.091822   val_loss: 0.010362   val_mae: 0.076979\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013932   mae: 0.091251   val_loss: 0.011481   val_mae: 0.081060\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014016   mae: 0.091663   val_loss: 0.010490   val_mae: 0.078779\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014084   mae: 0.092188   val_loss: 0.010215   val_mae: 0.076047\n",
      "Total:\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013977   mae: 0.091609   val_loss: 0.010755   val_mae: 0.078904\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013817   mae: 0.090811   val_loss: 0.011138   val_mae: 0.080487\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013811   mae: 0.091367   val_loss: 0.010712   val_mae: 0.078576\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013909   mae: 0.091405   val_loss: 0.010426   val_mae: 0.076918\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013569   mae: 0.089773   val_loss: 0.011914   val_mae: 0.083274\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013789   mae: 0.090826   val_loss: 0.010414   val_mae: 0.078558\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013827   mae: 0.091196   val_loss: 0.010088   val_mae: 0.076144\n",
      "Total:\n",
      "\t \ttime: 0h 0m 49s   loss: 0.013787   mae: 0.090896   val_loss: 0.010782   val_mae: 0.078993\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013743   mae: 0.090576   val_loss: 0.011010   val_mae: 0.080241\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013784   mae: 0.090918   val_loss: 0.011053   val_mae: 0.080753\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013859   mae: 0.091346   val_loss: 0.010179   val_mae: 0.076473\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013488   mae: 0.089684   val_loss: 0.011496   val_mae: 0.080809\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013662   mae: 0.090208   val_loss: 0.010566   val_mae: 0.078668\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013915   mae: 0.091387   val_loss: 0.009885   val_mae: 0.074801\n",
      "Total:\n",
      "\t \ttime: 0h 1m 1s   loss: 0.013742   mae: 0.090686   val_loss: 0.010698   val_mae: 0.078624\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013793   mae: 0.090553   val_loss: 0.010621   val_mae: 0.078468\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013691   mae: 0.090657   val_loss: 0.010429   val_mae: 0.077527\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013739   mae: 0.090852   val_loss: 0.010155   val_mae: 0.076172\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013425   mae: 0.089324   val_loss: 0.011854   val_mae: 0.082688\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013695   mae: 0.090454   val_loss: 0.010805   val_mae: 0.079911\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013989   mae: 0.091630   val_loss: 0.010205   val_mae: 0.076284\n",
      "Total:\n",
      "\t \ttime: 0h 1m 11s   loss: 0.013722   mae: 0.090578   val_loss: 0.010678   val_mae: 0.078509\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.021459   mae: 0.115789   val_loss: 0.017212   val_mae: 0.104226\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.030384   mae: 0.142913   val_loss: 0.027010   val_mae: 0.135162\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.018827   mae: 0.109690   val_loss: 0.013942   val_mae: 0.094670\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.038657   mae: 0.154595   val_loss: 0.036484   val_mae: 0.150521\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.023681   mae: 0.124640   val_loss: 0.018552   val_mae: 0.109257\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.021764   mae: 0.118638   val_loss: 0.017661   val_mae: 0.105757\n",
      "Total:\n",
      "\t \ttime: 0h 1m 2s   loss: 0.025795   mae: 0.127711   val_loss: 0.021810   val_mae: 0.116599\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.017573   mae: 0.103291   val_loss: 0.014048   val_mae: 0.092488\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.019830   mae: 0.110688   val_loss: 0.016163   val_mae: 0.100496\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.015827   mae: 0.098810   val_loss: 0.011944   val_mae: 0.085997\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.016179   mae: 0.099161   val_loss: 0.013254   val_mae: 0.089511\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.028750   mae: 0.134294   val_loss: 0.026161   val_mae: 0.126587\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.016403   mae: 0.100671   val_loss: 0.012338   val_mae: 0.086137\n",
      "Total:\n",
      "\t \ttime: 0h 1m 46s   loss: 0.019094   mae: 0.107819   val_loss: 0.015651   val_mae: 0.096869\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 25s   loss: 0.014659   mae: 0.094466   val_loss: 0.011365   val_mae: 0.082902\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014781   mae: 0.094529   val_loss: 0.011651   val_mae: 0.083192\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014661   mae: 0.093950   val_loss: 0.010825   val_mae: 0.079609\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014863   mae: 0.095122   val_loss: 0.012803   val_mae: 0.087690\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014347   mae: 0.093096   val_loss: 0.010892   val_mae: 0.079717\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014954   mae: 0.095533   val_loss: 0.011197   val_mae: 0.080473\n",
      "Total:\n",
      "\t \ttime: 0h 2m 28s   loss: 0.014711   mae: 0.094449   val_loss: 0.011455   val_mae: 0.082264\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.014043   mae: 0.091882   val_loss: 0.011014   val_mae: 0.080481\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 33s   loss: 0.014596   mae: 0.093575   val_loss: 0.011111   val_mae: 0.081308\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.014332   mae: 0.093404   val_loss: 0.010862   val_mae: 0.080153\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013842   mae: 0.091600   val_loss: 0.011974   val_mae: 0.084169\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.015699   mae: 0.097339   val_loss: 0.012624   val_mae: 0.086551\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.014933   mae: 0.094850   val_loss: 0.011054   val_mae: 0.080277\n",
      "Total:\n",
      "\t \ttime: 0h 3m 13s   loss: 0.014574   mae: 0.093775   val_loss: 0.011440   val_mae: 0.082156\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 40s   loss: 0.014012   mae: 0.091763   val_loss: 0.010970   val_mae: 0.080534\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.014311   mae: 0.092621   val_loss: 0.011382   val_mae: 0.082045\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013922   mae: 0.091471   val_loss: 0.010479   val_mae: 0.077416\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013618   mae: 0.090424   val_loss: 0.011720   val_mae: 0.082627\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.014183   mae: 0.092410   val_loss: 0.011152   val_mae: 0.080975\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.014127   mae: 0.092356   val_loss: 0.010260   val_mae: 0.076849\n",
      "Total:\n",
      "\t \ttime: 0h 3m 55s   loss: 0.014028   mae: 0.091841   val_loss: 0.010994   val_mae: 0.080074\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.037051   mae: 0.158103   val_loss: 0.031350   val_mae: 0.146820\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.030831   mae: 0.143636   val_loss: 0.027739   val_mae: 0.137242\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.024550   mae: 0.127237   val_loss: 0.020194   val_mae: 0.115684\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.027007   mae: 0.134265   val_loss: 0.022401   val_mae: 0.122046\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.034902   mae: 0.154659   val_loss: 0.030362   val_mae: 0.145616\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.048983   mae: 0.177655   val_loss: 0.046316   val_mae: 0.172783\n",
      "Total:\n",
      "\t \ttime: 0h 0m 43s   loss: 0.033887   mae: 0.149259   val_loss: 0.029727   val_mae: 0.140032\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.021609   mae: 0.118629   val_loss: 0.017437   val_mae: 0.105942\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.015479   mae: 0.096908   val_loss: 0.013028   val_mae: 0.089064\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.020674   mae: 0.115599   val_loss: 0.016473   val_mae: 0.103500\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.019597   mae: 0.110050   val_loss: 0.016658   val_mae: 0.102482\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.018301   mae: 0.106744   val_loss: 0.014051   val_mae: 0.092927\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.018956   mae: 0.110839   val_loss: 0.015673   val_mae: 0.099521\n",
      "Total:\n",
      "\t \ttime: 0h 1m 4s   loss: 0.019103   mae: 0.109795   val_loss: 0.015553   val_mae: 0.098906\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.033240   mae: 0.144095   val_loss: 0.031565   val_mae: 0.139800\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.018987   mae: 0.107558   val_loss: 0.014945   val_mae: 0.095261\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.016137   mae: 0.099480   val_loss: 0.012664   val_mae: 0.087532\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.015243   mae: 0.095834   val_loss: 0.013003   val_mae: 0.089024\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.016494   mae: 0.101643   val_loss: 0.013032   val_mae: 0.090700\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.019378   mae: 0.109241   val_loss: 0.015404   val_mae: 0.095904\n",
      "Total:\n",
      "\t \ttime: 0h 1m 28s   loss: 0.019913   mae: 0.109642   val_loss: 0.016769   val_mae: 0.099703\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.015086   mae: 0.095758   val_loss: 0.012215   val_mae: 0.085339\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.015305   mae: 0.096681   val_loss: 0.012357   val_mae: 0.086467\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.014507   mae: 0.093517   val_loss: 0.010642   val_mae: 0.078834\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.014321   mae: 0.093495   val_loss: 0.012416   val_mae: 0.086354\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.016555   mae: 0.099791   val_loss: 0.013019   val_mae: 0.087420\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.015169   mae: 0.096019   val_loss: 0.011364   val_mae: 0.081707\n",
      "Total:\n",
      "\t \ttime: 0h 1m 51s   loss: 0.015157   mae: 0.095877   val_loss: 0.012002   val_mae: 0.084354\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014401   mae: 0.092835   val_loss: 0.011608   val_mae: 0.082667\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014224   mae: 0.092633   val_loss: 0.011248   val_mae: 0.081679\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014278   mae: 0.093002   val_loss: 0.010806   val_mae: 0.079923\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.014127   mae: 0.092443   val_loss: 0.012157   val_mae: 0.084575\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.024154   mae: 0.124251   val_loss: 0.021589   val_mae: 0.116413\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.015039   mae: 0.096214   val_loss: 0.011155   val_mae: 0.081147\n",
      "Total:\n",
      "\t \ttime: 0h 2m 12s   loss: 0.016037   mae: 0.098563   val_loss: 0.013094   val_mae: 0.087734\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.048826   mae: 0.177406   val_loss: 0.046416   val_mae: 0.175441\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.034035   mae: 0.149742   val_loss: 0.029893   val_mae: 0.140596\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.034022   mae: 0.151542   val_loss: 0.030517   val_mae: 0.144755\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.030319   mae: 0.142835   val_loss: 0.026651   val_mae: 0.134960\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.032337   mae: 0.147361   val_loss: 0.028283   val_mae: 0.138677\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.038641   mae: 0.161478   val_loss: 0.034569   val_mae: 0.154303\n",
      "Total:\n",
      "\t \ttime: 0h 0m 32s   loss: 0.036363   mae: 0.155061   val_loss: 0.032722   val_mae: 0.148122\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.020795   mae: 0.115589   val_loss: 0.017152   val_mae: 0.104783\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.019593   mae: 0.111700   val_loss: 0.016903   val_mae: 0.103708\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.027089   mae: 0.133929   val_loss: 0.023680   val_mae: 0.125888\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.046316   mae: 0.172008   val_loss: 0.044019   val_mae: 0.169412\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.019594   mae: 0.112024   val_loss: 0.015550   val_mae: 0.099732\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.020719   mae: 0.116243   val_loss: 0.016910   val_mae: 0.104634\n",
      "Total:\n",
      "\t \ttime: 0h 0m 44s   loss: 0.025684   mae: 0.126915   val_loss: 0.022369   val_mae: 0.118026\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.020328   mae: 0.114662   val_loss: 0.016476   val_mae: 0.103813\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.020627   mae: 0.114001   val_loss: 0.017786   val_mae: 0.106624\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.028172   mae: 0.136663   val_loss: 0.023942   val_mae: 0.126998\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.016142   mae: 0.099462   val_loss: 0.014352   val_mae: 0.093534\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.040049   mae: 0.157472   val_loss: 0.038550   val_mae: 0.153643\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.018266   mae: 0.106912   val_loss: 0.015415   val_mae: 0.097419\n",
      "Total:\n",
      "\t \ttime: 0h 0m 56s   loss: 0.023931   mae: 0.121529   val_loss: 0.021087   val_mae: 0.113672\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.016206   mae: 0.100068   val_loss: 0.013183   val_mae: 0.090045\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.016102   mae: 0.100943   val_loss: 0.013443   val_mae: 0.092223\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.017377   mae: 0.104539   val_loss: 0.012958   val_mae: 0.090253\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014891   mae: 0.094856   val_loss: 0.013024   val_mae: 0.088377\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.015920   mae: 0.099861   val_loss: 0.012525   val_mae: 0.088922\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.015646   mae: 0.097998   val_loss: 0.012161   val_mae: 0.084941\n",
      "Total:\n",
      "\t \ttime: 0h 1m 9s   loss: 0.016023   mae: 0.099711   val_loss: 0.012882   val_mae: 0.089127\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.015131   mae: 0.096588   val_loss: 0.011795   val_mae: 0.085301\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.014709   mae: 0.094389   val_loss: 0.012277   val_mae: 0.086336\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.033252   mae: 0.144390   val_loss: 0.033009   val_mae: 0.142270\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.015592   mae: 0.097939   val_loss: 0.013853   val_mae: 0.091755\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.032198   mae: 0.140755   val_loss: 0.030361   val_mae: 0.136208\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.037266   mae: 0.153725   val_loss: 0.033525   val_mae: 0.144710\n",
      "Total:\n",
      "\t \ttime: 0h 1m 19s   loss: 0.024691   mae: 0.121298   val_loss: 0.022470   val_mae: 0.114430\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014433   mae: 0.093043   val_loss: 0.010950   val_mae: 0.080594\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014085   mae: 0.092037   val_loss: 0.011037   val_mae: 0.081077\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014415   mae: 0.093321   val_loss: 0.011569   val_mae: 0.080962\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014359   mae: 0.092938   val_loss: 0.012222   val_mae: 0.084746\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.015013   mae: 0.095428   val_loss: 0.011195   val_mae: 0.081307\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.015096   mae: 0.095593   val_loss: 0.010651   val_mae: 0.078315\n",
      "Total:\n",
      "\t \ttime: 0h 1m 2s   loss: 0.014567   mae: 0.093727   val_loss: 0.011271   val_mae: 0.081167\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013864   mae: 0.091269   val_loss: 0.010558   val_mae: 0.078575\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014032   mae: 0.091964   val_loss: 0.011173   val_mae: 0.080938\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014127   mae: 0.092261   val_loss: 0.010704   val_mae: 0.079165\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013804   mae: 0.090839   val_loss: 0.012202   val_mae: 0.084493\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013878   mae: 0.091178   val_loss: 0.010868   val_mae: 0.079844\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013882   mae: 0.091427   val_loss: 0.010352   val_mae: 0.076602\n",
      "Total:\n",
      "\t \ttime: 0h 1m 44s   loss: 0.013931   mae: 0.091490   val_loss: 0.010976   val_mae: 0.079936\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013696   mae: 0.090297   val_loss: 0.010739   val_mae: 0.078964\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013862   mae: 0.091193   val_loss: 0.010891   val_mae: 0.079974\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014200   mae: 0.093722   val_loss: 0.010768   val_mae: 0.080477\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 25s   loss: 0.013547   mae: 0.090000   val_loss: 0.011787   val_mae: 0.082744\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 25s   loss: 0.013832   mae: 0.090756   val_loss: 0.010619   val_mae: 0.078089\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013823   mae: 0.091204   val_loss: 0.010059   val_mae: 0.075654\n",
      "Total:\n",
      "\t \ttime: 0h 2m 27s   loss: 0.013827   mae: 0.091195   val_loss: 0.010811   val_mae: 0.079317\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013755   mae: 0.090756   val_loss: 0.011079   val_mae: 0.081705\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013775   mae: 0.090856   val_loss: 0.010608   val_mae: 0.078352\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013840   mae: 0.091136   val_loss: 0.010276   val_mae: 0.076733\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013480   mae: 0.089809   val_loss: 0.011482   val_mae: 0.081766\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013628   mae: 0.090445   val_loss: 0.010794   val_mae: 0.079829\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013840   mae: 0.091334   val_loss: 0.010345   val_mae: 0.077634\n",
      "Total:\n",
      "\t \ttime: 0h 3m 12s   loss: 0.013719   mae: 0.090722   val_loss: 0.010764   val_mae: 0.079337\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013550   mae: 0.090206   val_loss: 0.010451   val_mae: 0.077935\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013554   mae: 0.089860   val_loss: 0.010563   val_mae: 0.078574\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013867   mae: 0.092107   val_loss: 0.010245   val_mae: 0.077327\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013407   mae: 0.089455   val_loss: 0.011664   val_mae: 0.081971\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013659   mae: 0.090546   val_loss: 0.010431   val_mae: 0.077754\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 40s   loss: 0.013822   mae: 0.091905   val_loss: 0.010296   val_mae: 0.077486\n",
      "Total:\n",
      "\t \ttime: 0h 3m 57s   loss: 0.013643   mae: 0.090680   val_loss: 0.010609   val_mae: 0.078508\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014650   mae: 0.094240   val_loss: 0.011864   val_mae: 0.083809\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014302   mae: 0.092927   val_loss: 0.011864   val_mae: 0.084079\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014408   mae: 0.093135   val_loss: 0.010693   val_mae: 0.078301\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014090   mae: 0.091860   val_loss: 0.011796   val_mae: 0.082201\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014479   mae: 0.093356   val_loss: 0.011213   val_mae: 0.081237\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014975   mae: 0.095388   val_loss: 0.010861   val_mae: 0.079427\n",
      "Total:\n",
      "\t \ttime: 0h 0m 42s   loss: 0.014484   mae: 0.093484   val_loss: 0.011382   val_mae: 0.081509\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013906   mae: 0.091266   val_loss: 0.010857   val_mae: 0.079687\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013809   mae: 0.090897   val_loss: 0.010706   val_mae: 0.079295\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013817   mae: 0.091048   val_loss: 0.010303   val_mae: 0.076892\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.015277   mae: 0.098774   val_loss: 0.012920   val_mae: 0.089407\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013824   mae: 0.091168   val_loss: 0.010546   val_mae: 0.078698\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014423   mae: 0.093606   val_loss: 0.010417   val_mae: 0.078101\n",
      "Total:\n",
      "\t \ttime: 0h 1m 5s   loss: 0.014176   mae: 0.092793   val_loss: 0.010958   val_mae: 0.080347\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013639   mae: 0.090344   val_loss: 0.010670   val_mae: 0.078392\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013717   mae: 0.090697   val_loss: 0.010774   val_mae: 0.079733\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013797   mae: 0.090984   val_loss: 0.010334   val_mae: 0.077160\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013578   mae: 0.090106   val_loss: 0.011559   val_mae: 0.081535\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013646   mae: 0.090146   val_loss: 0.010587   val_mae: 0.078700\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013852   mae: 0.091348   val_loss: 0.010110   val_mae: 0.076215\n",
      "Total:\n",
      "\t \ttime: 0h 1m 28s   loss: 0.013705   mae: 0.090604   val_loss: 0.010672   val_mae: 0.078622\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013713   mae: 0.090595   val_loss: 0.010764   val_mae: 0.079207\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013572   mae: 0.089925   val_loss: 0.010503   val_mae: 0.078197\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013638   mae: 0.090436   val_loss: 0.010123   val_mae: 0.076093\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013534   mae: 0.089908   val_loss: 0.011402   val_mae: 0.081007\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013649   mae: 0.090612   val_loss: 0.010729   val_mae: 0.078787\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013805   mae: 0.091197   val_loss: 0.010354   val_mae: 0.077425\n",
      "Total:\n",
      "\t \ttime: 0h 1m 50s   loss: 0.013652   mae: 0.090446   val_loss: 0.010646   val_mae: 0.078453\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013636   mae: 0.090209   val_loss: 0.010762   val_mae: 0.078814\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013489   mae: 0.089883   val_loss: 0.010456   val_mae: 0.077898\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013626   mae: 0.090326   val_loss: 0.010270   val_mae: 0.076701\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013441   mae: 0.089621   val_loss: 0.011750   val_mae: 0.082580\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013585   mae: 0.090061   val_loss: 0.010247   val_mae: 0.077060\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013718   mae: 0.090597   val_loss: 0.010327   val_mae: 0.076476\n",
      "Total:\n",
      "\t \ttime: 0h 2m 13s   loss: 0.013582   mae: 0.090116   val_loss: 0.010635   val_mae: 0.078255\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014621   mae: 0.093516   val_loss: 0.011143   val_mae: 0.081052\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014432   mae: 0.093367   val_loss: 0.011691   val_mae: 0.083972\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.015086   mae: 0.095870   val_loss: 0.011176   val_mae: 0.081734\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014592   mae: 0.093622   val_loss: 0.012048   val_mae: 0.083634\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014323   mae: 0.092828   val_loss: 0.010946   val_mae: 0.080884\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.015433   mae: 0.097198   val_loss: 0.011492   val_mae: 0.082038\n",
      "Total:\n",
      "\t \ttime: 0h 0m 33s   loss: 0.014748   mae: 0.094400   val_loss: 0.011416   val_mae: 0.082219\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014118   mae: 0.092004   val_loss: 0.011184   val_mae: 0.081048\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013703   mae: 0.090682   val_loss: 0.010663   val_mae: 0.079181\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013994   mae: 0.091833   val_loss: 0.011310   val_mae: 0.081255\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013873   mae: 0.091265   val_loss: 0.012568   val_mae: 0.085037\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013890   mae: 0.091515   val_loss: 0.010632   val_mae: 0.079568\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014003   mae: 0.091777   val_loss: 0.010235   val_mae: 0.076956\n",
      "Total:\n",
      "\t \ttime: 0h 0m 46s   loss: 0.013930   mae: 0.091513   val_loss: 0.011099   val_mae: 0.080508\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013877   mae: 0.091153   val_loss: 0.010708   val_mae: 0.078937\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.015578   mae: 0.099706   val_loss: 0.012842   val_mae: 0.090187\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013771   mae: 0.091024   val_loss: 0.010397   val_mae: 0.077263\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.015734   mae: 0.100443   val_loss: 0.013459   val_mae: 0.091656\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013822   mae: 0.091022   val_loss: 0.010402   val_mae: 0.078573\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013913   mae: 0.091602   val_loss: 0.009993   val_mae: 0.075497\n",
      "Total:\n",
      "\t \ttime: 0h 0m 56s   loss: 0.014449   mae: 0.094158   val_loss: 0.011300   val_mae: 0.082019\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013714   mae: 0.090406   val_loss: 0.010569   val_mae: 0.077650\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013841   mae: 0.091248   val_loss: 0.010492   val_mae: 0.078404\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013706   mae: 0.090860   val_loss: 0.010205   val_mae: 0.076403\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013508   mae: 0.089797   val_loss: 0.011427   val_mae: 0.081345\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013608   mae: 0.090381   val_loss: 0.010652   val_mae: 0.079278\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013938   mae: 0.091931   val_loss: 0.010140   val_mae: 0.076300\n",
      "Total:\n",
      "\t \ttime: 0h 1m 7s   loss: 0.013719   mae: 0.090770   val_loss: 0.010581   val_mae: 0.078230\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013566   mae: 0.090254   val_loss: 0.010772   val_mae: 0.078865\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013636   mae: 0.090295   val_loss: 0.010681   val_mae: 0.079417\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013596   mae: 0.090450   val_loss: 0.010371   val_mae: 0.077145\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013323   mae: 0.089242   val_loss: 0.011523   val_mae: 0.080658\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013573   mae: 0.090162   val_loss: 0.010376   val_mae: 0.078052\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013870   mae: 0.091190   val_loss: 0.009929   val_mae: 0.075091\n",
      "Total:\n",
      "\t \ttime: 0h 1m 19s   loss: 0.013594   mae: 0.090266   val_loss: 0.010609   val_mae: 0.078205\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014279   mae: 0.092430   val_loss: 0.011008   val_mae: 0.079786\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014300   mae: 0.092638   val_loss: 0.011763   val_mae: 0.081882\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014530   mae: 0.093543   val_loss: 0.010529   val_mae: 0.078253\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014267   mae: 0.092658   val_loss: 0.011433   val_mae: 0.081077\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014515   mae: 0.093547   val_loss: 0.010879   val_mae: 0.079075\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.015057   mae: 0.096436   val_loss: 0.010690   val_mae: 0.080310\n",
      "Total:\n",
      "\t \ttime: 0h 1m 3s   loss: 0.014492   mae: 0.093542   val_loss: 0.011050   val_mae: 0.080064\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014110   mae: 0.091764   val_loss: 0.011178   val_mae: 0.079865\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014008   mae: 0.091536   val_loss: 0.010927   val_mae: 0.078580\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014263   mae: 0.092740   val_loss: 0.010562   val_mae: 0.079076\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014358   mae: 0.093182   val_loss: 0.012827   val_mae: 0.086830\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014151   mae: 0.092166   val_loss: 0.010979   val_mae: 0.079408\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014270   mae: 0.092746   val_loss: 0.010902   val_mae: 0.079057\n",
      "Total:\n",
      "\t \ttime: 0h 1m 44s   loss: 0.014193   mae: 0.092356   val_loss: 0.011229   val_mae: 0.080469\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014016   mae: 0.091444   val_loss: 0.011602   val_mae: 0.082948\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014010   mae: 0.091625   val_loss: 0.011000   val_mae: 0.079886\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014147   mae: 0.092386   val_loss: 0.010150   val_mae: 0.075584\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 25s   loss: 0.013771   mae: 0.090850   val_loss: 0.012041   val_mae: 0.083466\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014058   mae: 0.091637   val_loss: 0.011998   val_mae: 0.084956\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014325   mae: 0.092724   val_loss: 0.010169   val_mae: 0.076439\n",
      "Total:\n",
      "\t \ttime: 0h 2m 27s   loss: 0.014054   mae: 0.091778   val_loss: 0.011160   val_mae: 0.080547\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013827   mae: 0.090790   val_loss: 0.011148   val_mae: 0.080673\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013913   mae: 0.091147   val_loss: 0.010650   val_mae: 0.078570\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013994   mae: 0.091601   val_loss: 0.011622   val_mae: 0.082563\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013725   mae: 0.090679   val_loss: 0.011479   val_mae: 0.081467\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.014034   mae: 0.091436   val_loss: 0.010846   val_mae: 0.079671\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.014141   mae: 0.092319   val_loss: 0.010221   val_mae: 0.075973\n",
      "Total:\n",
      "\t \ttime: 0h 3m 10s   loss: 0.013939   mae: 0.091329   val_loss: 0.010994   val_mae: 0.079820\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013806   mae: 0.090646   val_loss: 0.010662   val_mae: 0.079855\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 40s   loss: 0.013928   mae: 0.091063   val_loss: 0.010663   val_mae: 0.078218\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 40s   loss: 0.013976   mae: 0.091619   val_loss: 0.011035   val_mae: 0.081642\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013841   mae: 0.091359   val_loss: 0.011637   val_mae: 0.082560\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013970   mae: 0.091499   val_loss: 0.011253   val_mae: 0.081573\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.052358   mae: 0.190075   val_loss: 0.050226   val_mae: 0.185406\n",
      "Total:\n",
      "\t \ttime: 0h 3m 57s   loss: 0.020313   mae: 0.107710   val_loss: 0.017579   val_mae: 0.098209\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014180   mae: 0.092263   val_loss: 0.011433   val_mae: 0.081963\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014320   mae: 0.092672   val_loss: 0.011389   val_mae: 0.082394\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014389   mae: 0.093214   val_loss: 0.011732   val_mae: 0.082954\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014125   mae: 0.092229   val_loss: 0.012421   val_mae: 0.085476\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014290   mae: 0.092527   val_loss: 0.010895   val_mae: 0.080169\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014749   mae: 0.095287   val_loss: 0.010850   val_mae: 0.080303\n",
      "Total:\n",
      "\t \ttime: 0h 0m 42s   loss: 0.014342   mae: 0.093032   val_loss: 0.011453   val_mae: 0.082210\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014358   mae: 0.093428   val_loss: 0.010595   val_mae: 0.078816\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014143   mae: 0.092035   val_loss: 0.010700   val_mae: 0.078361\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014092   mae: 0.092063   val_loss: 0.010776   val_mae: 0.079436\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014067   mae: 0.092384   val_loss: 0.011478   val_mae: 0.082224\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014001   mae: 0.091469   val_loss: 0.011431   val_mae: 0.081845\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014395   mae: 0.093223   val_loss: 0.011105   val_mae: 0.081642\n",
      "Total:\n",
      "\t \ttime: 0h 1m 5s   loss: 0.014176   mae: 0.092434   val_loss: 0.011014   val_mae: 0.080387\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.014025   mae: 0.091434   val_loss: 0.010604   val_mae: 0.078995\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013859   mae: 0.091179   val_loss: 0.010684   val_mae: 0.078036\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.014021   mae: 0.091989   val_loss: 0.010405   val_mae: 0.076837\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013687   mae: 0.090587   val_loss: 0.012112   val_mae: 0.084095\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013927   mae: 0.091168   val_loss: 0.010893   val_mae: 0.080009\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.014117   mae: 0.092052   val_loss: 0.010225   val_mae: 0.075560\n",
      "Total:\n",
      "\t \ttime: 0h 1m 28s   loss: 0.013939   mae: 0.091402   val_loss: 0.010820   val_mae: 0.078922\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013838   mae: 0.091009   val_loss: 0.010618   val_mae: 0.078736\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013955   mae: 0.091614   val_loss: 0.011943   val_mae: 0.084534\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.014020   mae: 0.091622   val_loss: 0.010683   val_mae: 0.078196\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013781   mae: 0.090764   val_loss: 0.011767   val_mae: 0.081966\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013822   mae: 0.090621   val_loss: 0.010608   val_mae: 0.078449\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.052349   mae: 0.190027   val_loss: 0.049452   val_mae: 0.185786\n",
      "Total:\n",
      "\t \ttime: 0h 1m 48s   loss: 0.020294   mae: 0.107609   val_loss: 0.017512   val_mae: 0.097944\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013640   mae: 0.090007   val_loss: 0.010473   val_mae: 0.078096\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013709   mae: 0.090628   val_loss: 0.010541   val_mae: 0.077828\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013910   mae: 0.091206   val_loss: 0.010509   val_mae: 0.077589\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013501   mae: 0.089911   val_loss: 0.011329   val_mae: 0.080282\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013711   mae: 0.090312   val_loss: 0.010791   val_mae: 0.079396\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013992   mae: 0.091583   val_loss: 0.010128   val_mae: 0.075813\n",
      "Total:\n",
      "\t \ttime: 0h 2m 15s   loss: 0.013744   mae: 0.090608   val_loss: 0.010629   val_mae: 0.078167\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014352   mae: 0.092617   val_loss: 0.010919   val_mae: 0.079978\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014554   mae: 0.093600   val_loss: 0.011074   val_mae: 0.080349\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014462   mae: 0.093356   val_loss: 0.010816   val_mae: 0.078963\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014248   mae: 0.092811   val_loss: 0.011452   val_mae: 0.081550\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014132   mae: 0.091977   val_loss: 0.010784   val_mae: 0.080000\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014989   mae: 0.097147   val_loss: 0.010852   val_mae: 0.080164\n",
      "Total:\n",
      "\t \ttime: 0h 0m 33s   loss: 0.014456   mae: 0.093584   val_loss: 0.010983   val_mae: 0.080167\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013997   mae: 0.091642   val_loss: 0.012869   val_mae: 0.088932\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013870   mae: 0.091276   val_loss: 0.010887   val_mae: 0.079706\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014054   mae: 0.091881   val_loss: 0.010841   val_mae: 0.078759\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013758   mae: 0.090708   val_loss: 0.011619   val_mae: 0.082332\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013930   mae: 0.091237   val_loss: 0.010877   val_mae: 0.079945\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013995   mae: 0.091696   val_loss: 0.010068   val_mae: 0.075691\n",
      "Total:\n",
      "\t \ttime: 0h 0m 43s   loss: 0.013934   mae: 0.091407   val_loss: 0.011194   val_mae: 0.080894\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013976   mae: 0.092037   val_loss: 0.010740   val_mae: 0.079889\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014033   mae: 0.091805   val_loss: 0.010891   val_mae: 0.079979\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014078   mae: 0.092775   val_loss: 0.010463   val_mae: 0.078611\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013757   mae: 0.090649   val_loss: 0.012167   val_mae: 0.085285\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013788   mae: 0.090899   val_loss: 0.010991   val_mae: 0.080310\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014010   mae: 0.091786   val_loss: 0.010414   val_mae: 0.077209\n",
      "Total:\n",
      "\t \ttime: 0h 0m 56s   loss: 0.013940   mae: 0.091659   val_loss: 0.010944   val_mae: 0.080214\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013679   mae: 0.090213   val_loss: 0.011199   val_mae: 0.080180\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013676   mae: 0.090360   val_loss: 0.010566   val_mae: 0.078123\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013892   mae: 0.091525   val_loss: 0.010350   val_mae: 0.076702\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013474   mae: 0.089854   val_loss: 0.011531   val_mae: 0.081141\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013675   mae: 0.090392   val_loss: 0.010404   val_mae: 0.078239\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013800   mae: 0.090979   val_loss: 0.010884   val_mae: 0.079045\n",
      "Total:\n",
      "\t \ttime: 0h 1m 6s   loss: 0.013699   mae: 0.090554   val_loss: 0.010822   val_mae: 0.078905\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 32   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.014220   mae: 0.092870   val_loss: 0.011008   val_mae: 0.080597\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013692   mae: 0.090273   val_loss: 0.010703   val_mae: 0.080222\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013945   mae: 0.092104   val_loss: 0.010488   val_mae: 0.078139\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013450   mae: 0.089634   val_loss: 0.011914   val_mae: 0.082956\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013694   mae: 0.090381   val_loss: 0.010372   val_mae: 0.078235\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013826   mae: 0.091135   val_loss: 0.009988   val_mae: 0.075354\n",
      "Total:\n",
      "\t \ttime: 0h 1m 20s   loss: 0.013805   mae: 0.091066   val_loss: 0.010745   val_mae: 0.079250\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.017678   mae: 0.105328   val_loss: 0.014366   val_mae: 0.094814\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.017422   mae: 0.103452   val_loss: 0.014934   val_mae: 0.095774\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.016460   mae: 0.100602   val_loss: 0.013491   val_mae: 0.090147\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.016293   mae: 0.099715   val_loss: 0.014612   val_mae: 0.094401\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.016471   mae: 0.101137   val_loss: 0.013364   val_mae: 0.090782\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.018006   mae: 0.106144   val_loss: 0.014670   val_mae: 0.094084\n",
      "Total:\n",
      "\t \ttime: 0h 0m 52s   loss: 0.017055   mae: 0.102730   val_loss: 0.014239   val_mae: 0.093334\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014705   mae: 0.094326   val_loss: 0.011667   val_mae: 0.084233\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.014451   mae: 0.093554   val_loss: 0.011787   val_mae: 0.084669\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014747   mae: 0.094837   val_loss: 0.011203   val_mae: 0.081757\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014726   mae: 0.094638   val_loss: 0.012763   val_mae: 0.087741\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014657   mae: 0.094714   val_loss: 0.011497   val_mae: 0.083383\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014616   mae: 0.094520   val_loss: 0.010881   val_mae: 0.080016\n",
      "Total:\n",
      "\t \ttime: 0h 1m 32s   loss: 0.014650   mae: 0.094431   val_loss: 0.011633   val_mae: 0.083633\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014324   mae: 0.093213   val_loss: 0.011315   val_mae: 0.081858\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.014339   mae: 0.093068   val_loss: 0.011820   val_mae: 0.084387\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.014109   mae: 0.092355   val_loss: 0.010627   val_mae: 0.078894\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013983   mae: 0.091435   val_loss: 0.012161   val_mae: 0.084737\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014173   mae: 0.092992   val_loss: 0.011341   val_mae: 0.082431\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.014366   mae: 0.093442   val_loss: 0.010894   val_mae: 0.079832\n",
      "Total:\n",
      "\t \ttime: 0h 2m 12s   loss: 0.014216   mae: 0.092751   val_loss: 0.011360   val_mae: 0.082023\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013796   mae: 0.090981   val_loss: 0.010724   val_mae: 0.080031\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.014126   mae: 0.092659   val_loss: 0.011458   val_mae: 0.083001\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 27s   loss: 0.013906   mae: 0.091580   val_loss: 0.010350   val_mae: 0.077577\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013714   mae: 0.090960   val_loss: 0.011862   val_mae: 0.083514\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013798   mae: 0.091364   val_loss: 0.010729   val_mae: 0.079731\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 27s   loss: 0.014052   mae: 0.092589   val_loss: 0.010254   val_mae: 0.077557\n",
      "Total:\n",
      "\t \ttime: 0h 2m 49s   loss: 0.013899   mae: 0.091689   val_loss: 0.010896   val_mae: 0.080235\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013871   mae: 0.091163   val_loss: 0.010846   val_mae: 0.080159\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013855   mae: 0.091518   val_loss: 0.010949   val_mae: 0.081033\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013812   mae: 0.091354   val_loss: 0.010289   val_mae: 0.077470\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013659   mae: 0.090465   val_loss: 0.011773   val_mae: 0.083274\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013824   mae: 0.091396   val_loss: 0.010827   val_mae: 0.079703\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013913   mae: 0.091730   val_loss: 0.010152   val_mae: 0.076508\n",
      "Total:\n",
      "\t \ttime: 0h 3m 32s   loss: 0.013822   mae: 0.091271   val_loss: 0.010806   val_mae: 0.079691\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.021082   mae: 0.115243   val_loss: 0.017274   val_mae: 0.104274\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.020259   mae: 0.113223   val_loss: 0.017506   val_mae: 0.105740\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.019399   mae: 0.111141   val_loss: 0.016619   val_mae: 0.102955\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.019239   mae: 0.109828   val_loss: 0.016928   val_mae: 0.102517\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.021651   mae: 0.117740   val_loss: 0.017966   val_mae: 0.106799\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.020155   mae: 0.113706   val_loss: 0.016691   val_mae: 0.101935\n",
      "Total:\n",
      "\t \ttime: 0h 0m 33s   loss: 0.020298   mae: 0.113480   val_loss: 0.017164   val_mae: 0.104037\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.015407   mae: 0.096788   val_loss: 0.012635   val_mae: 0.087498\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.015410   mae: 0.097007   val_loss: 0.013111   val_mae: 0.089551\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.015297   mae: 0.096609   val_loss: 0.012373   val_mae: 0.086696\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.015157   mae: 0.096627   val_loss: 0.013550   val_mae: 0.091071\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.015749   mae: 0.098254   val_loss: 0.012631   val_mae: 0.087208\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.015503   mae: 0.097656   val_loss: 0.012180   val_mae: 0.085407\n",
      "Total:\n",
      "\t \ttime: 0h 0m 53s   loss: 0.015421   mae: 0.097157   val_loss: 0.012746   val_mae: 0.087905\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014986   mae: 0.095573   val_loss: 0.012183   val_mae: 0.085890\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014418   mae: 0.093595   val_loss: 0.012089   val_mae: 0.085207\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014426   mae: 0.093947   val_loss: 0.011028   val_mae: 0.081814\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014240   mae: 0.092811   val_loss: 0.012342   val_mae: 0.086263\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014533   mae: 0.094163   val_loss: 0.011445   val_mae: 0.082991\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.015015   mae: 0.096069   val_loss: 0.011476   val_mae: 0.082011\n",
      "Total:\n",
      "\t \ttime: 0h 1m 11s   loss: 0.014603   mae: 0.094360   val_loss: 0.011761   val_mae: 0.084029\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013970   mae: 0.092031   val_loss: 0.010928   val_mae: 0.080665\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014152   mae: 0.092453   val_loss: 0.011361   val_mae: 0.082764\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014337   mae: 0.093427   val_loss: 0.010864   val_mae: 0.080359\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013842   mae: 0.091297   val_loss: 0.011833   val_mae: 0.084012\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014161   mae: 0.092849   val_loss: 0.011234   val_mae: 0.082142\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014190   mae: 0.092927   val_loss: 0.010453   val_mae: 0.078085\n",
      "Total:\n",
      "\t \ttime: 0h 1m 35s   loss: 0.014109   mae: 0.092497   val_loss: 0.011112   val_mae: 0.081338\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.014096   mae: 0.092095   val_loss: 0.011125   val_mae: 0.081451\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013916   mae: 0.091697   val_loss: 0.011051   val_mae: 0.081433\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013948   mae: 0.092085   val_loss: 0.010772   val_mae: 0.080062\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013706   mae: 0.090647   val_loss: 0.011724   val_mae: 0.082665\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013963   mae: 0.091807   val_loss: 0.010953   val_mae: 0.080619\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.014210   mae: 0.093113   val_loss: 0.010431   val_mae: 0.078028\n",
      "Total:\n",
      "\t \ttime: 0h 1m 56s   loss: 0.013973   mae: 0.091907   val_loss: 0.011009   val_mae: 0.080710\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.023188   mae: 0.122517   val_loss: 0.019488   val_mae: 0.111696\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.022626   mae: 0.119749   val_loss: 0.020771   val_mae: 0.115337\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.022835   mae: 0.121799   val_loss: 0.019582   val_mae: 0.112595\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.025015   mae: 0.128308   val_loss: 0.022116   val_mae: 0.120385\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.023904   mae: 0.124102   val_loss: 0.020506   val_mae: 0.114809\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.023691   mae: 0.124585   val_loss: 0.020093   val_mae: 0.113900\n",
      "Total:\n",
      "\t \ttime: 0h 0m 24s   loss: 0.023543   mae: 0.123510   val_loss: 0.020426   val_mae: 0.114787\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.017356   mae: 0.104301   val_loss: 0.014383   val_mae: 0.095024\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.017256   mae: 0.103317   val_loss: 0.015321   val_mae: 0.097429\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.017494   mae: 0.104495   val_loss: 0.014862   val_mae: 0.096513\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.017096   mae: 0.103332   val_loss: 0.015611   val_mae: 0.098797\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.017953   mae: 0.106257   val_loss: 0.014783   val_mae: 0.096407\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.016849   mae: 0.102585   val_loss: 0.013645   val_mae: 0.091045\n",
      "Total:\n",
      "\t \ttime: 0h 0m 35s   loss: 0.017334   mae: 0.104048   val_loss: 0.014767   val_mae: 0.095869\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.016028   mae: 0.099257   val_loss: 0.013108   val_mae: 0.089944\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.016023   mae: 0.099450   val_loss: 0.014261   val_mae: 0.094078\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.015012   mae: 0.096204   val_loss: 0.011814   val_mae: 0.085174\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.015964   mae: 0.098832   val_loss: 0.014256   val_mae: 0.093355\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.015901   mae: 0.099052   val_loss: 0.013001   val_mae: 0.089379\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.015869   mae: 0.098770   val_loss: 0.012378   val_mae: 0.085517\n",
      "Total:\n",
      "\t \ttime: 0h 0m 45s   loss: 0.015800   mae: 0.098594   val_loss: 0.013136   val_mae: 0.089574\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014557   mae: 0.094199   val_loss: 0.011584   val_mae: 0.083511\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014752   mae: 0.094825   val_loss: 0.011992   val_mae: 0.085937\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.015112   mae: 0.096333   val_loss: 0.011863   val_mae: 0.085250\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014431   mae: 0.093775   val_loss: 0.012661   val_mae: 0.087632\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014930   mae: 0.095542   val_loss: 0.011619   val_mae: 0.084453\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.015018   mae: 0.095708   val_loss: 0.011524   val_mae: 0.082332\n",
      "Total:\n",
      "\t \ttime: 0h 0m 55s   loss: 0.014800   mae: 0.095064   val_loss: 0.011874   val_mae: 0.084852\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014478   mae: 0.093659   val_loss: 0.011628   val_mae: 0.083591\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014323   mae: 0.093609   val_loss: 0.011304   val_mae: 0.083105\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014503   mae: 0.093861   val_loss: 0.011094   val_mae: 0.081314\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013970   mae: 0.091883   val_loss: 0.012124   val_mae: 0.084901\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014492   mae: 0.093991   val_loss: 0.011183   val_mae: 0.082280\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014852   mae: 0.095160   val_loss: 0.011486   val_mae: 0.081900\n",
      "Total:\n",
      "\t \ttime: 0h 1m 6s   loss: 0.014436   mae: 0.093694   val_loss: 0.011470   val_mae: 0.082848\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014056   mae: 0.091738   val_loss: 0.010968   val_mae: 0.080811\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013955   mae: 0.091140   val_loss: 0.010591   val_mae: 0.078059\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014138   mae: 0.092170   val_loss: 0.011205   val_mae: 0.080322\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013767   mae: 0.090814   val_loss: 0.011736   val_mae: 0.082881\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014371   mae: 0.093120   val_loss: 0.011130   val_mae: 0.081185\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014258   mae: 0.092756   val_loss: 0.010400   val_mae: 0.077290\n",
      "Total:\n",
      "\t \ttime: 0h 0m 52s   loss: 0.014091   mae: 0.091956   val_loss: 0.011005   val_mae: 0.080091\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013844   mae: 0.090854   val_loss: 0.010534   val_mae: 0.078995\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013831   mae: 0.090839   val_loss: 0.010629   val_mae: 0.078774\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013919   mae: 0.091563   val_loss: 0.010219   val_mae: 0.076162\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013570   mae: 0.089894   val_loss: 0.011674   val_mae: 0.082224\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013896   mae: 0.091128   val_loss: 0.010899   val_mae: 0.079329\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013958   mae: 0.091765   val_loss: 0.010103   val_mae: 0.075339\n",
      "Total:\n",
      "\t \ttime: 0h 1m 31s   loss: 0.013836   mae: 0.091007   val_loss: 0.010676   val_mae: 0.078471\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013709   mae: 0.090572   val_loss: 0.010649   val_mae: 0.078306\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013778   mae: 0.090359   val_loss: 0.010635   val_mae: 0.078342\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013702   mae: 0.090585   val_loss: 0.010296   val_mae: 0.076655\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013474   mae: 0.089613   val_loss: 0.011418   val_mae: 0.080694\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013674   mae: 0.090384   val_loss: 0.010766   val_mae: 0.079061\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013856   mae: 0.090969   val_loss: 0.009988   val_mae: 0.074730\n",
      "Total:\n",
      "\t \ttime: 0h 2m 13s   loss: 0.013699   mae: 0.090414   val_loss: 0.010625   val_mae: 0.077965\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013643   mae: 0.090111   val_loss: 0.010463   val_mae: 0.077738\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013649   mae: 0.090393   val_loss: 0.010662   val_mae: 0.078874\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013653   mae: 0.090664   val_loss: 0.010148   val_mae: 0.075469\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 27s   loss: 0.013305   mae: 0.089057   val_loss: 0.011797   val_mae: 0.082490\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013717   mae: 0.090969   val_loss: 0.011323   val_mae: 0.081431\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 27s   loss: 0.013674   mae: 0.090526   val_loss: 0.010600   val_mae: 0.077835\n",
      "Total:\n",
      "\t \ttime: 0h 2m 49s   loss: 0.013607   mae: 0.090287   val_loss: 0.010832   val_mae: 0.078973\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013481   mae: 0.089439   val_loss: 0.010396   val_mae: 0.077722\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013541   mae: 0.089888   val_loss: 0.010776   val_mae: 0.079395\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013593   mae: 0.090310   val_loss: 0.010263   val_mae: 0.076466\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013220   mae: 0.088713   val_loss: 0.011385   val_mae: 0.080850\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013492   mae: 0.089724   val_loss: 0.010352   val_mae: 0.077366\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013631   mae: 0.090314   val_loss: 0.009987   val_mae: 0.075553\n",
      "Total:\n",
      "\t \ttime: 0h 3m 31s   loss: 0.013493   mae: 0.089731   val_loss: 0.010526   val_mae: 0.077892\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014099   mae: 0.092225   val_loss: 0.010928   val_mae: 0.080348\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014014   mae: 0.091692   val_loss: 0.010999   val_mae: 0.080183\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014345   mae: 0.093099   val_loss: 0.011219   val_mae: 0.080986\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013998   mae: 0.091604   val_loss: 0.011761   val_mae: 0.082827\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014131   mae: 0.092294   val_loss: 0.010827   val_mae: 0.079433\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014374   mae: 0.093552   val_loss: 0.010364   val_mae: 0.077540\n",
      "Total:\n",
      "\t \ttime: 0h 0m 33s   loss: 0.014160   mae: 0.092411   val_loss: 0.011016   val_mae: 0.080220\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013769   mae: 0.090829   val_loss: 0.010858   val_mae: 0.079709\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013713   mae: 0.090572   val_loss: 0.010833   val_mae: 0.079597\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013979   mae: 0.091837   val_loss: 0.010478   val_mae: 0.078115\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013642   mae: 0.090338   val_loss: 0.012936   val_mae: 0.086363\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013858   mae: 0.090941   val_loss: 0.010466   val_mae: 0.078289\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013878   mae: 0.091460   val_loss: 0.010320   val_mae: 0.076537\n",
      "Total:\n",
      "\t \ttime: 0h 0m 53s   loss: 0.013807   mae: 0.090996   val_loss: 0.010982   val_mae: 0.079768\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013671   mae: 0.090335   val_loss: 0.010582   val_mae: 0.078300\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013701   mae: 0.090644   val_loss: 0.010829   val_mae: 0.079455\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013675   mae: 0.090677   val_loss: 0.010421   val_mae: 0.076958\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013295   mae: 0.089023   val_loss: 0.011348   val_mae: 0.080811\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013603   mae: 0.090245   val_loss: 0.010411   val_mae: 0.077644\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013799   mae: 0.091163   val_loss: 0.010260   val_mae: 0.076320\n",
      "Total:\n",
      "\t \ttime: 0h 1m 12s   loss: 0.013624   mae: 0.090348   val_loss: 0.010642   val_mae: 0.078248\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013612   mae: 0.090136   val_loss: 0.010765   val_mae: 0.078844\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013696   mae: 0.090382   val_loss: 0.010521   val_mae: 0.077968\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013699   mae: 0.090700   val_loss: 0.010426   val_mae: 0.077393\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013393   mae: 0.089550   val_loss: 0.011640   val_mae: 0.081361\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013480   mae: 0.089824   val_loss: 0.010730   val_mae: 0.079040\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013652   mae: 0.090422   val_loss: 0.010376   val_mae: 0.076812\n",
      "Total:\n",
      "\t \ttime: 0h 1m 33s   loss: 0.013589   mae: 0.090169   val_loss: 0.010743   val_mae: 0.078570\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013484   mae: 0.089718   val_loss: 0.010563   val_mae: 0.078029\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013498   mae: 0.089708   val_loss: 0.010759   val_mae: 0.078965\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013491   mae: 0.089893   val_loss: 0.010186   val_mae: 0.075827\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013237   mae: 0.088853   val_loss: 0.011324   val_mae: 0.080794\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013569   mae: 0.090007   val_loss: 0.010400   val_mae: 0.077844\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013593   mae: 0.090462   val_loss: 0.010019   val_mae: 0.075382\n",
      "Total:\n",
      "\t \ttime: 0h 1m 53s   loss: 0.013479   mae: 0.089773   val_loss: 0.010542   val_mae: 0.077807\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014033   mae: 0.091778   val_loss: 0.011107   val_mae: 0.080609\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014408   mae: 0.093171   val_loss: 0.011741   val_mae: 0.083855\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014323   mae: 0.093077   val_loss: 0.010611   val_mae: 0.078700\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.013998   mae: 0.091710   val_loss: 0.011795   val_mae: 0.083626\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014282   mae: 0.092918   val_loss: 0.011028   val_mae: 0.081196\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014241   mae: 0.092954   val_loss: 0.010278   val_mae: 0.077098\n",
      "Total:\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014214   mae: 0.092601   val_loss: 0.011093   val_mae: 0.080847\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013749   mae: 0.090643   val_loss: 0.010594   val_mae: 0.078580\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013879   mae: 0.091328   val_loss: 0.010728   val_mae: 0.079905\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013756   mae: 0.091127   val_loss: 0.010755   val_mae: 0.079384\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013567   mae: 0.089931   val_loss: 0.011651   val_mae: 0.082180\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013867   mae: 0.090929   val_loss: 0.010448   val_mae: 0.078438\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013928   mae: 0.091809   val_loss: 0.010193   val_mae: 0.076528\n",
      "Total:\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013791   mae: 0.090961   val_loss: 0.010728   val_mae: 0.079169\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013657   mae: 0.090230   val_loss: 0.010609   val_mae: 0.078130\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013594   mae: 0.090260   val_loss: 0.010556   val_mae: 0.078287\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013783   mae: 0.090970   val_loss: 0.010416   val_mae: 0.077536\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013381   mae: 0.089412   val_loss: 0.011495   val_mae: 0.081453\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013599   mae: 0.090074   val_loss: 0.010588   val_mae: 0.078973\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013855   mae: 0.091343   val_loss: 0.010257   val_mae: 0.076513\n",
      "Total:\n",
      "\t \ttime: 0h 0m 44s   loss: 0.013645   mae: 0.090382   val_loss: 0.010654   val_mae: 0.078482\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013597   mae: 0.089964   val_loss: 0.010515   val_mae: 0.077872\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013601   mae: 0.090325   val_loss: 0.010656   val_mae: 0.078980\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013524   mae: 0.090071   val_loss: 0.010255   val_mae: 0.076787\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013336   mae: 0.089190   val_loss: 0.012081   val_mae: 0.083921\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013489   mae: 0.089665   val_loss: 0.010171   val_mae: 0.077064\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013664   mae: 0.090604   val_loss: 0.009933   val_mae: 0.075228\n",
      "Total:\n",
      "\t \ttime: 0h 0m 56s   loss: 0.013535   mae: 0.089970   val_loss: 0.010602   val_mae: 0.078309\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013471   mae: 0.089818   val_loss: 0.010745   val_mae: 0.078880\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013536   mae: 0.089953   val_loss: 0.010982   val_mae: 0.080110\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013758   mae: 0.090819   val_loss: 0.010293   val_mae: 0.076827\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013209   mae: 0.088787   val_loss: 0.011350   val_mae: 0.080535\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013468   mae: 0.089856   val_loss: 0.010690   val_mae: 0.079280\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013553   mae: 0.090258   val_loss: 0.009918   val_mae: 0.074733\n",
      "Total:\n",
      "\t \ttime: 0h 1m 6s   loss: 0.013499   mae: 0.089915   val_loss: 0.010663   val_mae: 0.078394\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014433   mae: 0.092623   val_loss: 0.011492   val_mae: 0.082204\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014342   mae: 0.092741   val_loss: 0.011056   val_mae: 0.080013\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014413   mae: 0.093068   val_loss: 0.010763   val_mae: 0.079666\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014268   mae: 0.092383   val_loss: 0.011841   val_mae: 0.082579\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014504   mae: 0.093585   val_loss: 0.010913   val_mae: 0.078941\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014410   mae: 0.093215   val_loss: 0.010000   val_mae: 0.074859\n",
      "Total:\n",
      "\t \ttime: 0h 0m 51s   loss: 0.014395   mae: 0.092936   val_loss: 0.011011   val_mae: 0.079710\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014114   mae: 0.091701   val_loss: 0.011236   val_mae: 0.082262\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014099   mae: 0.091856   val_loss: 0.011573   val_mae: 0.082400\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014159   mae: 0.092424   val_loss: 0.010512   val_mae: 0.077610\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013839   mae: 0.090943   val_loss: 0.011777   val_mae: 0.083048\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.014115   mae: 0.091808   val_loss: 0.012022   val_mae: 0.084263\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014176   mae: 0.092398   val_loss: 0.010278   val_mae: 0.076201\n",
      "Total:\n",
      "\t \ttime: 0h 1m 32s   loss: 0.014084   mae: 0.091855   val_loss: 0.011233   val_mae: 0.080964\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013986   mae: 0.091557   val_loss: 0.010812   val_mae: 0.078921\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013981   mae: 0.091574   val_loss: 0.010729   val_mae: 0.078212\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.014052   mae: 0.091978   val_loss: 0.010450   val_mae: 0.077050\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013640   mae: 0.090391   val_loss: 0.012390   val_mae: 0.084412\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013963   mae: 0.091326   val_loss: 0.011770   val_mae: 0.083378\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.014030   mae: 0.091785   val_loss: 0.010250   val_mae: 0.077143\n",
      "Total:\n",
      "\t \ttime: 0h 2m 10s   loss: 0.013942   mae: 0.091435   val_loss: 0.011067   val_mae: 0.079852\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 27s   loss: 0.013862   mae: 0.091047   val_loss: 0.010425   val_mae: 0.077768\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013863   mae: 0.090853   val_loss: 0.010588   val_mae: 0.077823\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 27s   loss: 0.014029   mae: 0.091839   val_loss: 0.010579   val_mae: 0.077151\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 27s   loss: 0.013612   mae: 0.090054   val_loss: 0.011357   val_mae: 0.080417\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013823   mae: 0.090682   val_loss: 0.011408   val_mae: 0.081318\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013791   mae: 0.090892   val_loss: 0.010454   val_mae: 0.076988\n",
      "Total:\n",
      "\t \ttime: 0h 2m 49s   loss: 0.013830   mae: 0.090895   val_loss: 0.010802   val_mae: 0.078577\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013813   mae: 0.090582   val_loss: 0.010827   val_mae: 0.079846\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013824   mae: 0.090847   val_loss: 0.010806   val_mae: 0.080231\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013887   mae: 0.091412   val_loss: 0.010394   val_mae: 0.077596\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013587   mae: 0.089771   val_loss: 0.011567   val_mae: 0.081515\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013824   mae: 0.091003   val_loss: 0.010309   val_mae: 0.076984\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.014005   mae: 0.091764   val_loss: 0.011024   val_mae: 0.079754\n",
      "Total:\n",
      "\t \ttime: 0h 3m 31s   loss: 0.013823   mae: 0.090896   val_loss: 0.010821   val_mae: 0.079321\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014329   mae: 0.092556   val_loss: 0.011220   val_mae: 0.081708\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014302   mae: 0.092536   val_loss: 0.012022   val_mae: 0.084114\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014108   mae: 0.091991   val_loss: 0.011517   val_mae: 0.081163\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014112   mae: 0.091804   val_loss: 0.011544   val_mae: 0.081694\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014248   mae: 0.092478   val_loss: 0.011529   val_mae: 0.082736\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014278   mae: 0.092562   val_loss: 0.010351   val_mae: 0.077120\n",
      "Total:\n",
      "\t \ttime: 0h 0m 32s   loss: 0.014229   mae: 0.092321   val_loss: 0.011364   val_mae: 0.081423\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013930   mae: 0.091143   val_loss: 0.010989   val_mae: 0.079902\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013931   mae: 0.091250   val_loss: 0.011396   val_mae: 0.080945\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014064   mae: 0.092141   val_loss: 0.010433   val_mae: 0.077909\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013704   mae: 0.090443   val_loss: 0.011579   val_mae: 0.082109\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013978   mae: 0.091600   val_loss: 0.010669   val_mae: 0.078999\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014099   mae: 0.092159   val_loss: 0.010440   val_mae: 0.077763\n",
      "Total:\n",
      "\t \ttime: 0h 0m 52s   loss: 0.013951   mae: 0.091456   val_loss: 0.010918   val_mae: 0.079604\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013751   mae: 0.090623   val_loss: 0.011076   val_mae: 0.081051\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013945   mae: 0.091359   val_loss: 0.010685   val_mae: 0.078485\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013971   mae: 0.091514   val_loss: 0.010888   val_mae: 0.079295\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013565   mae: 0.090039   val_loss: 0.012177   val_mae: 0.084024\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013789   mae: 0.090840   val_loss: 0.010965   val_mae: 0.080866\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013933   mae: 0.091441   val_loss: 0.010083   val_mae: 0.075328\n",
      "Total:\n",
      "\t \ttime: 0h 1m 13s   loss: 0.013826   mae: 0.090969   val_loss: 0.010979   val_mae: 0.079842\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013802   mae: 0.090946   val_loss: 0.011101   val_mae: 0.080449\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013799   mae: 0.090667   val_loss: 0.010851   val_mae: 0.080714\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013867   mae: 0.091486   val_loss: 0.010552   val_mae: 0.077654\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013625   mae: 0.090117   val_loss: 0.011694   val_mae: 0.081450\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013796   mae: 0.090994   val_loss: 0.010665   val_mae: 0.078515\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013865   mae: 0.091343   val_loss: 0.010594   val_mae: 0.078163\n",
      "Total:\n",
      "\t \ttime: 0h 1m 33s   loss: 0.013792   mae: 0.090925   val_loss: 0.010910   val_mae: 0.079491\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013711   mae: 0.090352   val_loss: 0.011149   val_mae: 0.081743\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013700   mae: 0.090216   val_loss: 0.010903   val_mae: 0.080110\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013808   mae: 0.091065   val_loss: 0.010216   val_mae: 0.076037\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013471   mae: 0.089671   val_loss: 0.011949   val_mae: 0.083246\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013671   mae: 0.090473   val_loss: 0.010658   val_mae: 0.078884\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013845   mae: 0.091226   val_loss: 0.009970   val_mae: 0.074700\n",
      "Total:\n",
      "\t \ttime: 0h 1m 56s   loss: 0.013701   mae: 0.090500   val_loss: 0.010808   val_mae: 0.079120\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014144   mae: 0.092072   val_loss: 0.011696   val_mae: 0.082609\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014265   mae: 0.092451   val_loss: 0.010735   val_mae: 0.079310\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014265   mae: 0.092713   val_loss: 0.010581   val_mae: 0.078708\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.013944   mae: 0.091325   val_loss: 0.012264   val_mae: 0.083568\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014066   mae: 0.091916   val_loss: 0.010426   val_mae: 0.078945\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014307   mae: 0.092674   val_loss: 0.010110   val_mae: 0.076438\n",
      "Total:\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014165   mae: 0.092192   val_loss: 0.010969   val_mae: 0.079930\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013871   mae: 0.091018   val_loss: 0.010870   val_mae: 0.079664\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013921   mae: 0.090945   val_loss: 0.010930   val_mae: 0.079057\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013984   mae: 0.091450   val_loss: 0.010281   val_mae: 0.076205\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013629   mae: 0.090405   val_loss: 0.011616   val_mae: 0.082367\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013793   mae: 0.090793   val_loss: 0.010945   val_mae: 0.080637\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013988   mae: 0.091654   val_loss: 0.011010   val_mae: 0.079072\n",
      "Total:\n",
      "\t \ttime: 0h 0m 33s   loss: 0.013864   mae: 0.091044   val_loss: 0.010942   val_mae: 0.079500\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013672   mae: 0.090328   val_loss: 0.010652   val_mae: 0.077966\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013755   mae: 0.090547   val_loss: 0.010696   val_mae: 0.079196\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013888   mae: 0.091402   val_loss: 0.010580   val_mae: 0.078161\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013561   mae: 0.090019   val_loss: 0.011564   val_mae: 0.082188\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013748   mae: 0.090635   val_loss: 0.010336   val_mae: 0.077881\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013855   mae: 0.091249   val_loss: 0.010367   val_mae: 0.076926\n",
      "Total:\n",
      "\t \ttime: 0h 0m 44s   loss: 0.013747   mae: 0.090697   val_loss: 0.010699   val_mae: 0.078720\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013613   mae: 0.090091   val_loss: 0.010517   val_mae: 0.077398\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013705   mae: 0.090408   val_loss: 0.010691   val_mae: 0.079731\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013741   mae: 0.090770   val_loss: 0.010867   val_mae: 0.078534\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013418   mae: 0.089373   val_loss: 0.012502   val_mae: 0.084660\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013650   mae: 0.090515   val_loss: 0.010757   val_mae: 0.080005\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013711   mae: 0.090842   val_loss: 0.010379   val_mae: 0.077063\n",
      "Total:\n",
      "\t \ttime: 0h 0m 56s   loss: 0.013640   mae: 0.090333   val_loss: 0.010952   val_mae: 0.079565\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013618   mae: 0.090103   val_loss: 0.010809   val_mae: 0.079872\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013580   mae: 0.089956   val_loss: 0.010650   val_mae: 0.079329\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013736   mae: 0.091013   val_loss: 0.010687   val_mae: 0.078404\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013556   mae: 0.089778   val_loss: 0.012176   val_mae: 0.084282\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013840   mae: 0.090889   val_loss: 0.010567   val_mae: 0.079062\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013703   mae: 0.090672   val_loss: 0.010482   val_mae: 0.076894\n",
      "Total:\n",
      "\t \ttime: 0h 1m 6s   loss: 0.013672   mae: 0.090402   val_loss: 0.010895   val_mae: 0.079640\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.015968   mae: 0.099377   val_loss: 0.013079   val_mae: 0.089408\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.015286   mae: 0.096781   val_loss: 0.012274   val_mae: 0.086608\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.015964   mae: 0.098523   val_loss: 0.012733   val_mae: 0.087181\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.016333   mae: 0.099574   val_loss: 0.014302   val_mae: 0.093177\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.015625   mae: 0.098331   val_loss: 0.012346   val_mae: 0.086558\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.016307   mae: 0.100237   val_loss: 0.013565   val_mae: 0.089301\n",
      "Total:\n",
      "\t \ttime: 0h 0m 56s   loss: 0.015914   mae: 0.098804   val_loss: 0.013050   val_mae: 0.088706\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014336   mae: 0.093241   val_loss: 0.011313   val_mae: 0.082777\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014122   mae: 0.092245   val_loss: 0.011339   val_mae: 0.082478\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014731   mae: 0.094893   val_loss: 0.011348   val_mae: 0.082928\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014514   mae: 0.093607   val_loss: 0.012822   val_mae: 0.087877\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013988   mae: 0.091833   val_loss: 0.010706   val_mae: 0.079036\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014477   mae: 0.093780   val_loss: 0.010926   val_mae: 0.079536\n",
      "Total:\n",
      "\t \ttime: 0h 1m 39s   loss: 0.014361   mae: 0.093266   val_loss: 0.011409   val_mae: 0.082439\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 25s   loss: 0.014227   mae: 0.092947   val_loss: 0.011077   val_mae: 0.081307\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013953   mae: 0.091750   val_loss: 0.011073   val_mae: 0.081024\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014047   mae: 0.092153   val_loss: 0.010733   val_mae: 0.079457\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013621   mae: 0.090568   val_loss: 0.011614   val_mae: 0.082443\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013835   mae: 0.091274   val_loss: 0.010791   val_mae: 0.079800\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.014080   mae: 0.092396   val_loss: 0.010330   val_mae: 0.077194\n",
      "Total:\n",
      "\t \ttime: 0h 2m 22s   loss: 0.013960   mae: 0.091848   val_loss: 0.010936   val_mae: 0.080204\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013818   mae: 0.091041   val_loss: 0.010748   val_mae: 0.079621\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013687   mae: 0.090690   val_loss: 0.010939   val_mae: 0.080499\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.013805   mae: 0.091275   val_loss: 0.010574   val_mae: 0.078458\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013532   mae: 0.090320   val_loss: 0.011611   val_mae: 0.082544\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013751   mae: 0.090804   val_loss: 0.010713   val_mae: 0.079285\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.014031   mae: 0.092187   val_loss: 0.010502   val_mae: 0.078600\n",
      "Total:\n",
      "\t \ttime: 0h 3m 5s   loss: 0.013771   mae: 0.091053   val_loss: 0.010848   val_mae: 0.079834\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013675   mae: 0.090411   val_loss: 0.010714   val_mae: 0.079128\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013617   mae: 0.090223   val_loss: 0.010858   val_mae: 0.080033\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013784   mae: 0.091017   val_loss: 0.010338   val_mae: 0.077254\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013477   mae: 0.089989   val_loss: 0.011699   val_mae: 0.082449\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013488   mae: 0.089863   val_loss: 0.010415   val_mae: 0.077781\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013802   mae: 0.091386   val_loss: 0.009991   val_mae: 0.075814\n",
      "Total:\n",
      "\t \ttime: 0h 3m 41s   loss: 0.013640   mae: 0.090482   val_loss: 0.010669   val_mae: 0.078743\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.018160   mae: 0.106747   val_loss: 0.014675   val_mae: 0.095234\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.018296   mae: 0.106881   val_loss: 0.015913   val_mae: 0.099533\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.018555   mae: 0.107644   val_loss: 0.015320   val_mae: 0.098031\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.016742   mae: 0.101951   val_loss: 0.015032   val_mae: 0.096565\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.018313   mae: 0.106878   val_loss: 0.014955   val_mae: 0.096099\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.018690   mae: 0.108227   val_loss: 0.014918   val_mae: 0.095337\n",
      "Total:\n",
      "\t \ttime: 0h 0m 37s   loss: 0.018126   mae: 0.106388   val_loss: 0.015135   val_mae: 0.096800\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.015513   mae: 0.097186   val_loss: 0.012345   val_mae: 0.086578\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014590   mae: 0.094290   val_loss: 0.011937   val_mae: 0.084928\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014981   mae: 0.095438   val_loss: 0.011496   val_mae: 0.082819\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014469   mae: 0.093705   val_loss: 0.012505   val_mae: 0.086426\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014862   mae: 0.095119   val_loss: 0.011473   val_mae: 0.082875\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014837   mae: 0.095415   val_loss: 0.011108   val_mae: 0.080865\n",
      "Total:\n",
      "\t \ttime: 0h 0m 57s   loss: 0.014875   mae: 0.095192   val_loss: 0.011811   val_mae: 0.084082\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.014310   mae: 0.093003   val_loss: 0.011435   val_mae: 0.082744\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.014393   mae: 0.093639   val_loss: 0.011994   val_mae: 0.085170\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.014365   mae: 0.093610   val_loss: 0.010926   val_mae: 0.080829\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013805   mae: 0.091304   val_loss: 0.012164   val_mae: 0.085142\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014178   mae: 0.092457   val_loss: 0.011009   val_mae: 0.080605\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014358   mae: 0.093417   val_loss: 0.010494   val_mae: 0.078144\n",
      "Total:\n",
      "\t \ttime: 0h 1m 18s   loss: 0.014235   mae: 0.092905   val_loss: 0.011337   val_mae: 0.082106\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014082   mae: 0.092128   val_loss: 0.011351   val_mae: 0.082103\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014021   mae: 0.091984   val_loss: 0.011160   val_mae: 0.081615\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013917   mae: 0.091809   val_loss: 0.010507   val_mae: 0.078214\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013629   mae: 0.090719   val_loss: 0.011782   val_mae: 0.083260\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013950   mae: 0.091757   val_loss: 0.011014   val_mae: 0.080908\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014024   mae: 0.092070   val_loss: 0.010498   val_mae: 0.077992\n",
      "Total:\n",
      "\t \ttime: 0h 1m 41s   loss: 0.013937   mae: 0.091744   val_loss: 0.011052   val_mae: 0.080682\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013697   mae: 0.090643   val_loss: 0.010717   val_mae: 0.079607\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013809   mae: 0.091267   val_loss: 0.010894   val_mae: 0.080404\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013716   mae: 0.090801   val_loss: 0.010324   val_mae: 0.077059\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013440   mae: 0.089609   val_loss: 0.011590   val_mae: 0.081856\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013617   mae: 0.090393   val_loss: 0.010527   val_mae: 0.078393\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.014069   mae: 0.092466   val_loss: 0.010419   val_mae: 0.078079\n",
      "Total:\n",
      "\t \ttime: 0h 2m 3s   loss: 0.013725   mae: 0.090863   val_loss: 0.010745   val_mae: 0.079233\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.021780   mae: 0.118721   val_loss: 0.018104   val_mae: 0.108071\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.022488   mae: 0.120748   val_loss: 0.019383   val_mae: 0.112874\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.020543   mae: 0.114371   val_loss: 0.017561   val_mae: 0.105702\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.023884   mae: 0.124524   val_loss: 0.020894   val_mae: 0.116140\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.019967   mae: 0.111384   val_loss: 0.016010   val_mae: 0.098591\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.023156   mae: 0.121711   val_loss: 0.018980   val_mae: 0.109448\n",
      "Total:\n",
      "\t \ttime: 0h 0m 27s   loss: 0.021970   mae: 0.118576   val_loss: 0.018489   val_mae: 0.108471\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.016088   mae: 0.098899   val_loss: 0.013284   val_mae: 0.089424\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.017034   mae: 0.103301   val_loss: 0.014712   val_mae: 0.096763\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.018241   mae: 0.107506   val_loss: 0.015114   val_mae: 0.098106\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.016843   mae: 0.101906   val_loss: 0.015105   val_mae: 0.096309\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.015387   mae: 0.097141   val_loss: 0.012323   val_mae: 0.086700\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.015800   mae: 0.098693   val_loss: 0.012289   val_mae: 0.085454\n",
      "Total:\n",
      "\t \ttime: 0h 0m 38s   loss: 0.016566   mae: 0.101241   val_loss: 0.013804   val_mae: 0.092126\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.015002   mae: 0.095861   val_loss: 0.012313   val_mae: 0.086534\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014493   mae: 0.093913   val_loss: 0.012016   val_mae: 0.085818\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.015763   mae: 0.098794   val_loss: 0.012625   val_mae: 0.088953\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014673   mae: 0.094318   val_loss: 0.012615   val_mae: 0.087539\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.015034   mae: 0.095763   val_loss: 0.012015   val_mae: 0.085654\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.015303   mae: 0.097249   val_loss: 0.011776   val_mae: 0.083690\n",
      "Total:\n",
      "\t \ttime: 0h 0m 48s   loss: 0.015045   mae: 0.095983   val_loss: 0.012227   val_mae: 0.086365\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014190   mae: 0.092698   val_loss: 0.011066   val_mae: 0.081185\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014635   mae: 0.094529   val_loss: 0.011706   val_mae: 0.084713\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014103   mae: 0.092424   val_loss: 0.010932   val_mae: 0.080370\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014061   mae: 0.092196   val_loss: 0.012137   val_mae: 0.084827\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014000   mae: 0.092199   val_loss: 0.010629   val_mae: 0.079953\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014492   mae: 0.094125   val_loss: 0.010815   val_mae: 0.079630\n",
      "Total:\n",
      "\t \ttime: 0h 1m 1s   loss: 0.014247   mae: 0.093029   val_loss: 0.011214   val_mae: 0.081780\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014015   mae: 0.091878   val_loss: 0.010986   val_mae: 0.080219\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014004   mae: 0.092210   val_loss: 0.011094   val_mae: 0.081962\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014181   mae: 0.092845   val_loss: 0.010598   val_mae: 0.079049\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013600   mae: 0.090442   val_loss: 0.011925   val_mae: 0.083549\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014200   mae: 0.092657   val_loss: 0.010932   val_mae: 0.080884\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014286   mae: 0.093349   val_loss: 0.010647   val_mae: 0.078979\n",
      "Total:\n",
      "\t \ttime: 0h 1m 11s   loss: 0.014048   mae: 0.092230   val_loss: 0.011030   val_mae: 0.080774\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014061   mae: 0.091668   val_loss: 0.010770   val_mae: 0.079451\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014021   mae: 0.091614   val_loss: 0.010724   val_mae: 0.078980\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014247   mae: 0.092514   val_loss: 0.010722   val_mae: 0.079927\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013775   mae: 0.090821   val_loss: 0.011989   val_mae: 0.083102\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014058   mae: 0.091725   val_loss: 0.010657   val_mae: 0.079224\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014290   mae: 0.092788   val_loss: 0.010632   val_mae: 0.077770\n",
      "Total:\n",
      "\t \ttime: 0h 0m 55s   loss: 0.014075   mae: 0.091855   val_loss: 0.010916   val_mae: 0.079742\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013768   mae: 0.090710   val_loss: 0.010703   val_mae: 0.078946\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013774   mae: 0.090640   val_loss: 0.010667   val_mae: 0.078372\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013815   mae: 0.091012   val_loss: 0.011004   val_mae: 0.079712\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013545   mae: 0.089937   val_loss: 0.011748   val_mae: 0.082378\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013815   mae: 0.090978   val_loss: 0.010655   val_mae: 0.078260\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013914   mae: 0.091422   val_loss: 0.010006   val_mae: 0.075576\n",
      "Total:\n",
      "\t \ttime: 0h 1m 36s   loss: 0.013772   mae: 0.090783   val_loss: 0.010797   val_mae: 0.078874\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013601   mae: 0.089855   val_loss: 0.011062   val_mae: 0.080256\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 25s   loss: 0.013617   mae: 0.090352   val_loss: 0.010805   val_mae: 0.079558\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013621   mae: 0.090453   val_loss: 0.009994   val_mae: 0.075363\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013407   mae: 0.089587   val_loss: 0.011754   val_mae: 0.082178\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013655   mae: 0.090302   val_loss: 0.011025   val_mae: 0.079990\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013910   mae: 0.091440   val_loss: 0.010080   val_mae: 0.075494\n",
      "Total:\n",
      "\t \ttime: 0h 2m 19s   loss: 0.013635   mae: 0.090331   val_loss: 0.010787   val_mae: 0.078806\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.013528   mae: 0.089850   val_loss: 0.010448   val_mae: 0.077506\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.013513   mae: 0.089885   val_loss: 0.012101   val_mae: 0.084044\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013728   mae: 0.090734   val_loss: 0.010374   val_mae: 0.077121\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013232   mae: 0.089048   val_loss: 0.011565   val_mae: 0.081456\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.013462   mae: 0.089470   val_loss: 0.010318   val_mae: 0.077190\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013680   mae: 0.090508   val_loss: 0.009908   val_mae: 0.075027\n",
      "Total:\n",
      "\t \ttime: 0h 3m 3s   loss: 0.013524   mae: 0.089916   val_loss: 0.010786   val_mae: 0.078724\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 40s   loss: 0.013434   mae: 0.089400   val_loss: 0.010829   val_mae: 0.079590\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013438   mae: 0.089421   val_loss: 0.010586   val_mae: 0.078889\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013632   mae: 0.090511   val_loss: 0.010616   val_mae: 0.077867\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013250   mae: 0.088796   val_loss: 0.011369   val_mae: 0.080615\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013497   mae: 0.089810   val_loss: 0.010507   val_mae: 0.078139\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013613   mae: 0.090321   val_loss: 0.010076   val_mae: 0.075681\n",
      "Total:\n",
      "\t \ttime: 0h 3m 46s   loss: 0.013477   mae: 0.089710   val_loss: 0.010664   val_mae: 0.078464\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013956   mae: 0.091167   val_loss: 0.010814   val_mae: 0.079321\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013924   mae: 0.091455   val_loss: 0.010785   val_mae: 0.079470\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014301   mae: 0.092682   val_loss: 0.010450   val_mae: 0.077753\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013903   mae: 0.091627   val_loss: 0.011986   val_mae: 0.083033\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014171   mae: 0.092051   val_loss: 0.010852   val_mae: 0.079682\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014161   mae: 0.092374   val_loss: 0.010192   val_mae: 0.076204\n",
      "Total:\n",
      "\t \ttime: 0h 0m 37s   loss: 0.014069   mae: 0.091893   val_loss: 0.010847   val_mae: 0.079244\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013795   mae: 0.091003   val_loss: 0.010874   val_mae: 0.078854\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013755   mae: 0.090616   val_loss: 0.010845   val_mae: 0.079826\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013744   mae: 0.090796   val_loss: 0.010761   val_mae: 0.078429\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013605   mae: 0.090344   val_loss: 0.011517   val_mae: 0.081492\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013776   mae: 0.090802   val_loss: 0.010905   val_mae: 0.080016\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013946   mae: 0.091715   val_loss: 0.010035   val_mae: 0.075262\n",
      "Total:\n",
      "\t \ttime: 0h 0m 58s   loss: 0.013770   mae: 0.090879   val_loss: 0.010823   val_mae: 0.078980\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013677   mae: 0.090254   val_loss: 0.010988   val_mae: 0.080439\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013558   mae: 0.090009   val_loss: 0.011355   val_mae: 0.081268\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013789   mae: 0.091074   val_loss: 0.010253   val_mae: 0.075769\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013349   mae: 0.089408   val_loss: 0.011752   val_mae: 0.082173\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013639   mae: 0.090332   val_loss: 0.010352   val_mae: 0.077741\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013669   mae: 0.090620   val_loss: 0.010426   val_mae: 0.076642\n",
      "Total:\n",
      "\t \ttime: 0h 1m 18s   loss: 0.013614   mae: 0.090283   val_loss: 0.010854   val_mae: 0.079005\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013542   mae: 0.089897   val_loss: 0.010551   val_mae: 0.078274\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013510   mae: 0.089763   val_loss: 0.010471   val_mae: 0.078259\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013629   mae: 0.090414   val_loss: 0.010240   val_mae: 0.075819\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013264   mae: 0.089044   val_loss: 0.011413   val_mae: 0.080841\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013623   mae: 0.090405   val_loss: 0.011142   val_mae: 0.080318\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013574   mae: 0.090315   val_loss: 0.010354   val_mae: 0.076636\n",
      "Total:\n",
      "\t \ttime: 0h 1m 41s   loss: 0.013524   mae: 0.089973   val_loss: 0.010695   val_mae: 0.078358\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013506   mae: 0.089759   val_loss: 0.010683   val_mae: 0.078962\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013566   mae: 0.090003   val_loss: 0.010587   val_mae: 0.078631\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013531   mae: 0.090191   val_loss: 0.010470   val_mae: 0.077410\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013259   mae: 0.088998   val_loss: 0.011331   val_mae: 0.080757\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013471   mae: 0.089677   val_loss: 0.010473   val_mae: 0.078085\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013582   mae: 0.090231   val_loss: 0.009948   val_mae: 0.075188\n",
      "Total:\n",
      "\t \ttime: 0h 2m 4s   loss: 0.013486   mae: 0.089810   val_loss: 0.010582   val_mae: 0.078172\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014319   mae: 0.092618   val_loss: 0.011211   val_mae: 0.080974\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014019   mae: 0.091628   val_loss: 0.010732   val_mae: 0.079219\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014351   mae: 0.093238   val_loss: 0.010554   val_mae: 0.078388\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013955   mae: 0.091497   val_loss: 0.011538   val_mae: 0.081850\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014203   mae: 0.092454   val_loss: 0.010949   val_mae: 0.081036\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014384   mae: 0.093437   val_loss: 0.010260   val_mae: 0.076978\n",
      "Total:\n",
      "\t \ttime: 0h 0m 27s   loss: 0.014205   mae: 0.092479   val_loss: 0.010874   val_mae: 0.079741\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013870   mae: 0.091335   val_loss: 0.011110   val_mae: 0.080579\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013752   mae: 0.090716   val_loss: 0.010840   val_mae: 0.079800\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013706   mae: 0.090709   val_loss: 0.010610   val_mae: 0.077998\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013619   mae: 0.090223   val_loss: 0.011678   val_mae: 0.082090\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013751   mae: 0.090596   val_loss: 0.010309   val_mae: 0.077859\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013943   mae: 0.091597   val_loss: 0.010114   val_mae: 0.075739\n",
      "Total:\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013774   mae: 0.090863   val_loss: 0.010777   val_mae: 0.079011\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013636   mae: 0.090196   val_loss: 0.010347   val_mae: 0.077200\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013597   mae: 0.090117   val_loss: 0.010790   val_mae: 0.079417\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013603   mae: 0.090472   val_loss: 0.010160   val_mae: 0.076399\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013404   mae: 0.089445   val_loss: 0.011552   val_mae: 0.081565\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013646   mae: 0.090167   val_loss: 0.010521   val_mae: 0.078386\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013879   mae: 0.091191   val_loss: 0.010097   val_mae: 0.075438\n",
      "Total:\n",
      "\t \ttime: 0h 0m 49s   loss: 0.013627   mae: 0.090265   val_loss: 0.010578   val_mae: 0.078067\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013571   mae: 0.089880   val_loss: 0.010932   val_mae: 0.079992\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013523   mae: 0.090082   val_loss: 0.010511   val_mae: 0.078095\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013726   mae: 0.090709   val_loss: 0.010804   val_mae: 0.079295\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013293   mae: 0.088730   val_loss: 0.012322   val_mae: 0.084818\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013363   mae: 0.089344   val_loss: 0.010316   val_mae: 0.077679\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013685   mae: 0.090762   val_loss: 0.009986   val_mae: 0.075348\n",
      "Total:\n",
      "\t \ttime: 0h 1m 0s   loss: 0.013527   mae: 0.089918   val_loss: 0.010812   val_mae: 0.079205\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013558   mae: 0.089776   val_loss: 0.010496   val_mae: 0.078276\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013469   mae: 0.089877   val_loss: 0.010686   val_mae: 0.079447\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013523   mae: 0.090167   val_loss: 0.010093   val_mae: 0.076014\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013303   mae: 0.089130   val_loss: 0.012205   val_mae: 0.083673\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013420   mae: 0.089464   val_loss: 0.010317   val_mae: 0.078186\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013627   mae: 0.090247   val_loss: 0.010087   val_mae: 0.075726\n",
      "Total:\n",
      "\t \ttime: 0h 1m 14s   loss: 0.013483   mae: 0.089777   val_loss: 0.010648   val_mae: 0.078554\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014422   mae: 0.092754   val_loss: 0.011301   val_mae: 0.080689\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014379   mae: 0.092747   val_loss: 0.011075   val_mae: 0.079457\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014603   mae: 0.093784   val_loss: 0.011101   val_mae: 0.080614\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014237   mae: 0.092431   val_loss: 0.011711   val_mae: 0.082015\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014512   mae: 0.093362   val_loss: 0.010622   val_mae: 0.078589\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014405   mae: 0.092965   val_loss: 0.010409   val_mae: 0.076228\n",
      "Total:\n",
      "\t \ttime: 0h 0m 55s   loss: 0.014426   mae: 0.093007   val_loss: 0.011036   val_mae: 0.079599\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014095   mae: 0.091825   val_loss: 0.010614   val_mae: 0.079102\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014004   mae: 0.091517   val_loss: 0.010863   val_mae: 0.079265\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014267   mae: 0.092726   val_loss: 0.010357   val_mae: 0.076609\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013972   mae: 0.091386   val_loss: 0.011839   val_mae: 0.083798\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014165   mae: 0.092143   val_loss: 0.011377   val_mae: 0.081186\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014204   mae: 0.092336   val_loss: 0.010424   val_mae: 0.077811\n",
      "Total:\n",
      "\t \ttime: 0h 1m 37s   loss: 0.014118   mae: 0.091989   val_loss: 0.010912   val_mae: 0.079628\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014129   mae: 0.091868   val_loss: 0.010650   val_mae: 0.079897\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.014062   mae: 0.091696   val_loss: 0.010613   val_mae: 0.079032\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.014034   mae: 0.091814   val_loss: 0.010184   val_mae: 0.076354\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013756   mae: 0.090882   val_loss: 0.011192   val_mae: 0.080375\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014098   mae: 0.091836   val_loss: 0.010641   val_mae: 0.078944\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013981   mae: 0.091660   val_loss: 0.010602   val_mae: 0.078427\n",
      "Total:\n",
      "\t \ttime: 0h 2m 18s   loss: 0.014010   mae: 0.091626   val_loss: 0.010647   val_mae: 0.078838\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 33s   loss: 0.013927   mae: 0.091020   val_loss: 0.010658   val_mae: 0.079037\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.013945   mae: 0.091312   val_loss: 0.010524   val_mae: 0.078420\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.014002   mae: 0.091940   val_loss: 0.010283   val_mae: 0.076586\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013658   mae: 0.090451   val_loss: 0.011413   val_mae: 0.080894\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013923   mae: 0.091051   val_loss: 0.010733   val_mae: 0.080348\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013997   mae: 0.091855   val_loss: 0.010267   val_mae: 0.075963\n",
      "Total:\n",
      "\t \ttime: 0h 3m 3s   loss: 0.013909   mae: 0.091271   val_loss: 0.010646   val_mae: 0.078541\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013792   mae: 0.090641   val_loss: 0.010625   val_mae: 0.078543\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013841   mae: 0.091129   val_loss: 0.010860   val_mae: 0.078850\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013889   mae: 0.091034   val_loss: 0.010437   val_mae: 0.077118\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013573   mae: 0.090254   val_loss: 0.011835   val_mae: 0.082425\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013807   mae: 0.090784   val_loss: 0.010902   val_mae: 0.079773\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013907   mae: 0.091301   val_loss: 0.011065   val_mae: 0.081582\n",
      "Total:\n",
      "\t \ttime: 0h 3m 42s   loss: 0.013801   mae: 0.090857   val_loss: 0.010954   val_mae: 0.079715\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014189   mae: 0.092042   val_loss: 0.010777   val_mae: 0.078562\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014107   mae: 0.092098   val_loss: 0.010916   val_mae: 0.079689\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014436   mae: 0.093295   val_loss: 0.011372   val_mae: 0.081619\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014122   mae: 0.092031   val_loss: 0.012152   val_mae: 0.084777\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014213   mae: 0.092363   val_loss: 0.010937   val_mae: 0.080079\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014507   mae: 0.093603   val_loss: 0.010252   val_mae: 0.076622\n",
      "Total:\n",
      "\t \ttime: 0h 0m 37s   loss: 0.014263   mae: 0.092572   val_loss: 0.011068   val_mae: 0.080225\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014015   mae: 0.091676   val_loss: 0.010797   val_mae: 0.078702\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013867   mae: 0.091016   val_loss: 0.010466   val_mae: 0.078183\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014037   mae: 0.091828   val_loss: 0.010170   val_mae: 0.077067\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013759   mae: 0.090688   val_loss: 0.011473   val_mae: 0.081567\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014237   mae: 0.092342   val_loss: 0.010567   val_mae: 0.078648\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014060   mae: 0.091925   val_loss: 0.010298   val_mae: 0.076258\n",
      "Total:\n",
      "\t \ttime: 0h 0m 59s   loss: 0.013996   mae: 0.091579   val_loss: 0.010629   val_mae: 0.078404\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013913   mae: 0.091111   val_loss: 0.010823   val_mae: 0.078828\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013930   mae: 0.091346   val_loss: 0.011689   val_mae: 0.082725\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014061   mae: 0.091819   val_loss: 0.010689   val_mae: 0.078401\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013669   mae: 0.090580   val_loss: 0.011178   val_mae: 0.079969\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013791   mae: 0.090892   val_loss: 0.011310   val_mae: 0.080817\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013960   mae: 0.091658   val_loss: 0.010236   val_mae: 0.075996\n",
      "Total:\n",
      "\t \ttime: 0h 1m 19s   loss: 0.013887   mae: 0.091234   val_loss: 0.010988   val_mae: 0.079456\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013851   mae: 0.091065   val_loss: 0.010379   val_mae: 0.077755\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013827   mae: 0.091000   val_loss: 0.010888   val_mae: 0.079347\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013746   mae: 0.090995   val_loss: 0.011197   val_mae: 0.081714\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013677   mae: 0.090453   val_loss: 0.011994   val_mae: 0.084161\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013776   mae: 0.090797   val_loss: 0.010523   val_mae: 0.077944\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013974   mae: 0.091710   val_loss: 0.010055   val_mae: 0.074958\n",
      "Total:\n",
      "\t \ttime: 0h 1m 41s   loss: 0.013808   mae: 0.091003   val_loss: 0.010839   val_mae: 0.079313\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013672   mae: 0.090353   val_loss: 0.011107   val_mae: 0.080274\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013632   mae: 0.090259   val_loss: 0.010651   val_mae: 0.079669\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013871   mae: 0.091243   val_loss: 0.010218   val_mae: 0.077227\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013552   mae: 0.090112   val_loss: 0.012106   val_mae: 0.083620\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013667   mae: 0.090583   val_loss: 0.011051   val_mae: 0.079872\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013874   mae: 0.091260   val_loss: 0.010685   val_mae: 0.078117\n",
      "Total:\n",
      "\t \ttime: 0h 2m 2s   loss: 0.013711   mae: 0.090635   val_loss: 0.010970   val_mae: 0.079797\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014306   mae: 0.092903   val_loss: 0.010731   val_mae: 0.078064\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014263   mae: 0.092321   val_loss: 0.011025   val_mae: 0.079934\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014115   mae: 0.092321   val_loss: 0.010732   val_mae: 0.078122\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.013896   mae: 0.091299   val_loss: 0.011676   val_mae: 0.081807\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014322   mae: 0.092707   val_loss: 0.010897   val_mae: 0.080212\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014476   mae: 0.093502   val_loss: 0.010756   val_mae: 0.079353\n",
      "Total:\n",
      "\t \ttime: 0h 0m 27s   loss: 0.014230   mae: 0.092509   val_loss: 0.010970   val_mae: 0.079582\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014119   mae: 0.092043   val_loss: 0.010885   val_mae: 0.079056\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013962   mae: 0.091291   val_loss: 0.010818   val_mae: 0.079445\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014056   mae: 0.091952   val_loss: 0.010236   val_mae: 0.076075\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013715   mae: 0.090422   val_loss: 0.011819   val_mae: 0.083079\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013813   mae: 0.090793   val_loss: 0.010828   val_mae: 0.079672\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014046   mae: 0.091942   val_loss: 0.010579   val_mae: 0.077829\n",
      "Total:\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013952   mae: 0.091407   val_loss: 0.010861   val_mae: 0.079193\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013803   mae: 0.090629   val_loss: 0.011180   val_mae: 0.081268\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013903   mae: 0.091156   val_loss: 0.011165   val_mae: 0.080997\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013903   mae: 0.091551   val_loss: 0.011475   val_mae: 0.082173\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013475   mae: 0.089871   val_loss: 0.011405   val_mae: 0.080567\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013744   mae: 0.090384   val_loss: 0.010762   val_mae: 0.079356\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014091   mae: 0.092012   val_loss: 0.010433   val_mae: 0.077990\n",
      "Total:\n",
      "\t \ttime: 0h 0m 49s   loss: 0.013820   mae: 0.090934   val_loss: 0.011070   val_mae: 0.080392\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013839   mae: 0.090811   val_loss: 0.010755   val_mae: 0.078747\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013640   mae: 0.090297   val_loss: 0.010464   val_mae: 0.077996\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013801   mae: 0.091128   val_loss: 0.010379   val_mae: 0.077646\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013565   mae: 0.089988   val_loss: 0.011543   val_mae: 0.081520\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013761   mae: 0.090780   val_loss: 0.010558   val_mae: 0.078928\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013833   mae: 0.091262   val_loss: 0.010055   val_mae: 0.075237\n",
      "Total:\n",
      "\t \ttime: 0h 1m 1s   loss: 0.013740   mae: 0.090711   val_loss: 0.010626   val_mae: 0.078346\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013775   mae: 0.090694   val_loss: 0.010676   val_mae: 0.078003\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013560   mae: 0.089928   val_loss: 0.011105   val_mae: 0.080829\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013667   mae: 0.090449   val_loss: 0.010557   val_mae: 0.078176\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013366   mae: 0.089281   val_loss: 0.011505   val_mae: 0.080852\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013664   mae: 0.090271   val_loss: 0.010645   val_mae: 0.079386\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013842   mae: 0.091161   val_loss: 0.010145   val_mae: 0.076317\n",
      "Total:\n",
      "\t \ttime: 0h 1m 11s   loss: 0.013646   mae: 0.090297   val_loss: 0.010772   val_mae: 0.078927\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.016355   mae: 0.100315   val_loss: 0.013233   val_mae: 0.089924\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.015651   mae: 0.097562   val_loss: 0.013162   val_mae: 0.089287\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.016162   mae: 0.100559   val_loss: 0.012744   val_mae: 0.089495\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014989   mae: 0.095619   val_loss: 0.013126   val_mae: 0.089252\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.015902   mae: 0.098893   val_loss: 0.012268   val_mae: 0.086636\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.016988   mae: 0.103581   val_loss: 0.012872   val_mae: 0.088277\n",
      "Total:\n",
      "\t \ttime: 0h 1m 2s   loss: 0.016008   mae: 0.099421   val_loss: 0.012901   val_mae: 0.088812\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014212   mae: 0.092352   val_loss: 0.010946   val_mae: 0.079990\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014314   mae: 0.093154   val_loss: 0.011865   val_mae: 0.084742\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014471   mae: 0.093863   val_loss: 0.011324   val_mae: 0.082292\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.014217   mae: 0.092546   val_loss: 0.012368   val_mae: 0.085583\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014203   mae: 0.092693   val_loss: 0.011256   val_mae: 0.081333\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014474   mae: 0.094024   val_loss: 0.010789   val_mae: 0.079786\n",
      "Total:\n",
      "\t \ttime: 0h 1m 44s   loss: 0.014315   mae: 0.093105   val_loss: 0.011425   val_mae: 0.082288\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 25s   loss: 0.013896   mae: 0.091342   val_loss: 0.010993   val_mae: 0.080672\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013716   mae: 0.090426   val_loss: 0.010701   val_mae: 0.079355\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 25s   loss: 0.013926   mae: 0.091551   val_loss: 0.010251   val_mae: 0.076534\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013612   mae: 0.090545   val_loss: 0.011718   val_mae: 0.082833\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013998   mae: 0.091879   val_loss: 0.010672   val_mae: 0.079117\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014054   mae: 0.092192   val_loss: 0.010395   val_mae: 0.077366\n",
      "Total:\n",
      "\t \ttime: 0h 2m 27s   loss: 0.013867   mae: 0.091323   val_loss: 0.010788   val_mae: 0.079313\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013600   mae: 0.090348   val_loss: 0.010545   val_mae: 0.078639\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 33s   loss: 0.013716   mae: 0.090652   val_loss: 0.010752   val_mae: 0.079559\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013926   mae: 0.091535   val_loss: 0.010544   val_mae: 0.078156\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013464   mae: 0.089854   val_loss: 0.011742   val_mae: 0.082687\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013809   mae: 0.091096   val_loss: 0.010763   val_mae: 0.079157\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.014062   mae: 0.092635   val_loss: 0.010290   val_mae: 0.077352\n",
      "Total:\n",
      "\t \ttime: 0h 3m 13s   loss: 0.013763   mae: 0.091020   val_loss: 0.010773   val_mae: 0.079258\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013530   mae: 0.089832   val_loss: 0.010503   val_mae: 0.078607\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013510   mae: 0.090149   val_loss: 0.010764   val_mae: 0.079522\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 43s   loss: 0.013613   mae: 0.090500   val_loss: 0.010542   val_mae: 0.077736\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013329   mae: 0.089262   val_loss: 0.011565   val_mae: 0.081729\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013649   mae: 0.090406   val_loss: 0.010708   val_mae: 0.079209\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013642   mae: 0.090530   val_loss: 0.009882   val_mae: 0.074862\n",
      "Total:\n",
      "\t \ttime: 0h 3m 58s   loss: 0.013545   mae: 0.090113   val_loss: 0.010661   val_mae: 0.078611\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.022905   mae: 0.121699   val_loss: 0.018479   val_mae: 0.109415\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.016368   mae: 0.100513   val_loss: 0.013814   val_mae: 0.092171\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.017807   mae: 0.105624   val_loss: 0.014326   val_mae: 0.094800\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.016881   mae: 0.102147   val_loss: 0.014797   val_mae: 0.095417\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.017571   mae: 0.104341   val_loss: 0.014530   val_mae: 0.094356\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.017560   mae: 0.104738   val_loss: 0.014092   val_mae: 0.092325\n",
      "Total:\n",
      "\t \ttime: 0h 0m 44s   loss: 0.018182   mae: 0.106510   val_loss: 0.015006   val_mae: 0.096414\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014929   mae: 0.095288   val_loss: 0.011993   val_mae: 0.085208\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.015288   mae: 0.096556   val_loss: 0.012976   val_mae: 0.088198\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.015398   mae: 0.097071   val_loss: 0.012062   val_mae: 0.085014\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014409   mae: 0.093500   val_loss: 0.012463   val_mae: 0.086600\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014311   mae: 0.092845   val_loss: 0.011158   val_mae: 0.081743\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014586   mae: 0.094470   val_loss: 0.010747   val_mae: 0.079459\n",
      "Total:\n",
      "\t \ttime: 0h 1m 6s   loss: 0.014820   mae: 0.094955   val_loss: 0.011900   val_mae: 0.084371\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.014269   mae: 0.092213   val_loss: 0.011197   val_mae: 0.081273\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.014249   mae: 0.092686   val_loss: 0.011512   val_mae: 0.083393\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.014051   mae: 0.092007   val_loss: 0.010635   val_mae: 0.078642\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.014109   mae: 0.092308   val_loss: 0.012248   val_mae: 0.085232\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.014299   mae: 0.092736   val_loss: 0.011088   val_mae: 0.081315\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.014930   mae: 0.096097   val_loss: 0.011184   val_mae: 0.081029\n",
      "Total:\n",
      "\t \ttime: 0h 1m 26s   loss: 0.014318   mae: 0.093008   val_loss: 0.011311   val_mae: 0.081814\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013971   mae: 0.091717   val_loss: 0.011047   val_mae: 0.081485\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013870   mae: 0.091382   val_loss: 0.010744   val_mae: 0.079750\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013857   mae: 0.091339   val_loss: 0.010272   val_mae: 0.076970\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013467   mae: 0.089719   val_loss: 0.011543   val_mae: 0.081431\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.014886   mae: 0.094345   val_loss: 0.011778   val_mae: 0.083021\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.014039   mae: 0.092349   val_loss: 0.010321   val_mae: 0.077717\n",
      "Total:\n",
      "\t \ttime: 0h 1m 50s   loss: 0.014015   mae: 0.091809   val_loss: 0.010951   val_mae: 0.080062\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013662   mae: 0.090505   val_loss: 0.010722   val_mae: 0.079249\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013676   mae: 0.090692   val_loss: 0.010715   val_mae: 0.079666\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013937   mae: 0.091764   val_loss: 0.010412   val_mae: 0.077691\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013900   mae: 0.091613   val_loss: 0.011917   val_mae: 0.083966\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013699   mae: 0.090532   val_loss: 0.010759   val_mae: 0.079432\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013814   mae: 0.091373   val_loss: 0.009990   val_mae: 0.076077\n",
      "Total:\n",
      "\t \ttime: 0h 2m 12s   loss: 0.013781   mae: 0.091080   val_loss: 0.010752   val_mae: 0.079347\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.021972   mae: 0.119316   val_loss: 0.017981   val_mae: 0.107464\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.023798   mae: 0.124047   val_loss: 0.020813   val_mae: 0.116433\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.025383   mae: 0.129073   val_loss: 0.021956   val_mae: 0.120861\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.036499   mae: 0.154331   val_loss: 0.032427   val_mae: 0.145804\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.029084   mae: 0.138790   val_loss: 0.024131   val_mae: 0.126584\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.029204   mae: 0.139147   val_loss: 0.023966   val_mae: 0.126215\n",
      "Total:\n",
      "\t \ttime: 0h 0m 33s   loss: 0.027657   mae: 0.134117   val_loss: 0.023545   val_mae: 0.123894\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.017209   mae: 0.103813   val_loss: 0.013632   val_mae: 0.091829\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.016103   mae: 0.099459   val_loss: 0.013443   val_mae: 0.090826\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.017839   mae: 0.104559   val_loss: 0.014819   val_mae: 0.094558\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.015575   mae: 0.097729   val_loss: 0.013588   val_mae: 0.091190\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.017053   mae: 0.101632   val_loss: 0.014244   val_mae: 0.092059\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.021055   mae: 0.117324   val_loss: 0.017190   val_mae: 0.104327\n",
      "Total:\n",
      "\t \ttime: 0h 0m 44s   loss: 0.017472   mae: 0.104086   val_loss: 0.014486   val_mae: 0.094132\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014597   mae: 0.094000   val_loss: 0.011375   val_mae: 0.082759\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014232   mae: 0.092562   val_loss: 0.011254   val_mae: 0.082270\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.015091   mae: 0.096271   val_loss: 0.011826   val_mae: 0.085086\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014409   mae: 0.093485   val_loss: 0.012821   val_mae: 0.087846\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014754   mae: 0.095301   val_loss: 0.011730   val_mae: 0.084915\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014537   mae: 0.094452   val_loss: 0.011209   val_mae: 0.081500\n",
      "Total:\n",
      "\t \ttime: 0h 0m 56s   loss: 0.014603   mae: 0.094345   val_loss: 0.011703   val_mae: 0.084063\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014104   mae: 0.092331   val_loss: 0.011180   val_mae: 0.081165\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014140   mae: 0.092051   val_loss: 0.011291   val_mae: 0.081896\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014848   mae: 0.094912   val_loss: 0.011439   val_mae: 0.081946\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013964   mae: 0.091374   val_loss: 0.011948   val_mae: 0.083697\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013890   mae: 0.091572   val_loss: 0.010698   val_mae: 0.079784\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014183   mae: 0.092999   val_loss: 0.010472   val_mae: 0.078490\n",
      "Total:\n",
      "\t \ttime: 0h 1m 9s   loss: 0.014188   mae: 0.092540   val_loss: 0.011171   val_mae: 0.081163\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.014060   mae: 0.092160   val_loss: 0.011040   val_mae: 0.080851\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013935   mae: 0.091565   val_loss: 0.011030   val_mae: 0.081053\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.014065   mae: 0.092553   val_loss: 0.010707   val_mae: 0.079828\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013617   mae: 0.090720   val_loss: 0.011940   val_mae: 0.083441\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013724   mae: 0.090734   val_loss: 0.010641   val_mae: 0.079623\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.014040   mae: 0.092379   val_loss: 0.010239   val_mae: 0.077024\n",
      "Total:\n",
      "\t \ttime: 0h 1m 20s   loss: 0.013907   mae: 0.091685   val_loss: 0.010933   val_mae: 0.080303\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014151   mae: 0.091916   val_loss: 0.010712   val_mae: 0.079441\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014233   mae: 0.092353   val_loss: 0.010689   val_mae: 0.078763\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014347   mae: 0.092932   val_loss: 0.010694   val_mae: 0.078705\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013936   mae: 0.091613   val_loss: 0.011554   val_mae: 0.081250\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013994   mae: 0.091466   val_loss: 0.010811   val_mae: 0.079550\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014351   mae: 0.093077   val_loss: 0.010191   val_mae: 0.076089\n",
      "Total:\n",
      "\t \ttime: 0h 1m 2s   loss: 0.014169   mae: 0.092226   val_loss: 0.010775   val_mae: 0.078966\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013937   mae: 0.091206   val_loss: 0.010719   val_mae: 0.079547\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013833   mae: 0.091002   val_loss: 0.011027   val_mae: 0.080178\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013929   mae: 0.091536   val_loss: 0.010450   val_mae: 0.076791\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013663   mae: 0.090571   val_loss: 0.012137   val_mae: 0.084451\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013869   mae: 0.091067   val_loss: 0.011007   val_mae: 0.079767\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013855   mae: 0.091402   val_loss: 0.010986   val_mae: 0.080836\n",
      "Total:\n",
      "\t \ttime: 0h 1m 45s   loss: 0.013847   mae: 0.091131   val_loss: 0.011054   val_mae: 0.080262\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013757   mae: 0.090445   val_loss: 0.010641   val_mae: 0.078357\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013816   mae: 0.090883   val_loss: 0.011848   val_mae: 0.083677\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013772   mae: 0.090927   val_loss: 0.010644   val_mae: 0.078355\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013423   mae: 0.089435   val_loss: 0.011529   val_mae: 0.081642\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013669   mae: 0.090483   val_loss: 0.010757   val_mae: 0.079290\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013821   mae: 0.091142   val_loss: 0.010138   val_mae: 0.075890\n",
      "Total:\n",
      "\t \ttime: 0h 2m 25s   loss: 0.013710   mae: 0.090552   val_loss: 0.010926   val_mae: 0.079535\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013569   mae: 0.090079   val_loss: 0.010581   val_mae: 0.078446\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013628   mae: 0.090219   val_loss: 0.010559   val_mae: 0.078397\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013620   mae: 0.090530   val_loss: 0.010402   val_mae: 0.076979\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013358   mae: 0.089282   val_loss: 0.011264   val_mae: 0.080246\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013544   mae: 0.090017   val_loss: 0.010459   val_mae: 0.077595\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013730   mae: 0.090686   val_loss: 0.010770   val_mae: 0.078438\n",
      "Total:\n",
      "\t \ttime: 0h 3m 13s   loss: 0.013575   mae: 0.090136   val_loss: 0.010673   val_mae: 0.078350\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013471   mae: 0.089604   val_loss: 0.010489   val_mae: 0.078148\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013391   mae: 0.089562   val_loss: 0.010642   val_mae: 0.078618\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 40s   loss: 0.013602   mae: 0.090308   val_loss: 0.010167   val_mae: 0.075868\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 41s   loss: 0.013275   mae: 0.088976   val_loss: 0.011368   val_mae: 0.080662\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013484   mae: 0.089681   val_loss: 0.010568   val_mae: 0.078529\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013587   mae: 0.090219   val_loss: 0.009928   val_mae: 0.074880\n",
      "Total:\n",
      "\t \ttime: 0h 3m 56s   loss: 0.013468   mae: 0.089725   val_loss: 0.010527   val_mae: 0.077784\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014273   mae: 0.092481   val_loss: 0.011288   val_mae: 0.081131\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013945   mae: 0.091391   val_loss: 0.010814   val_mae: 0.079549\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014226   mae: 0.092762   val_loss: 0.010467   val_mae: 0.078008\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013907   mae: 0.091169   val_loss: 0.011516   val_mae: 0.081766\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013919   mae: 0.091425   val_loss: 0.010850   val_mae: 0.079774\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014316   mae: 0.093098   val_loss: 0.010201   val_mae: 0.076528\n",
      "Total:\n",
      "\t \ttime: 0h 0m 42s   loss: 0.014098   mae: 0.092054   val_loss: 0.010856   val_mae: 0.079459\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013834   mae: 0.090901   val_loss: 0.010935   val_mae: 0.079994\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013806   mae: 0.091034   val_loss: 0.010742   val_mae: 0.079548\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013968   mae: 0.091566   val_loss: 0.010220   val_mae: 0.076299\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013536   mae: 0.089932   val_loss: 0.011873   val_mae: 0.082623\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013671   mae: 0.090427   val_loss: 0.010401   val_mae: 0.078320\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014061   mae: 0.092085   val_loss: 0.010262   val_mae: 0.076439\n",
      "Total:\n",
      "\t \ttime: 0h 1m 5s   loss: 0.013813   mae: 0.090991   val_loss: 0.010739   val_mae: 0.078870\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013739   mae: 0.090573   val_loss: 0.010430   val_mae: 0.077735\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013589   mae: 0.090275   val_loss: 0.010429   val_mae: 0.077866\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013696   mae: 0.090819   val_loss: 0.010310   val_mae: 0.077160\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013437   mae: 0.089654   val_loss: 0.011895   val_mae: 0.082711\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013728   mae: 0.090821   val_loss: 0.010686   val_mae: 0.079130\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013855   mae: 0.091230   val_loss: 0.010214   val_mae: 0.076370\n",
      "Total:\n",
      "\t \ttime: 0h 1m 27s   loss: 0.013674   mae: 0.090562   val_loss: 0.010661   val_mae: 0.078496\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013549   mae: 0.089969   val_loss: 0.010633   val_mae: 0.078401\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013553   mae: 0.089934   val_loss: 0.011315   val_mae: 0.081394\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013658   mae: 0.090479   val_loss: 0.010785   val_mae: 0.079364\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013386   mae: 0.089353   val_loss: 0.011558   val_mae: 0.081550\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013662   mae: 0.090544   val_loss: 0.010516   val_mae: 0.078582\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013687   mae: 0.090468   val_loss: 0.010379   val_mae: 0.076740\n",
      "Total:\n",
      "\t \ttime: 0h 1m 50s   loss: 0.013582   mae: 0.090124   val_loss: 0.010864   val_mae: 0.079339\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013697   mae: 0.090396   val_loss: 0.011152   val_mae: 0.079778\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013557   mae: 0.090153   val_loss: 0.010488   val_mae: 0.078012\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013575   mae: 0.090261   val_loss: 0.010112   val_mae: 0.075530\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013186   mae: 0.088388   val_loss: 0.012144   val_mae: 0.083698\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013606   mae: 0.090221   val_loss: 0.010629   val_mae: 0.078758\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013662   mae: 0.090558   val_loss: 0.009924   val_mae: 0.074993\n",
      "Total:\n",
      "\t \ttime: 0h 2m 12s   loss: 0.013547   mae: 0.089996   val_loss: 0.010741   val_mae: 0.078461\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014046   mae: 0.091883   val_loss: 0.012471   val_mae: 0.085523\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014147   mae: 0.091858   val_loss: 0.011669   val_mae: 0.083143\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014391   mae: 0.093457   val_loss: 0.010659   val_mae: 0.078745\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014036   mae: 0.091866   val_loss: 0.012160   val_mae: 0.084280\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013950   mae: 0.091733   val_loss: 0.010615   val_mae: 0.079092\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014225   mae: 0.092692   val_loss: 0.010702   val_mae: 0.078147\n",
      "Total:\n",
      "\t \ttime: 0h 0m 32s   loss: 0.014133   mae: 0.092248   val_loss: 0.011380   val_mae: 0.081488\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013680   mae: 0.090386   val_loss: 0.010603   val_mae: 0.078602\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013779   mae: 0.090996   val_loss: 0.012249   val_mae: 0.085553\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014074   mae: 0.091788   val_loss: 0.010869   val_mae: 0.078952\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013468   mae: 0.089945   val_loss: 0.011830   val_mae: 0.082951\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013660   mae: 0.090353   val_loss: 0.011010   val_mae: 0.081126\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013871   mae: 0.091439   val_loss: 0.011912   val_mae: 0.084115\n",
      "Total:\n",
      "\t \ttime: 0h 0m 44s   loss: 0.013755   mae: 0.090818   val_loss: 0.011412   val_mae: 0.081883\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013550   mae: 0.090012   val_loss: 0.010866   val_mae: 0.079455\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013557   mae: 0.089841   val_loss: 0.010546   val_mae: 0.078452\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013758   mae: 0.090854   val_loss: 0.010216   val_mae: 0.076032\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013300   mae: 0.089097   val_loss: 0.011610   val_mae: 0.081806\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013666   mae: 0.090396   val_loss: 0.010374   val_mae: 0.077846\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013705   mae: 0.090787   val_loss: 0.010495   val_mae: 0.077850\n",
      "Total:\n",
      "\t \ttime: 0h 0m 55s   loss: 0.013589   mae: 0.090164   val_loss: 0.010685   val_mae: 0.078573\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013760   mae: 0.090632   val_loss: 0.010665   val_mae: 0.078408\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013517   mae: 0.089867   val_loss: 0.010534   val_mae: 0.078723\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013567   mae: 0.090274   val_loss: 0.010104   val_mae: 0.075871\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013360   mae: 0.089490   val_loss: 0.011865   val_mae: 0.082415\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013516   mae: 0.089817   val_loss: 0.010427   val_mae: 0.078129\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013716   mae: 0.090701   val_loss: 0.010439   val_mae: 0.076807\n",
      "Total:\n",
      "\t \ttime: 0h 1m 8s   loss: 0.013573   mae: 0.090130   val_loss: 0.010672   val_mae: 0.078392\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013366   mae: 0.089346   val_loss: 0.010552   val_mae: 0.077728\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013425   mae: 0.089566   val_loss: 0.010789   val_mae: 0.079272\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013532   mae: 0.090056   val_loss: 0.010512   val_mae: 0.077253\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013207   mae: 0.088993   val_loss: 0.011397   val_mae: 0.080782\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013267   mae: 0.089041   val_loss: 0.010609   val_mae: 0.079412\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013603   mae: 0.090651   val_loss: 0.010179   val_mae: 0.075415\n",
      "Total:\n",
      "\t \ttime: 0h 1m 20s   loss: 0.013400   mae: 0.089609   val_loss: 0.010673   val_mae: 0.078310\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014417   mae: 0.092949   val_loss: 0.012018   val_mae: 0.082915\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014249   mae: 0.092608   val_loss: 0.013891   val_mae: 0.090683\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014477   mae: 0.093059   val_loss: 0.010230   val_mae: 0.076521\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014438   mae: 0.093333   val_loss: 0.012023   val_mae: 0.083973\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014564   mae: 0.093226   val_loss: 0.010941   val_mae: 0.080126\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014505   mae: 0.093601   val_loss: 0.012256   val_mae: 0.083648\n",
      "Total:\n",
      "\t \ttime: 0h 1m 3s   loss: 0.014442   mae: 0.093129   val_loss: 0.011893   val_mae: 0.082978\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014173   mae: 0.092019   val_loss: 0.010660   val_mae: 0.078862\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013996   mae: 0.091259   val_loss: 0.010735   val_mae: 0.078694\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.014236   mae: 0.092569   val_loss: 0.010525   val_mae: 0.078300\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014135   mae: 0.091834   val_loss: 0.012709   val_mae: 0.087029\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014203   mae: 0.092356   val_loss: 0.010466   val_mae: 0.077683\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014249   mae: 0.092505   val_loss: 0.010889   val_mae: 0.079149\n",
      "Total:\n",
      "\t \ttime: 0h 1m 45s   loss: 0.014166   mae: 0.092090   val_loss: 0.010998   val_mae: 0.079953\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014045   mae: 0.091408   val_loss: 0.010446   val_mae: 0.078192\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013905   mae: 0.091348   val_loss: 0.010662   val_mae: 0.078649\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014292   mae: 0.092576   val_loss: 0.010257   val_mae: 0.076936\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013745   mae: 0.090813   val_loss: 0.011550   val_mae: 0.081764\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 26s   loss: 0.014033   mae: 0.091740   val_loss: 0.010910   val_mae: 0.080266\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014182   mae: 0.092310   val_loss: 0.010828   val_mae: 0.079571\n",
      "Total:\n",
      "\t \ttime: 0h 2m 27s   loss: 0.014034   mae: 0.091699   val_loss: 0.010776   val_mae: 0.079229\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013949   mae: 0.091089   val_loss: 0.010461   val_mae: 0.077875\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013904   mae: 0.091066   val_loss: 0.010974   val_mae: 0.081176\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013905   mae: 0.091555   val_loss: 0.010108   val_mae: 0.075842\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013633   mae: 0.090216   val_loss: 0.011575   val_mae: 0.081290\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.014011   mae: 0.091641   val_loss: 0.010469   val_mae: 0.077800\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013978   mae: 0.091569   val_loss: 0.010366   val_mae: 0.076830\n",
      "Total:\n",
      "\t \ttime: 0h 3m 13s   loss: 0.013897   mae: 0.091189   val_loss: 0.010659   val_mae: 0.078469\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013897   mae: 0.091012   val_loss: 0.011371   val_mae: 0.081923\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 40s   loss: 0.013725   mae: 0.090778   val_loss: 0.010709   val_mae: 0.078800\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013897   mae: 0.091251   val_loss: 0.010333   val_mae: 0.076458\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013655   mae: 0.090412   val_loss: 0.011971   val_mae: 0.082574\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013769   mae: 0.090594   val_loss: 0.010586   val_mae: 0.077693\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013884   mae: 0.091392   val_loss: 0.010503   val_mae: 0.076728\n",
      "Total:\n",
      "\t \ttime: 0h 3m 58s   loss: 0.013804   mae: 0.090907   val_loss: 0.010912   val_mae: 0.079029\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014349   mae: 0.092774   val_loss: 0.011030   val_mae: 0.080546\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014297   mae: 0.092647   val_loss: 0.010880   val_mae: 0.080352\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014544   mae: 0.093657   val_loss: 0.010611   val_mae: 0.078295\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014038   mae: 0.091671   val_loss: 0.011689   val_mae: 0.082211\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014380   mae: 0.092865   val_loss: 0.010818   val_mae: 0.079891\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014389   mae: 0.093491   val_loss: 0.012914   val_mae: 0.087463\n",
      "Total:\n",
      "\t \ttime: 0h 0m 43s   loss: 0.014333   mae: 0.092851   val_loss: 0.011324   val_mae: 0.081460\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014209   mae: 0.092140   val_loss: 0.010999   val_mae: 0.080700\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013945   mae: 0.091329   val_loss: 0.011041   val_mae: 0.081225\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014059   mae: 0.091764   val_loss: 0.010799   val_mae: 0.079041\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013985   mae: 0.091505   val_loss: 0.012788   val_mae: 0.085621\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013998   mae: 0.091735   val_loss: 0.010812   val_mae: 0.079192\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014328   mae: 0.092891   val_loss: 0.011060   val_mae: 0.080238\n",
      "Total:\n",
      "\t \ttime: 0h 1m 5s   loss: 0.014087   mae: 0.091894   val_loss: 0.011250   val_mae: 0.081003\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013842   mae: 0.090957   val_loss: 0.010518   val_mae: 0.078008\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013869   mae: 0.091156   val_loss: 0.011132   val_mae: 0.080227\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.014080   mae: 0.091994   val_loss: 0.012171   val_mae: 0.085013\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013644   mae: 0.090166   val_loss: 0.011820   val_mae: 0.083334\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013906   mae: 0.091089   val_loss: 0.010661   val_mae: 0.078973\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014021   mae: 0.091926   val_loss: 0.010408   val_mae: 0.076082\n",
      "Total:\n",
      "\t \ttime: 0h 1m 26s   loss: 0.013894   mae: 0.091215   val_loss: 0.011118   val_mae: 0.080273\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013809   mae: 0.090534   val_loss: 0.011070   val_mae: 0.079455\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013877   mae: 0.091127   val_loss: 0.011826   val_mae: 0.084236\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013901   mae: 0.091478   val_loss: 0.010440   val_mae: 0.076903\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013531   mae: 0.089627   val_loss: 0.011973   val_mae: 0.082898\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013669   mae: 0.090519   val_loss: 0.011073   val_mae: 0.080630\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013883   mae: 0.091244   val_loss: 0.010481   val_mae: 0.076717\n",
      "Total:\n",
      "\t \ttime: 0h 1m 50s   loss: 0.013778   mae: 0.090755   val_loss: 0.011144   val_mae: 0.080140\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013623   mae: 0.090112   val_loss: 0.010569   val_mae: 0.077674\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013692   mae: 0.090709   val_loss: 0.011708   val_mae: 0.082862\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013835   mae: 0.091128   val_loss: 0.010313   val_mae: 0.076988\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013573   mae: 0.090069   val_loss: 0.011646   val_mae: 0.080673\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013759   mae: 0.090725   val_loss: 0.010334   val_mae: 0.077105\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013878   mae: 0.091221   val_loss: 0.010336   val_mae: 0.077583\n",
      "Total:\n",
      "\t \ttime: 0h 2m 14s   loss: 0.013727   mae: 0.090661   val_loss: 0.010818   val_mae: 0.078814\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014150   mae: 0.092056   val_loss: 0.010571   val_mae: 0.077990\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014195   mae: 0.092013   val_loss: 0.010754   val_mae: 0.078957\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014548   mae: 0.093491   val_loss: 0.010865   val_mae: 0.079775\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013949   mae: 0.091602   val_loss: 0.011863   val_mae: 0.082386\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014157   mae: 0.092052   val_loss: 0.012065   val_mae: 0.085993\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014225   mae: 0.092753   val_loss: 0.010068   val_mae: 0.076133\n",
      "Total:\n",
      "\t \ttime: 0h 0m 33s   loss: 0.014204   mae: 0.092328   val_loss: 0.011031   val_mae: 0.080206\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014060   mae: 0.091637   val_loss: 0.011598   val_mae: 0.082038\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013904   mae: 0.091057   val_loss: 0.010989   val_mae: 0.080141\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014046   mae: 0.091826   val_loss: 0.010345   val_mae: 0.078161\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013730   mae: 0.090840   val_loss: 0.013319   val_mae: 0.089045\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013932   mae: 0.091611   val_loss: 0.010703   val_mae: 0.079891\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013944   mae: 0.091686   val_loss: 0.010223   val_mae: 0.076454\n",
      "Total:\n",
      "\t \ttime: 0h 0m 44s   loss: 0.013936   mae: 0.091443   val_loss: 0.011196   val_mae: 0.080955\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013799   mae: 0.090806   val_loss: 0.010738   val_mae: 0.078645\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013782   mae: 0.090594   val_loss: 0.010634   val_mae: 0.078033\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013854   mae: 0.091139   val_loss: 0.010533   val_mae: 0.078673\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013577   mae: 0.089970   val_loss: 0.011627   val_mae: 0.081214\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013929   mae: 0.091441   val_loss: 0.010582   val_mae: 0.078800\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013982   mae: 0.091785   val_loss: 0.010259   val_mae: 0.077188\n",
      "Total:\n",
      "\t \ttime: 0h 0m 56s   loss: 0.013820   mae: 0.090956   val_loss: 0.010729   val_mae: 0.078759\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013603   mae: 0.090121   val_loss: 0.010661   val_mae: 0.079355\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013756   mae: 0.090768   val_loss: 0.010912   val_mae: 0.079634\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013750   mae: 0.090942   val_loss: 0.010224   val_mae: 0.077511\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013446   mae: 0.089547   val_loss: 0.011742   val_mae: 0.083055\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013590   mae: 0.090252   val_loss: 0.010909   val_mae: 0.080914\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013820   mae: 0.091297   val_loss: 0.010232   val_mae: 0.075872\n",
      "Total:\n",
      "\t \ttime: 0h 1m 8s   loss: 0.013661   mae: 0.090488   val_loss: 0.010780   val_mae: 0.079390\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 64   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013825   mae: 0.090844   val_loss: 0.011886   val_mae: 0.083868\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013666   mae: 0.090256   val_loss: 0.010613   val_mae: 0.078869\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013777   mae: 0.090867   val_loss: 0.010234   val_mae: 0.076209\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013385   mae: 0.089505   val_loss: 0.011314   val_mae: 0.080222\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013691   mae: 0.090434   val_loss: 0.010392   val_mae: 0.077793\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013643   mae: 0.090571   val_loss: 0.010283   val_mae: 0.076079\n",
      "Total:\n",
      "\t \ttime: 0h 1m 21s   loss: 0.013665   mae: 0.090413   val_loss: 0.010787   val_mae: 0.078840\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.015852   mae: 0.098577   val_loss: 0.012896   val_mae: 0.089016\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.015620   mae: 0.097960   val_loss: 0.013094   val_mae: 0.089339\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.016100   mae: 0.099268   val_loss: 0.013069   val_mae: 0.089030\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.015627   mae: 0.097625   val_loss: 0.013871   val_mae: 0.092095\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.015628   mae: 0.098091   val_loss: 0.012546   val_mae: 0.087297\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.015765   mae: 0.098843   val_loss: 0.012224   val_mae: 0.085532\n",
      "Total:\n",
      "\t \ttime: 0h 0m 53s   loss: 0.015765   mae: 0.098394   val_loss: 0.012950   val_mae: 0.088718\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014288   mae: 0.093049   val_loss: 0.011349   val_mae: 0.082613\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014332   mae: 0.093316   val_loss: 0.011656   val_mae: 0.083935\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014399   mae: 0.093679   val_loss: 0.010897   val_mae: 0.080741\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014258   mae: 0.092996   val_loss: 0.012456   val_mae: 0.086564\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014417   mae: 0.093339   val_loss: 0.011498   val_mae: 0.082579\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.014587   mae: 0.094590   val_loss: 0.010970   val_mae: 0.080285\n",
      "Total:\n",
      "\t \ttime: 0h 1m 32s   loss: 0.014380   mae: 0.093495   val_loss: 0.011471   val_mae: 0.082786\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013890   mae: 0.091502   val_loss: 0.010941   val_mae: 0.080240\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014043   mae: 0.092042   val_loss: 0.011373   val_mae: 0.082675\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013939   mae: 0.091822   val_loss: 0.010595   val_mae: 0.078771\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013906   mae: 0.091699   val_loss: 0.011983   val_mae: 0.084610\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013899   mae: 0.091554   val_loss: 0.010639   val_mae: 0.078793\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.014095   mae: 0.092827   val_loss: 0.010230   val_mae: 0.077353\n",
      "Total:\n",
      "\t \ttime: 0h 2m 11s   loss: 0.013962   mae: 0.091908   val_loss: 0.010960   val_mae: 0.080407\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013824   mae: 0.091118   val_loss: 0.010690   val_mae: 0.079665\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013740   mae: 0.091160   val_loss: 0.010941   val_mae: 0.080653\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013842   mae: 0.091668   val_loss: 0.010401   val_mae: 0.077797\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013406   mae: 0.089618   val_loss: 0.011434   val_mae: 0.081860\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013667   mae: 0.090760   val_loss: 0.010709   val_mae: 0.079284\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013998   mae: 0.092297   val_loss: 0.010380   val_mae: 0.077592\n",
      "Total:\n",
      "\t \ttime: 0h 2m 53s   loss: 0.013746   mae: 0.091104   val_loss: 0.010759   val_mae: 0.079475\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013666   mae: 0.090572   val_loss: 0.010612   val_mae: 0.078881\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013708   mae: 0.090748   val_loss: 0.010901   val_mae: 0.080360\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013693   mae: 0.090882   val_loss: 0.010500   val_mae: 0.078160\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013472   mae: 0.089944   val_loss: 0.011539   val_mae: 0.081839\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013598   mae: 0.090395   val_loss: 0.010609   val_mae: 0.078727\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013870   mae: 0.091488   val_loss: 0.010114   val_mae: 0.076388\n",
      "Total:\n",
      "\t \ttime: 0h 3m 39s   loss: 0.013668   mae: 0.090671   val_loss: 0.010712   val_mae: 0.079059\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.017657   mae: 0.104676   val_loss: 0.014627   val_mae: 0.094845\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.017350   mae: 0.104001   val_loss: 0.015264   val_mae: 0.097818\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.018558   mae: 0.108807   val_loss: 0.016499   val_mae: 0.102623\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.017371   mae: 0.104199   val_loss: 0.015608   val_mae: 0.098518\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.017211   mae: 0.103344   val_loss: 0.014142   val_mae: 0.093344\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.017800   mae: 0.105163   val_loss: 0.014664   val_mae: 0.093569\n",
      "Total:\n",
      "\t \ttime: 0h 0m 33s   loss: 0.017658   mae: 0.105032   val_loss: 0.015134   val_mae: 0.096786\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014682   mae: 0.094413   val_loss: 0.011732   val_mae: 0.084317\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014505   mae: 0.094070   val_loss: 0.011946   val_mae: 0.085544\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.015068   mae: 0.096061   val_loss: 0.012284   val_mae: 0.086221\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014683   mae: 0.094292   val_loss: 0.012864   val_mae: 0.088467\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014975   mae: 0.095888   val_loss: 0.011794   val_mae: 0.084977\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.015070   mae: 0.096018   val_loss: 0.011513   val_mae: 0.082394\n",
      "Total:\n",
      "\t \ttime: 0h 0m 53s   loss: 0.014830   mae: 0.095123   val_loss: 0.012022   val_mae: 0.085320\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014185   mae: 0.092564   val_loss: 0.011423   val_mae: 0.082424\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014254   mae: 0.092859   val_loss: 0.011422   val_mae: 0.083176\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014168   mae: 0.092721   val_loss: 0.010828   val_mae: 0.079946\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014019   mae: 0.091930   val_loss: 0.012473   val_mae: 0.086168\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014175   mae: 0.092708   val_loss: 0.011163   val_mae: 0.081978\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014311   mae: 0.093479   val_loss: 0.010566   val_mae: 0.078506\n",
      "Total:\n",
      "\t \ttime: 0h 1m 14s   loss: 0.014185   mae: 0.092710   val_loss: 0.011313   val_mae: 0.082033\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013803   mae: 0.091106   val_loss: 0.010866   val_mae: 0.080483\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013839   mae: 0.091386   val_loss: 0.011176   val_mae: 0.081788\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014053   mae: 0.092654   val_loss: 0.010629   val_mae: 0.078971\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013732   mae: 0.091033   val_loss: 0.011787   val_mae: 0.083076\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013921   mae: 0.091917   val_loss: 0.010807   val_mae: 0.080084\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014021   mae: 0.092483   val_loss: 0.010275   val_mae: 0.077637\n",
      "Total:\n",
      "\t \ttime: 0h 1m 34s   loss: 0.013895   mae: 0.091763   val_loss: 0.010923   val_mae: 0.080340\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013785   mae: 0.091112   val_loss: 0.010804   val_mae: 0.080235\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013759   mae: 0.091101   val_loss: 0.011087   val_mae: 0.081244\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013728   mae: 0.091193   val_loss: 0.010357   val_mae: 0.077595\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013533   mae: 0.090141   val_loss: 0.011689   val_mae: 0.082923\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013767   mae: 0.091201   val_loss: 0.010752   val_mae: 0.079482\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013814   mae: 0.091371   val_loss: 0.010106   val_mae: 0.076415\n",
      "Total:\n",
      "\t \ttime: 0h 1m 56s   loss: 0.013731   mae: 0.091020   val_loss: 0.010799   val_mae: 0.079649\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.021438   mae: 0.116430   val_loss: 0.018080   val_mae: 0.107185\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.020972   mae: 0.115739   val_loss: 0.019202   val_mae: 0.111136\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.020020   mae: 0.112542   val_loss: 0.017378   val_mae: 0.105139\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.019983   mae: 0.112571   val_loss: 0.017555   val_mae: 0.105210\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.022454   mae: 0.119663   val_loss: 0.018719   val_mae: 0.108977\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.022554   mae: 0.120628   val_loss: 0.019477   val_mae: 0.111225\n",
      "Total:\n",
      "\t \ttime: 0h 0m 24s   loss: 0.021237   mae: 0.116262   val_loss: 0.018402   val_mae: 0.108145\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.016249   mae: 0.099988   val_loss: 0.013494   val_mae: 0.090919\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.015792   mae: 0.098649   val_loss: 0.013591   val_mae: 0.091850\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.016108   mae: 0.099795   val_loss: 0.013559   val_mae: 0.091498\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.016255   mae: 0.099156   val_loss: 0.014815   val_mae: 0.094730\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.016242   mae: 0.100369   val_loss: 0.013659   val_mae: 0.091899\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.016094   mae: 0.099699   val_loss: 0.013072   val_mae: 0.087643\n",
      "Total:\n",
      "\t \ttime: 0h 0m 34s   loss: 0.016123   mae: 0.099609   val_loss: 0.013698   val_mae: 0.091423\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014834   mae: 0.095414   val_loss: 0.011798   val_mae: 0.084546\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014993   mae: 0.095280   val_loss: 0.012977   val_mae: 0.089322\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014826   mae: 0.095130   val_loss: 0.011943   val_mae: 0.084872\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014365   mae: 0.093441   val_loss: 0.012532   val_mae: 0.087018\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014891   mae: 0.095548   val_loss: 0.011632   val_mae: 0.083908\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014907   mae: 0.095856   val_loss: 0.011329   val_mae: 0.082350\n",
      "Total:\n",
      "\t \ttime: 0h 0m 44s   loss: 0.014803   mae: 0.095111   val_loss: 0.012035   val_mae: 0.085336\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014229   mae: 0.092912   val_loss: 0.011304   val_mae: 0.081885\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014120   mae: 0.092605   val_loss: 0.011472   val_mae: 0.083707\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014635   mae: 0.094497   val_loss: 0.011625   val_mae: 0.083644\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014074   mae: 0.092453   val_loss: 0.012038   val_mae: 0.085203\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014488   mae: 0.093913   val_loss: 0.011396   val_mae: 0.082904\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014356   mae: 0.093649   val_loss: 0.010857   val_mae: 0.080020\n",
      "Total:\n",
      "\t \ttime: 0h 0m 56s   loss: 0.014317   mae: 0.093338   val_loss: 0.011449   val_mae: 0.082894\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013912   mae: 0.091719   val_loss: 0.011161   val_mae: 0.081230\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014008   mae: 0.092440   val_loss: 0.011197   val_mae: 0.082509\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014112   mae: 0.092518   val_loss: 0.010810   val_mae: 0.080201\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013914   mae: 0.091785   val_loss: 0.012125   val_mae: 0.085568\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014055   mae: 0.092118   val_loss: 0.011027   val_mae: 0.081033\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014430   mae: 0.093724   val_loss: 0.010569   val_mae: 0.078306\n",
      "Total:\n",
      "\t \ttime: 0h 1m 7s   loss: 0.014072   mae: 0.092384   val_loss: 0.011148   val_mae: 0.081474\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014216   mae: 0.092324   val_loss: 0.011020   val_mae: 0.080843\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014022   mae: 0.091689   val_loss: 0.011085   val_mae: 0.080765\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014253   mae: 0.092538   val_loss: 0.010689   val_mae: 0.079006\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013926   mae: 0.091206   val_loss: 0.012469   val_mae: 0.085201\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014114   mae: 0.091935   val_loss: 0.010817   val_mae: 0.079379\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014045   mae: 0.092023   val_loss: 0.010933   val_mae: 0.079474\n",
      "Total:\n",
      "\t \ttime: 0h 0m 53s   loss: 0.014096   mae: 0.091953   val_loss: 0.011169   val_mae: 0.080778\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013896   mae: 0.090836   val_loss: 0.010848   val_mae: 0.079032\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013789   mae: 0.090711   val_loss: 0.011033   val_mae: 0.080035\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013829   mae: 0.090997   val_loss: 0.010441   val_mae: 0.077712\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013503   mae: 0.089792   val_loss: 0.011466   val_mae: 0.081512\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013818   mae: 0.090879   val_loss: 0.010673   val_mae: 0.078466\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013975   mae: 0.091497   val_loss: 0.010189   val_mae: 0.075889\n",
      "Total:\n",
      "\t \ttime: 0h 1m 33s   loss: 0.013802   mae: 0.090785   val_loss: 0.010775   val_mae: 0.078774\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013570   mae: 0.090014   val_loss: 0.010599   val_mae: 0.078451\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013528   mae: 0.089673   val_loss: 0.010618   val_mae: 0.078132\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013697   mae: 0.090670   val_loss: 0.010242   val_mae: 0.076080\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013484   mae: 0.089586   val_loss: 0.011544   val_mae: 0.081477\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013646   mae: 0.090357   val_loss: 0.010516   val_mae: 0.077633\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013741   mae: 0.090709   val_loss: 0.010537   val_mae: 0.077815\n",
      "Total:\n",
      "\t \ttime: 0h 2m 16s   loss: 0.013611   mae: 0.090168   val_loss: 0.010676   val_mae: 0.078265\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013569   mae: 0.089968   val_loss: 0.010464   val_mae: 0.077995\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013485   mae: 0.089755   val_loss: 0.010626   val_mae: 0.078171\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013679   mae: 0.090552   val_loss: 0.010247   val_mae: 0.076281\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013263   mae: 0.088766   val_loss: 0.011255   val_mae: 0.080329\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013501   mae: 0.089941   val_loss: 0.010913   val_mae: 0.079426\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013643   mae: 0.090332   val_loss: 0.010186   val_mae: 0.076287\n",
      "Total:\n",
      "\t \ttime: 0h 2m 55s   loss: 0.013523   mae: 0.089886   val_loss: 0.010615   val_mae: 0.078082\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013430   mae: 0.089408   val_loss: 0.010409   val_mae: 0.077562\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013473   mae: 0.089664   val_loss: 0.010989   val_mae: 0.079744\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013545   mae: 0.090148   val_loss: 0.010342   val_mae: 0.076785\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013183   mae: 0.088667   val_loss: 0.011358   val_mae: 0.080509\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013530   mae: 0.089743   val_loss: 0.010333   val_mae: 0.076990\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013485   mae: 0.089960   val_loss: 0.010130   val_mae: 0.075630\n",
      "Total:\n",
      "\t \ttime: 0h 3m 32s   loss: 0.013441   mae: 0.089598   val_loss: 0.010594   val_mae: 0.077870\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014082   mae: 0.091781   val_loss: 0.011242   val_mae: 0.081529\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014073   mae: 0.091827   val_loss: 0.010942   val_mae: 0.080450\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014156   mae: 0.092180   val_loss: 0.010957   val_mae: 0.079415\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013886   mae: 0.090962   val_loss: 0.011550   val_mae: 0.081668\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014127   mae: 0.092371   val_loss: 0.010722   val_mae: 0.079154\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014275   mae: 0.092682   val_loss: 0.010057   val_mae: 0.075881\n",
      "Total:\n",
      "\t \ttime: 0h 0m 33s   loss: 0.014100   mae: 0.091967   val_loss: 0.010912   val_mae: 0.079683\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013829   mae: 0.090825   val_loss: 0.010900   val_mae: 0.079563\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013793   mae: 0.090795   val_loss: 0.010818   val_mae: 0.079187\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013934   mae: 0.091362   val_loss: 0.010685   val_mae: 0.078323\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013495   mae: 0.089803   val_loss: 0.012025   val_mae: 0.083983\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013857   mae: 0.091074   val_loss: 0.010808   val_mae: 0.079426\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013954   mae: 0.091674   val_loss: 0.010109   val_mae: 0.075750\n",
      "Total:\n",
      "\t \ttime: 0h 0m 54s   loss: 0.013810   mae: 0.090922   val_loss: 0.010891   val_mae: 0.079372\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013690   mae: 0.090406   val_loss: 0.011203   val_mae: 0.080504\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013655   mae: 0.090234   val_loss: 0.011603   val_mae: 0.082523\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013636   mae: 0.090407   val_loss: 0.010123   val_mae: 0.075671\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013474   mae: 0.089613   val_loss: 0.011608   val_mae: 0.081876\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013710   mae: 0.090479   val_loss: 0.011584   val_mae: 0.082129\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013798   mae: 0.091277   val_loss: 0.010123   val_mae: 0.076295\n",
      "Total:\n",
      "\t \ttime: 0h 1m 14s   loss: 0.013660   mae: 0.090403   val_loss: 0.011041   val_mae: 0.079833\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013574   mae: 0.089940   val_loss: 0.010755   val_mae: 0.078901\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013495   mae: 0.089785   val_loss: 0.010722   val_mae: 0.078902\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013553   mae: 0.089963   val_loss: 0.010065   val_mae: 0.075304\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013273   mae: 0.088897   val_loss: 0.011509   val_mae: 0.081348\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013491   mae: 0.089812   val_loss: 0.010457   val_mae: 0.078173\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013657   mae: 0.090323   val_loss: 0.010546   val_mae: 0.076894\n",
      "Total:\n",
      "\t \ttime: 0h 1m 36s   loss: 0.013507   mae: 0.089787   val_loss: 0.010676   val_mae: 0.078253\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013416   mae: 0.089482   val_loss: 0.010617   val_mae: 0.078530\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013445   mae: 0.089320   val_loss: 0.010673   val_mae: 0.078570\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013541   mae: 0.090075   val_loss: 0.010469   val_mae: 0.077098\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013290   mae: 0.089038   val_loss: 0.011770   val_mae: 0.082743\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013458   mae: 0.089699   val_loss: 0.010623   val_mae: 0.078764\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013586   mae: 0.090263   val_loss: 0.009997   val_mae: 0.074895\n",
      "Total:\n",
      "\t \ttime: 0h 1m 55s   loss: 0.013456   mae: 0.089646   val_loss: 0.010692   val_mae: 0.078433\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014185   mae: 0.092141   val_loss: 0.011204   val_mae: 0.080497\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014215   mae: 0.092527   val_loss: 0.011118   val_mae: 0.081289\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014246   mae: 0.092926   val_loss: 0.010668   val_mae: 0.079101\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.013756   mae: 0.090792   val_loss: 0.011658   val_mae: 0.082039\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.013914   mae: 0.091517   val_loss: 0.010890   val_mae: 0.080565\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014153   mae: 0.092547   val_loss: 0.010172   val_mae: 0.076646\n",
      "Total:\n",
      "\t \ttime: 0h 0m 23s   loss: 0.014078   mae: 0.092075   val_loss: 0.010952   val_mae: 0.080023\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013856   mae: 0.091114   val_loss: 0.010796   val_mae: 0.078945\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013732   mae: 0.090729   val_loss: 0.010591   val_mae: 0.078846\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013911   mae: 0.091578   val_loss: 0.010366   val_mae: 0.077477\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013326   mae: 0.089319   val_loss: 0.011489   val_mae: 0.081126\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013701   mae: 0.090581   val_loss: 0.010522   val_mae: 0.078389\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013844   mae: 0.091286   val_loss: 0.010592   val_mae: 0.078492\n",
      "Total:\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013728   mae: 0.090768   val_loss: 0.010726   val_mae: 0.078879\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013707   mae: 0.090304   val_loss: 0.010786   val_mae: 0.078923\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013696   mae: 0.090623   val_loss: 0.010631   val_mae: 0.078578\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013817   mae: 0.091119   val_loss: 0.011413   val_mae: 0.082449\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013395   mae: 0.089466   val_loss: 0.011537   val_mae: 0.081149\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013668   mae: 0.090246   val_loss: 0.010424   val_mae: 0.078322\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013654   mae: 0.090536   val_loss: 0.010373   val_mae: 0.077015\n",
      "Total:\n",
      "\t \ttime: 0h 0m 44s   loss: 0.013656   mae: 0.090382   val_loss: 0.010861   val_mae: 0.079406\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013634   mae: 0.090330   val_loss: 0.010652   val_mae: 0.078308\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013504   mae: 0.089834   val_loss: 0.011399   val_mae: 0.081997\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013663   mae: 0.090594   val_loss: 0.010837   val_mae: 0.079559\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013301   mae: 0.088912   val_loss: 0.011507   val_mae: 0.081401\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013576   mae: 0.090016   val_loss: 0.010475   val_mae: 0.078377\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013604   mae: 0.090455   val_loss: 0.010000   val_mae: 0.075207\n",
      "Total:\n",
      "\t \ttime: 0h 0m 57s   loss: 0.013547   mae: 0.090024   val_loss: 0.010812   val_mae: 0.079141\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013500   mae: 0.089624   val_loss: 0.010579   val_mae: 0.077530\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013471   mae: 0.089696   val_loss: 0.010662   val_mae: 0.078336\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013504   mae: 0.089981   val_loss: 0.010148   val_mae: 0.076056\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013185   mae: 0.088707   val_loss: 0.011473   val_mae: 0.081582\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013491   mae: 0.089831   val_loss: 0.010554   val_mae: 0.078589\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013637   mae: 0.090343   val_loss: 0.010112   val_mae: 0.075602\n",
      "Total:\n",
      "\t \ttime: 0h 1m 7s   loss: 0.013465   mae: 0.089697   val_loss: 0.010588   val_mae: 0.077949\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014621   mae: 0.093117   val_loss: 0.011344   val_mae: 0.081245\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014481   mae: 0.093067   val_loss: 0.011618   val_mae: 0.083409\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014483   mae: 0.093477   val_loss: 0.010492   val_mae: 0.077037\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014091   mae: 0.091828   val_loss: 0.011717   val_mae: 0.083100\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014378   mae: 0.092457   val_loss: 0.010664   val_mae: 0.078252\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014613   mae: 0.093683   val_loss: 0.010517   val_mae: 0.077683\n",
      "Total:\n",
      "\t \ttime: 0h 0m 52s   loss: 0.014445   mae: 0.092938   val_loss: 0.011058   val_mae: 0.080121\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014033   mae: 0.091563   val_loss: 0.010680   val_mae: 0.079233\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014079   mae: 0.091700   val_loss: 0.010467   val_mae: 0.077932\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014203   mae: 0.092191   val_loss: 0.010409   val_mae: 0.077124\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013849   mae: 0.090618   val_loss: 0.011519   val_mae: 0.081035\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014102   mae: 0.091785   val_loss: 0.010934   val_mae: 0.079301\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014157   mae: 0.092282   val_loss: 0.010503   val_mae: 0.077171\n",
      "Total:\n",
      "\t \ttime: 0h 1m 35s   loss: 0.014070   mae: 0.091690   val_loss: 0.010752   val_mae: 0.078633\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013888   mae: 0.090784   val_loss: 0.010804   val_mae: 0.079678\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014027   mae: 0.091635   val_loss: 0.011178   val_mae: 0.081050\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.014025   mae: 0.091782   val_loss: 0.011132   val_mae: 0.080065\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013836   mae: 0.090528   val_loss: 0.011556   val_mae: 0.081147\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.014057   mae: 0.091645   val_loss: 0.011274   val_mae: 0.081959\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014071   mae: 0.091772   val_loss: 0.010030   val_mae: 0.075127\n",
      "Total:\n",
      "\t \ttime: 0h 2m 13s   loss: 0.013984   mae: 0.091358   val_loss: 0.010996   val_mae: 0.079838\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013966   mae: 0.091250   val_loss: 0.011557   val_mae: 0.083538\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013878   mae: 0.090982   val_loss: 0.011085   val_mae: 0.080466\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.014039   mae: 0.091873   val_loss: 0.010633   val_mae: 0.077767\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013676   mae: 0.090335   val_loss: 0.011376   val_mae: 0.080801\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013876   mae: 0.090785   val_loss: 0.010335   val_mae: 0.077233\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013951   mae: 0.091493   val_loss: 0.010328   val_mae: 0.075895\n",
      "Total:\n",
      "\t \ttime: 0h 2m 55s   loss: 0.013898   mae: 0.091120   val_loss: 0.010885   val_mae: 0.079283\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013741   mae: 0.090700   val_loss: 0.010574   val_mae: 0.078504\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013723   mae: 0.090511   val_loss: 0.011818   val_mae: 0.082842\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013993   mae: 0.091357   val_loss: 0.010166   val_mae: 0.076349\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013692   mae: 0.090345   val_loss: 0.011779   val_mae: 0.082400\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013708   mae: 0.090641   val_loss: 0.010924   val_mae: 0.079869\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013894   mae: 0.091096   val_loss: 0.010148   val_mae: 0.075431\n",
      "Total:\n",
      "\t \ttime: 0h 3m 33s   loss: 0.013792   mae: 0.090775   val_loss: 0.010901   val_mae: 0.079233\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014221   mae: 0.092364   val_loss: 0.011669   val_mae: 0.084772\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014327   mae: 0.092590   val_loss: 0.010612   val_mae: 0.078902\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014429   mae: 0.092946   val_loss: 0.010661   val_mae: 0.078818\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014049   mae: 0.091700   val_loss: 0.011679   val_mae: 0.081697\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014383   mae: 0.093021   val_loss: 0.011171   val_mae: 0.082007\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014290   mae: 0.092666   val_loss: 0.010309   val_mae: 0.075846\n",
      "Total:\n",
      "\t \ttime: 0h 0m 32s   loss: 0.014283   mae: 0.092548   val_loss: 0.011017   val_mae: 0.080340\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014056   mae: 0.091593   val_loss: 0.010803   val_mae: 0.079750\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013984   mae: 0.091531   val_loss: 0.010453   val_mae: 0.077619\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014085   mae: 0.091835   val_loss: 0.011740   val_mae: 0.082465\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013863   mae: 0.091066   val_loss: 0.011741   val_mae: 0.081658\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013989   mae: 0.091650   val_loss: 0.010503   val_mae: 0.078539\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014088   mae: 0.092013   val_loss: 0.010713   val_mae: 0.078885\n",
      "Total:\n",
      "\t \ttime: 0h 0m 53s   loss: 0.014011   mae: 0.091614   val_loss: 0.010992   val_mae: 0.079819\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013827   mae: 0.090882   val_loss: 0.010740   val_mae: 0.078607\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013758   mae: 0.090370   val_loss: 0.010605   val_mae: 0.078052\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014090   mae: 0.091973   val_loss: 0.010561   val_mae: 0.078018\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013668   mae: 0.090428   val_loss: 0.011568   val_mae: 0.081753\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013916   mae: 0.091250   val_loss: 0.010342   val_mae: 0.077783\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014064   mae: 0.091929   val_loss: 0.010196   val_mae: 0.075736\n",
      "Total:\n",
      "\t \ttime: 0h 1m 15s   loss: 0.013887   mae: 0.091139   val_loss: 0.010669   val_mae: 0.078325\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013768   mae: 0.090829   val_loss: 0.010446   val_mae: 0.077620\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013789   mae: 0.090835   val_loss: 0.010575   val_mae: 0.078415\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013923   mae: 0.091409   val_loss: 0.010117   val_mae: 0.076057\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013766   mae: 0.090667   val_loss: 0.011963   val_mae: 0.083604\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013932   mae: 0.091314   val_loss: 0.010931   val_mae: 0.080500\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013923   mae: 0.091541   val_loss: 0.010548   val_mae: 0.077942\n",
      "Total:\n",
      "\t \ttime: 0h 1m 35s   loss: 0.013850   mae: 0.091099   val_loss: 0.010763   val_mae: 0.079023\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013703   mae: 0.090134   val_loss: 0.011041   val_mae: 0.080058\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013748   mae: 0.090685   val_loss: 0.010609   val_mae: 0.078433\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013825   mae: 0.091012   val_loss: 0.010129   val_mae: 0.075996\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013460   mae: 0.089570   val_loss: 0.012104   val_mae: 0.084385\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013705   mae: 0.090451   val_loss: 0.011123   val_mae: 0.080783\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013891   mae: 0.091437   val_loss: 0.010225   val_mae: 0.075587\n",
      "Total:\n",
      "\t \ttime: 0h 1m 55s   loss: 0.013722   mae: 0.090548   val_loss: 0.010872   val_mae: 0.079207\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014231   mae: 0.092160   val_loss: 0.010907   val_mae: 0.079941\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014072   mae: 0.091752   val_loss: 0.011464   val_mae: 0.081919\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014301   mae: 0.092600   val_loss: 0.011166   val_mae: 0.080866\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014023   mae: 0.091651   val_loss: 0.011566   val_mae: 0.081855\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014414   mae: 0.093037   val_loss: 0.010610   val_mae: 0.079674\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014273   mae: 0.092747   val_loss: 0.010207   val_mae: 0.076188\n",
      "Total:\n",
      "\t \ttime: 0h 0m 23s   loss: 0.014219   mae: 0.092324   val_loss: 0.010987   val_mae: 0.080074\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013874   mae: 0.090969   val_loss: 0.010669   val_mae: 0.078507\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013791   mae: 0.090907   val_loss: 0.011262   val_mae: 0.081924\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014090   mae: 0.092086   val_loss: 0.010203   val_mae: 0.076498\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013617   mae: 0.090069   val_loss: 0.011462   val_mae: 0.080781\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014004   mae: 0.091583   val_loss: 0.010491   val_mae: 0.078744\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014043   mae: 0.091892   val_loss: 0.010044   val_mae: 0.075015\n",
      "Total:\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013903   mae: 0.091251   val_loss: 0.010688   val_mae: 0.078578\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013926   mae: 0.091084   val_loss: 0.010544   val_mae: 0.078584\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013782   mae: 0.090715   val_loss: 0.010813   val_mae: 0.078775\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013886   mae: 0.091052   val_loss: 0.010048   val_mae: 0.075187\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013518   mae: 0.089620   val_loss: 0.011807   val_mae: 0.082315\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013747   mae: 0.090382   val_loss: 0.010305   val_mae: 0.077485\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013971   mae: 0.091628   val_loss: 0.010452   val_mae: 0.077930\n",
      "Total:\n",
      "\t \ttime: 0h 0m 46s   loss: 0.013805   mae: 0.090747   val_loss: 0.010662   val_mae: 0.078379\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013716   mae: 0.090524   val_loss: 0.011086   val_mae: 0.080308\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013703   mae: 0.090356   val_loss: 0.010533   val_mae: 0.078366\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013767   mae: 0.091131   val_loss: 0.010174   val_mae: 0.076153\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013456   mae: 0.089768   val_loss: 0.012970   val_mae: 0.086581\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013875   mae: 0.090811   val_loss: 0.010761   val_mae: 0.079273\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013809   mae: 0.091076   val_loss: 0.010357   val_mae: 0.077526\n",
      "Total:\n",
      "\t \ttime: 0h 0m 56s   loss: 0.013721   mae: 0.090611   val_loss: 0.010980   val_mae: 0.079701\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013813   mae: 0.090560   val_loss: 0.010578   val_mae: 0.078402\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013539   mae: 0.090090   val_loss: 0.010731   val_mae: 0.079520\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013703   mae: 0.090811   val_loss: 0.010042   val_mae: 0.075333\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013400   mae: 0.089479   val_loss: 0.011658   val_mae: 0.082828\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013654   mae: 0.090487   val_loss: 0.010908   val_mae: 0.079956\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013767   mae: 0.091063   val_loss: 0.010519   val_mae: 0.077506\n",
      "Total:\n",
      "\t \ttime: 0h 1m 7s   loss: 0.013646   mae: 0.090415   val_loss: 0.010739   val_mae: 0.078924\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.015195   mae: 0.096322   val_loss: 0.012058   val_mae: 0.085829\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.015039   mae: 0.095860   val_loss: 0.012278   val_mae: 0.086763\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.015383   mae: 0.096906   val_loss: 0.012297   val_mae: 0.085722\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.015147   mae: 0.096156   val_loss: 0.013068   val_mae: 0.089211\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014697   mae: 0.095001   val_loss: 0.011374   val_mae: 0.082716\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014970   mae: 0.095753   val_loss: 0.011557   val_mae: 0.082946\n",
      "Total:\n",
      "\t \ttime: 0h 0m 59s   loss: 0.015072   mae: 0.096000   val_loss: 0.012105   val_mae: 0.085531\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014000   mae: 0.091809   val_loss: 0.010881   val_mae: 0.080344\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013834   mae: 0.091277   val_loss: 0.010946   val_mae: 0.080771\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014080   mae: 0.092333   val_loss: 0.010713   val_mae: 0.078973\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013749   mae: 0.090845   val_loss: 0.011774   val_mae: 0.083391\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013866   mae: 0.091472   val_loss: 0.010994   val_mae: 0.080141\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014073   mae: 0.092500   val_loss: 0.010334   val_mae: 0.077475\n",
      "Total:\n",
      "\t \ttime: 0h 1m 42s   loss: 0.013934   mae: 0.091706   val_loss: 0.010940   val_mae: 0.080182\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013725   mae: 0.090723   val_loss: 0.010661   val_mae: 0.079075\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 25s   loss: 0.013737   mae: 0.090766   val_loss: 0.010688   val_mae: 0.079386\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013928   mae: 0.092215   val_loss: 0.010491   val_mae: 0.078375\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013611   mae: 0.090551   val_loss: 0.011701   val_mae: 0.083014\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013640   mae: 0.090366   val_loss: 0.010730   val_mae: 0.078966\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013899   mae: 0.091599   val_loss: 0.010260   val_mae: 0.076634\n",
      "Total:\n",
      "\t \ttime: 0h 2m 24s   loss: 0.013757   mae: 0.091037   val_loss: 0.010755   val_mae: 0.079242\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.013485   mae: 0.089804   val_loss: 0.010410   val_mae: 0.077780\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.013708   mae: 0.090862   val_loss: 0.010766   val_mae: 0.079996\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013644   mae: 0.090591   val_loss: 0.010400   val_mae: 0.077434\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013247   mae: 0.088905   val_loss: 0.011397   val_mae: 0.081215\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013604   mae: 0.090350   val_loss: 0.010493   val_mae: 0.078064\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013598   mae: 0.090518   val_loss: 0.010141   val_mae: 0.075725\n",
      "Total:\n",
      "\t \ttime: 0h 3m 8s   loss: 0.013548   mae: 0.090172   val_loss: 0.010601   val_mae: 0.078369\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013591   mae: 0.090188   val_loss: 0.010626   val_mae: 0.078563\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013512   mae: 0.089845   val_loss: 0.010691   val_mae: 0.079220\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013492   mae: 0.090142   val_loss: 0.010286   val_mae: 0.076961\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013329   mae: 0.089291   val_loss: 0.011474   val_mae: 0.081684\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013477   mae: 0.089632   val_loss: 0.010482   val_mae: 0.078345\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013643   mae: 0.090917   val_loss: 0.010008   val_mae: 0.075470\n",
      "Total:\n",
      "\t \ttime: 0h 3m 45s   loss: 0.013507   mae: 0.090003   val_loss: 0.010594   val_mae: 0.078374\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.016352   mae: 0.100081   val_loss: 0.013624   val_mae: 0.091227\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.015859   mae: 0.098350   val_loss: 0.013832   val_mae: 0.091700\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.017292   mae: 0.103751   val_loss: 0.014609   val_mae: 0.095504\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.016112   mae: 0.099126   val_loss: 0.014604   val_mae: 0.094582\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.016286   mae: 0.100120   val_loss: 0.013100   val_mae: 0.089272\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.016892   mae: 0.101813   val_loss: 0.013453   val_mae: 0.089069\n",
      "Total:\n",
      "\t \ttime: 0h 0m 38s   loss: 0.016465   mae: 0.100540   val_loss: 0.013870   val_mae: 0.091892\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014265   mae: 0.093062   val_loss: 0.011258   val_mae: 0.082108\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014327   mae: 0.093278   val_loss: 0.011854   val_mae: 0.084930\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014486   mae: 0.093890   val_loss: 0.011032   val_mae: 0.081167\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014061   mae: 0.092156   val_loss: 0.012004   val_mae: 0.084555\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014408   mae: 0.093450   val_loss: 0.011324   val_mae: 0.082349\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014504   mae: 0.093914   val_loss: 0.010814   val_mae: 0.079565\n",
      "Total:\n",
      "\t \ttime: 0h 1m 0s   loss: 0.014342   mae: 0.093292   val_loss: 0.011381   val_mae: 0.082445\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013906   mae: 0.091720   val_loss: 0.011065   val_mae: 0.081158\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013683   mae: 0.090621   val_loss: 0.010968   val_mae: 0.080619\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013904   mae: 0.091617   val_loss: 0.010597   val_mae: 0.078793\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013535   mae: 0.090154   val_loss: 0.011634   val_mae: 0.082375\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013996   mae: 0.092179   val_loss: 0.011045   val_mae: 0.081124\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013825   mae: 0.091527   val_loss: 0.010312   val_mae: 0.077206\n",
      "Total:\n",
      "\t \ttime: 0h 1m 22s   loss: 0.013808   mae: 0.091303   val_loss: 0.010937   val_mae: 0.080212\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013594   mae: 0.090337   val_loss: 0.010819   val_mae: 0.079669\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013577   mae: 0.090340   val_loss: 0.010798   val_mae: 0.079789\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013680   mae: 0.090959   val_loss: 0.010403   val_mae: 0.077983\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013401   mae: 0.089579   val_loss: 0.011463   val_mae: 0.081680\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013699   mae: 0.090793   val_loss: 0.010644   val_mae: 0.078790\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013971   mae: 0.092105   val_loss: 0.010227   val_mae: 0.077111\n",
      "Total:\n",
      "\t \ttime: 0h 1m 43s   loss: 0.013654   mae: 0.090685   val_loss: 0.010726   val_mae: 0.079170\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013603   mae: 0.090212   val_loss: 0.010656   val_mae: 0.079360\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013705   mae: 0.090938   val_loss: 0.010780   val_mae: 0.079952\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013655   mae: 0.090475   val_loss: 0.010337   val_mae: 0.077497\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013342   mae: 0.089451   val_loss: 0.011580   val_mae: 0.082156\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013469   mae: 0.089863   val_loss: 0.010441   val_mae: 0.077986\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013707   mae: 0.091304   val_loss: 0.010215   val_mae: 0.076858\n",
      "Total:\n",
      "\t \ttime: 0h 2m 5s   loss: 0.013580   mae: 0.090374   val_loss: 0.010668   val_mae: 0.078968\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.018348   mae: 0.106944   val_loss: 0.015702   val_mae: 0.099230\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.018201   mae: 0.106337   val_loss: 0.015998   val_mae: 0.099368\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.019294   mae: 0.108659   val_loss: 0.017252   val_mae: 0.101900\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.017664   mae: 0.104646   val_loss: 0.015734   val_mae: 0.099007\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.019258   mae: 0.110267   val_loss: 0.016152   val_mae: 0.100876\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.018796   mae: 0.109199   val_loss: 0.015269   val_mae: 0.096798\n",
      "Total:\n",
      "\t \ttime: 0h 0m 28s   loss: 0.018593   mae: 0.107675   val_loss: 0.016018   val_mae: 0.099530\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.015007   mae: 0.095669   val_loss: 0.012764   val_mae: 0.087860\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014743   mae: 0.094739   val_loss: 0.012360   val_mae: 0.086624\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.015180   mae: 0.096566   val_loss: 0.012390   val_mae: 0.086579\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014809   mae: 0.095098   val_loss: 0.012952   val_mae: 0.089106\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.015517   mae: 0.097633   val_loss: 0.012603   val_mae: 0.088321\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.015268   mae: 0.097067   val_loss: 0.011786   val_mae: 0.083679\n",
      "Total:\n",
      "\t \ttime: 0h 0m 39s   loss: 0.015088   mae: 0.096128   val_loss: 0.012476   val_mae: 0.087028\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014513   mae: 0.093968   val_loss: 0.011445   val_mae: 0.083325\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014433   mae: 0.093998   val_loss: 0.011595   val_mae: 0.084339\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014224   mae: 0.092952   val_loss: 0.011096   val_mae: 0.080836\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013687   mae: 0.090825   val_loss: 0.011823   val_mae: 0.083503\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014068   mae: 0.092324   val_loss: 0.011151   val_mae: 0.081624\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014591   mae: 0.094682   val_loss: 0.010902   val_mae: 0.080282\n",
      "Total:\n",
      "\t \ttime: 0h 0m 52s   loss: 0.014253   mae: 0.093125   val_loss: 0.011335   val_mae: 0.082318\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013941   mae: 0.091571   val_loss: 0.010837   val_mae: 0.080143\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013653   mae: 0.090586   val_loss: 0.010875   val_mae: 0.080543\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013924   mae: 0.091851   val_loss: 0.010552   val_mae: 0.078759\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013686   mae: 0.090928   val_loss: 0.011751   val_mae: 0.082933\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014017   mae: 0.092200   val_loss: 0.010760   val_mae: 0.080471\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014165   mae: 0.092815   val_loss: 0.010418   val_mae: 0.077997\n",
      "Total:\n",
      "\t \ttime: 0h 1m 3s   loss: 0.013898   mae: 0.091658   val_loss: 0.010866   val_mae: 0.080141\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013781   mae: 0.091205   val_loss: 0.010815   val_mae: 0.079565\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013829   mae: 0.091111   val_loss: 0.010960   val_mae: 0.080769\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013865   mae: 0.091481   val_loss: 0.010535   val_mae: 0.078588\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013604   mae: 0.090625   val_loss: 0.011860   val_mae: 0.083411\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013718   mae: 0.090919   val_loss: 0.010640   val_mae: 0.079626\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013891   mae: 0.091591   val_loss: 0.010198   val_mae: 0.076666\n",
      "Total:\n",
      "\t \ttime: 0h 1m 13s   loss: 0.013781   mae: 0.091155   val_loss: 0.010835   val_mae: 0.079771\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014220   mae: 0.092101   val_loss: 0.011310   val_mae: 0.082407\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014204   mae: 0.092173   val_loss: 0.010570   val_mae: 0.078168\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014139   mae: 0.092000   val_loss: 0.010445   val_mae: 0.077289\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013877   mae: 0.091115   val_loss: 0.011823   val_mae: 0.083715\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014087   mae: 0.091699   val_loss: 0.011170   val_mae: 0.080095\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014261   mae: 0.092638   val_loss: 0.010161   val_mae: 0.076329\n",
      "Total:\n",
      "\t \ttime: 0h 0m 59s   loss: 0.014131   mae: 0.091954   val_loss: 0.010913   val_mae: 0.079667\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013800   mae: 0.090718   val_loss: 0.010448   val_mae: 0.077827\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013815   mae: 0.090843   val_loss: 0.010961   val_mae: 0.079461\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013831   mae: 0.091106   val_loss: 0.010527   val_mae: 0.077757\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013684   mae: 0.090524   val_loss: 0.011485   val_mae: 0.080919\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013862   mae: 0.091096   val_loss: 0.010494   val_mae: 0.077846\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013896   mae: 0.091446   val_loss: 0.010306   val_mae: 0.076744\n",
      "Total:\n",
      "\t \ttime: 0h 1m 41s   loss: 0.013815   mae: 0.090955   val_loss: 0.010704   val_mae: 0.078426\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013804   mae: 0.090881   val_loss: 0.011271   val_mae: 0.081949\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013673   mae: 0.090395   val_loss: 0.010540   val_mae: 0.078372\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013740   mae: 0.090687   val_loss: 0.010042   val_mae: 0.075243\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013380   mae: 0.089360   val_loss: 0.011412   val_mae: 0.080745\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013573   mae: 0.090312   val_loss: 0.011310   val_mae: 0.080943\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013776   mae: 0.090911   val_loss: 0.010417   val_mae: 0.076714\n",
      "Total:\n",
      "\t \ttime: 0h 2m 23s   loss: 0.013658   mae: 0.090424   val_loss: 0.010832   val_mae: 0.078994\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.013565   mae: 0.089859   val_loss: 0.010514   val_mae: 0.077736\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.013516   mae: 0.089938   val_loss: 0.010920   val_mae: 0.080557\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013571   mae: 0.090299   val_loss: 0.010233   val_mae: 0.075906\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013297   mae: 0.088902   val_loss: 0.011426   val_mae: 0.080935\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013420   mae: 0.089454   val_loss: 0.010510   val_mae: 0.077838\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.013666   mae: 0.090637   val_loss: 0.010228   val_mae: 0.076343\n",
      "Total:\n",
      "\t \ttime: 0h 3m 6s   loss: 0.013506   mae: 0.089848   val_loss: 0.010639   val_mae: 0.078219\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013453   mae: 0.089462   val_loss: 0.010824   val_mae: 0.079255\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013384   mae: 0.089581   val_loss: 0.010741   val_mae: 0.078670\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013469   mae: 0.089932   val_loss: 0.010423   val_mae: 0.077034\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013188   mae: 0.088639   val_loss: 0.011323   val_mae: 0.080482\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013462   mae: 0.089630   val_loss: 0.010488   val_mae: 0.077719\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013503   mae: 0.089952   val_loss: 0.010363   val_mae: 0.076610\n",
      "Total:\n",
      "\t \ttime: 0h 3m 46s   loss: 0.013410   mae: 0.089533   val_loss: 0.010694   val_mae: 0.078295\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014067   mae: 0.091575   val_loss: 0.010786   val_mae: 0.079685\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013974   mae: 0.091543   val_loss: 0.010880   val_mae: 0.080019\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014033   mae: 0.091985   val_loss: 0.010418   val_mae: 0.077517\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013968   mae: 0.091400   val_loss: 0.012288   val_mae: 0.084496\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014027   mae: 0.091637   val_loss: 0.010625   val_mae: 0.078446\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014207   mae: 0.092369   val_loss: 0.010253   val_mae: 0.077167\n",
      "Total:\n",
      "\t \ttime: 0h 0m 38s   loss: 0.014046   mae: 0.091751   val_loss: 0.010875   val_mae: 0.079555\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013723   mae: 0.090615   val_loss: 0.010621   val_mae: 0.078899\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013815   mae: 0.090916   val_loss: 0.011827   val_mae: 0.083107\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013917   mae: 0.091565   val_loss: 0.010103   val_mae: 0.075574\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013530   mae: 0.089837   val_loss: 0.011410   val_mae: 0.080918\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013724   mae: 0.090509   val_loss: 0.010677   val_mae: 0.078994\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013952   mae: 0.091752   val_loss: 0.010139   val_mae: 0.075615\n",
      "Total:\n",
      "\t \ttime: 0h 0m 58s   loss: 0.013777   mae: 0.090866   val_loss: 0.010796   val_mae: 0.078851\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013651   mae: 0.090048   val_loss: 0.010475   val_mae: 0.077782\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013640   mae: 0.089994   val_loss: 0.010776   val_mae: 0.079389\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013786   mae: 0.090873   val_loss: 0.010320   val_mae: 0.076573\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013449   mae: 0.089392   val_loss: 0.011439   val_mae: 0.080657\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013652   mae: 0.090307   val_loss: 0.010278   val_mae: 0.077248\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013817   mae: 0.091169   val_loss: 0.010359   val_mae: 0.076589\n",
      "Total:\n",
      "\t \ttime: 0h 1m 21s   loss: 0.013666   mae: 0.090297   val_loss: 0.010608   val_mae: 0.078040\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013524   mae: 0.089936   val_loss: 0.010586   val_mae: 0.078475\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013460   mae: 0.089745   val_loss: 0.010557   val_mae: 0.077847\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013684   mae: 0.090597   val_loss: 0.010210   val_mae: 0.076365\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013333   mae: 0.089058   val_loss: 0.011296   val_mae: 0.080441\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013509   mae: 0.089927   val_loss: 0.010346   val_mae: 0.077965\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013642   mae: 0.090514   val_loss: 0.010002   val_mae: 0.075025\n",
      "Total:\n",
      "\t \ttime: 0h 1m 41s   loss: 0.013525   mae: 0.089963   val_loss: 0.010499   val_mae: 0.077686\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013502   mae: 0.089699   val_loss: 0.010632   val_mae: 0.078050\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013335   mae: 0.089259   val_loss: 0.010499   val_mae: 0.077883\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013704   mae: 0.090509   val_loss: 0.010400   val_mae: 0.077076\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013253   mae: 0.088919   val_loss: 0.011315   val_mae: 0.080793\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013416   mae: 0.089505   val_loss: 0.010483   val_mae: 0.078247\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013505   mae: 0.090006   val_loss: 0.009872   val_mae: 0.074700\n",
      "Total:\n",
      "\t \ttime: 0h 2m 4s   loss: 0.013452   mae: 0.089650   val_loss: 0.010534   val_mae: 0.077792\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.013984   mae: 0.091168   val_loss: 0.010782   val_mae: 0.079291\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014146   mae: 0.092136   val_loss: 0.010882   val_mae: 0.079885\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014053   mae: 0.091948   val_loss: 0.010871   val_mae: 0.079534\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.013823   mae: 0.091192   val_loss: 0.011933   val_mae: 0.083445\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.013990   mae: 0.091534   val_loss: 0.010800   val_mae: 0.079691\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014694   mae: 0.094155   val_loss: 0.012575   val_mae: 0.086018\n",
      "Total:\n",
      "\t \ttime: 0h 0m 27s   loss: 0.014115   mae: 0.092022   val_loss: 0.011307   val_mae: 0.081311\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013800   mae: 0.090878   val_loss: 0.010843   val_mae: 0.079344\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013662   mae: 0.090638   val_loss: 0.010823   val_mae: 0.079958\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013909   mae: 0.091200   val_loss: 0.010491   val_mae: 0.077911\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013537   mae: 0.089976   val_loss: 0.011581   val_mae: 0.081775\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013773   mae: 0.090707   val_loss: 0.010476   val_mae: 0.078401\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013794   mae: 0.091261   val_loss: 0.010666   val_mae: 0.078672\n",
      "Total:\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013746   mae: 0.090777   val_loss: 0.010813   val_mae: 0.079343\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013532   mae: 0.089918   val_loss: 0.010998   val_mae: 0.079661\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013628   mae: 0.090231   val_loss: 0.010689   val_mae: 0.078851\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013615   mae: 0.090382   val_loss: 0.010133   val_mae: 0.076036\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013254   mae: 0.088847   val_loss: 0.011325   val_mae: 0.080678\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013569   mae: 0.090129   val_loss: 0.010558   val_mae: 0.078514\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013602   mae: 0.090270   val_loss: 0.010258   val_mae: 0.076667\n",
      "Total:\n",
      "\t \ttime: 0h 0m 50s   loss: 0.013533   mae: 0.089963   val_loss: 0.010660   val_mae: 0.078401\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013680   mae: 0.090129   val_loss: 0.010877   val_mae: 0.079056\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013520   mae: 0.089896   val_loss: 0.010642   val_mae: 0.078519\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013541   mae: 0.090509   val_loss: 0.010467   val_mae: 0.076880\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013299   mae: 0.089175   val_loss: 0.011568   val_mae: 0.081597\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013507   mae: 0.089921   val_loss: 0.010346   val_mae: 0.077984\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013783   mae: 0.090890   val_loss: 0.010388   val_mae: 0.077789\n",
      "Total:\n",
      "\t \ttime: 0h 1m 4s   loss: 0.013555   mae: 0.090087   val_loss: 0.010715   val_mae: 0.078638\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013562   mae: 0.089873   val_loss: 0.010589   val_mae: 0.077733\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013521   mae: 0.089805   val_loss: 0.010406   val_mae: 0.077918\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013418   mae: 0.089676   val_loss: 0.010122   val_mae: 0.076000\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013247   mae: 0.089016   val_loss: 0.011677   val_mae: 0.081955\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013385   mae: 0.089368   val_loss: 0.010136   val_mae: 0.076670\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013525   mae: 0.090046   val_loss: 0.009967   val_mae: 0.074997\n",
      "Total:\n",
      "\t \ttime: 0h 1m 13s   loss: 0.013443   mae: 0.089631   val_loss: 0.010483   val_mae: 0.077546\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014472   mae: 0.093067   val_loss: 0.011116   val_mae: 0.081094\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014540   mae: 0.093464   val_loss: 0.011223   val_mae: 0.080525\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014496   mae: 0.093528   val_loss: 0.011270   val_mae: 0.082270\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014284   mae: 0.092688   val_loss: 0.012226   val_mae: 0.084808\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014601   mae: 0.094012   val_loss: 0.011124   val_mae: 0.080697\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014603   mae: 0.093910   val_loss: 0.011115   val_mae: 0.079805\n",
      "Total:\n",
      "\t \ttime: 0h 0m 59s   loss: 0.014499   mae: 0.093445   val_loss: 0.011346   val_mae: 0.081533\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014078   mae: 0.091708   val_loss: 0.011478   val_mae: 0.082228\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014206   mae: 0.092335   val_loss: 0.011518   val_mae: 0.081988\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014227   mae: 0.092448   val_loss: 0.010947   val_mae: 0.079374\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013901   mae: 0.090962   val_loss: 0.011533   val_mae: 0.081734\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014162   mae: 0.091965   val_loss: 0.010758   val_mae: 0.079264\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014142   mae: 0.092321   val_loss: 0.011453   val_mae: 0.082183\n",
      "Total:\n",
      "\t \ttime: 0h 1m 41s   loss: 0.014119   mae: 0.091956   val_loss: 0.011281   val_mae: 0.081129\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.014041   mae: 0.091437   val_loss: 0.010532   val_mae: 0.078033\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013957   mae: 0.091242   val_loss: 0.011563   val_mae: 0.084484\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013941   mae: 0.091677   val_loss: 0.010634   val_mae: 0.079271\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013824   mae: 0.090875   val_loss: 0.011495   val_mae: 0.080879\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 25s   loss: 0.014028   mae: 0.091745   val_loss: 0.011190   val_mae: 0.080863\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.014007   mae: 0.091694   val_loss: 0.010134   val_mae: 0.075072\n",
      "Total:\n",
      "\t \ttime: 0h 2m 22s   loss: 0.013966   mae: 0.091445   val_loss: 0.010925   val_mae: 0.079767\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013836   mae: 0.090868   val_loss: 0.010483   val_mae: 0.077604\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013842   mae: 0.090761   val_loss: 0.011237   val_mae: 0.080726\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013908   mae: 0.091362   val_loss: 0.010102   val_mae: 0.075466\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013703   mae: 0.090487   val_loss: 0.011287   val_mae: 0.080562\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013967   mae: 0.091483   val_loss: 0.010777   val_mae: 0.078871\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013944   mae: 0.091605   val_loss: 0.010619   val_mae: 0.077175\n",
      "Total:\n",
      "\t \ttime: 0h 3m 6s   loss: 0.013866   mae: 0.091094   val_loss: 0.010751   val_mae: 0.078401\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013840   mae: 0.090759   val_loss: 0.010365   val_mae: 0.077665\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013866   mae: 0.090978   val_loss: 0.010510   val_mae: 0.078640\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013838   mae: 0.091036   val_loss: 0.010474   val_mae: 0.077435\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013559   mae: 0.089918   val_loss: 0.012015   val_mae: 0.084067\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013882   mae: 0.091288   val_loss: 0.011455   val_mae: 0.081911\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013910   mae: 0.091365   val_loss: 0.010647   val_mae: 0.078665\n",
      "Total:\n",
      "\t \ttime: 0h 3m 45s   loss: 0.013816   mae: 0.090891   val_loss: 0.010911   val_mae: 0.079730\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014274   mae: 0.092150   val_loss: 0.010855   val_mae: 0.079740\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014202   mae: 0.092475   val_loss: 0.011183   val_mae: 0.080623\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014341   mae: 0.092848   val_loss: 0.010835   val_mae: 0.079990\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014202   mae: 0.092206   val_loss: 0.012326   val_mae: 0.083885\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014441   mae: 0.093176   val_loss: 0.010981   val_mae: 0.080236\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014394   mae: 0.092946   val_loss: 0.011295   val_mae: 0.081257\n",
      "Total:\n",
      "\t \ttime: 0h 0m 36s   loss: 0.014309   mae: 0.092633   val_loss: 0.011246   val_mae: 0.080955\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013968   mae: 0.091271   val_loss: 0.010583   val_mae: 0.078057\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013981   mae: 0.091604   val_loss: 0.010760   val_mae: 0.078880\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014081   mae: 0.091952   val_loss: 0.010257   val_mae: 0.076618\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013750   mae: 0.090677   val_loss: 0.011926   val_mae: 0.082331\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013963   mae: 0.091411   val_loss: 0.010475   val_mae: 0.078345\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014205   mae: 0.092241   val_loss: 0.010345   val_mae: 0.076121\n",
      "Total:\n",
      "\t \ttime: 0h 0m 59s   loss: 0.013991   mae: 0.091526   val_loss: 0.010724   val_mae: 0.078392\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013926   mae: 0.091136   val_loss: 0.010486   val_mae: 0.077933\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013934   mae: 0.091440   val_loss: 0.010840   val_mae: 0.079116\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.014084   mae: 0.092043   val_loss: 0.010549   val_mae: 0.077845\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013634   mae: 0.090179   val_loss: 0.011729   val_mae: 0.082944\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013816   mae: 0.090817   val_loss: 0.010957   val_mae: 0.080925\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013994   mae: 0.091734   val_loss: 0.010541   val_mae: 0.077286\n",
      "Total:\n",
      "\t \ttime: 0h 1m 19s   loss: 0.013898   mae: 0.091225   val_loss: 0.010850   val_mae: 0.079341\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013925   mae: 0.091223   val_loss: 0.010907   val_mae: 0.079923\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013762   mae: 0.090570   val_loss: 0.010874   val_mae: 0.078873\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013812   mae: 0.091243   val_loss: 0.010293   val_mae: 0.076594\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013575   mae: 0.090208   val_loss: 0.012070   val_mae: 0.083398\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013745   mae: 0.090658   val_loss: 0.010443   val_mae: 0.077551\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013851   mae: 0.091128   val_loss: 0.010082   val_mae: 0.075324\n",
      "Total:\n",
      "\t \ttime: 0h 1m 42s   loss: 0.013778   mae: 0.090838   val_loss: 0.010778   val_mae: 0.078610\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013725   mae: 0.090318   val_loss: 0.011211   val_mae: 0.081254\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013766   mae: 0.090755   val_loss: 0.010530   val_mae: 0.078923\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013824   mae: 0.091101   val_loss: 0.010556   val_mae: 0.078551\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013471   mae: 0.089488   val_loss: 0.011404   val_mae: 0.080906\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013697   mae: 0.090398   val_loss: 0.010719   val_mae: 0.078792\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013842   mae: 0.091264   val_loss: 0.010014   val_mae: 0.075438\n",
      "Total:\n",
      "\t \ttime: 0h 2m 4s   loss: 0.013721   mae: 0.090554   val_loss: 0.010739   val_mae: 0.078977\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014106   mae: 0.091723   val_loss: 0.011119   val_mae: 0.079551\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013996   mae: 0.091718   val_loss: 0.011348   val_mae: 0.081086\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014251   mae: 0.092815   val_loss: 0.010384   val_mae: 0.077289\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.013943   mae: 0.091313   val_loss: 0.011878   val_mae: 0.083287\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014234   mae: 0.092224   val_loss: 0.010579   val_mae: 0.079471\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014422   mae: 0.093303   val_loss: 0.010093   val_mae: 0.075619\n",
      "Total:\n",
      "\t \ttime: 0h 0m 28s   loss: 0.014159   mae: 0.092183   val_loss: 0.010900   val_mae: 0.079384\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013744   mae: 0.090543   val_loss: 0.011005   val_mae: 0.080938\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013928   mae: 0.091344   val_loss: 0.010474   val_mae: 0.078336\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013912   mae: 0.091235   val_loss: 0.010570   val_mae: 0.077880\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013802   mae: 0.090819   val_loss: 0.011649   val_mae: 0.081972\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013991   mae: 0.091405   val_loss: 0.010553   val_mae: 0.078584\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014012   mae: 0.091991   val_loss: 0.010496   val_mae: 0.077712\n",
      "Total:\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013898   mae: 0.091223   val_loss: 0.010791   val_mae: 0.079237\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013879   mae: 0.091087   val_loss: 0.010771   val_mae: 0.079191\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013968   mae: 0.091671   val_loss: 0.010800   val_mae: 0.078791\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013928   mae: 0.091508   val_loss: 0.010170   val_mae: 0.075169\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013547   mae: 0.090125   val_loss: 0.012387   val_mae: 0.085682\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013807   mae: 0.090926   val_loss: 0.010500   val_mae: 0.079118\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013821   mae: 0.091034   val_loss: 0.010030   val_mae: 0.074948\n",
      "Total:\n",
      "\t \ttime: 0h 0m 50s   loss: 0.013825   mae: 0.091058   val_loss: 0.010776   val_mae: 0.078817\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013691   mae: 0.090392   val_loss: 0.010789   val_mae: 0.078612\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013679   mae: 0.090399   val_loss: 0.010338   val_mae: 0.077756\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013858   mae: 0.091232   val_loss: 0.010340   val_mae: 0.076764\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013404   mae: 0.089288   val_loss: 0.011460   val_mae: 0.080840\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013752   mae: 0.090737   val_loss: 0.010355   val_mae: 0.077791\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013641   mae: 0.090625   val_loss: 0.010381   val_mae: 0.076841\n",
      "Total:\n",
      "\t \ttime: 0h 1m 2s   loss: 0.013671   mae: 0.090445   val_loss: 0.010610   val_mae: 0.078101\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013573   mae: 0.090071   val_loss: 0.010817   val_mae: 0.079753\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013597   mae: 0.090205   val_loss: 0.010541   val_mae: 0.078899\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013755   mae: 0.090859   val_loss: 0.010646   val_mae: 0.078682\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013461   mae: 0.089639   val_loss: 0.012167   val_mae: 0.084777\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013603   mae: 0.089951   val_loss: 0.010433   val_mae: 0.078631\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013847   mae: 0.091281   val_loss: 0.010288   val_mae: 0.075924\n",
      "Total:\n",
      "\t \ttime: 0h 1m 13s   loss: 0.013639   mae: 0.090334   val_loss: 0.010815   val_mae: 0.079444\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014851   mae: 0.095639   val_loss: 0.011644   val_mae: 0.084280\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.015183   mae: 0.096289   val_loss: 0.013075   val_mae: 0.089278\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.015175   mae: 0.096323   val_loss: 0.012120   val_mae: 0.085464\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014403   mae: 0.093480   val_loss: 0.012353   val_mae: 0.086098\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014706   mae: 0.094361   val_loss: 0.011363   val_mae: 0.081836\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.015455   mae: 0.097565   val_loss: 0.011848   val_mae: 0.083369\n",
      "Total:\n",
      "\t \ttime: 0h 1m 4s   loss: 0.014962   mae: 0.095609   val_loss: 0.012067   val_mae: 0.085054\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013834   mae: 0.091340   val_loss: 0.010732   val_mae: 0.079756\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014198   mae: 0.092718   val_loss: 0.011432   val_mae: 0.082754\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013965   mae: 0.091981   val_loss: 0.010506   val_mae: 0.078274\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013649   mae: 0.090505   val_loss: 0.011597   val_mae: 0.082430\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013970   mae: 0.091879   val_loss: 0.011035   val_mae: 0.080730\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.014224   mae: 0.093078   val_loss: 0.010449   val_mae: 0.077876\n",
      "Total:\n",
      "\t \ttime: 0h 1m 47s   loss: 0.013973   mae: 0.091917   val_loss: 0.010959   val_mae: 0.080303\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 25s   loss: 0.013627   mae: 0.090480   val_loss: 0.010591   val_mae: 0.078633\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013575   mae: 0.090000   val_loss: 0.010779   val_mae: 0.079483\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013692   mae: 0.090897   val_loss: 0.010334   val_mae: 0.077247\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013413   mae: 0.089627   val_loss: 0.011485   val_mae: 0.081607\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 25s   loss: 0.013668   mae: 0.090576   val_loss: 0.010727   val_mae: 0.079318\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 25s   loss: 0.013842   mae: 0.091572   val_loss: 0.010064   val_mae: 0.076136\n",
      "Total:\n",
      "\t \ttime: 0h 2m 31s   loss: 0.013636   mae: 0.090525   val_loss: 0.010663   val_mae: 0.078737\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 33s   loss: 0.013405   mae: 0.089107   val_loss: 0.010418   val_mae: 0.078039\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013676   mae: 0.090769   val_loss: 0.010692   val_mae: 0.079427\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013546   mae: 0.090270   val_loss: 0.010319   val_mae: 0.076537\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013223   mae: 0.089043   val_loss: 0.011597   val_mae: 0.081722\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 33s   loss: 0.013623   mae: 0.090439   val_loss: 0.010644   val_mae: 0.078952\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013634   mae: 0.090490   val_loss: 0.009931   val_mae: 0.075405\n",
      "Total:\n",
      "\t \ttime: 0h 3m 16s   loss: 0.013518   mae: 0.090020   val_loss: 0.010600   val_mae: 0.078347\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 40s   loss: 0.013525   mae: 0.089884   val_loss: 0.010464   val_mae: 0.078026\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013454   mae: 0.089593   val_loss: 0.010783   val_mae: 0.079415\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013559   mae: 0.090382   val_loss: 0.010292   val_mae: 0.076668\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013282   mae: 0.089073   val_loss: 0.011529   val_mae: 0.081754\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 41s   loss: 0.013429   mae: 0.089576   val_loss: 0.010424   val_mae: 0.077837\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013555   mae: 0.090245   val_loss: 0.009851   val_mae: 0.074668\n",
      "Total:\n",
      "\t \ttime: 0h 3m 57s   loss: 0.013467   mae: 0.089792   val_loss: 0.010557   val_mae: 0.078061\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.015855   mae: 0.098429   val_loss: 0.012548   val_mae: 0.087420\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.015882   mae: 0.098571   val_loss: 0.013934   val_mae: 0.092141\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.016014   mae: 0.099263   val_loss: 0.012558   val_mae: 0.086971\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.015585   mae: 0.097499   val_loss: 0.013466   val_mae: 0.091064\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.016584   mae: 0.101064   val_loss: 0.013766   val_mae: 0.092087\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.016083   mae: 0.098764   val_loss: 0.012727   val_mae: 0.085951\n",
      "Total:\n",
      "\t \ttime: 0h 0m 44s   loss: 0.016001   mae: 0.098932   val_loss: 0.013166   val_mae: 0.089272\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014087   mae: 0.092519   val_loss: 0.010987   val_mae: 0.080895\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014362   mae: 0.093441   val_loss: 0.011738   val_mae: 0.083916\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014489   mae: 0.094061   val_loss: 0.011338   val_mae: 0.082445\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013826   mae: 0.091149   val_loss: 0.011992   val_mae: 0.084011\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014260   mae: 0.093034   val_loss: 0.011142   val_mae: 0.081390\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014632   mae: 0.094603   val_loss: 0.011327   val_mae: 0.081597\n",
      "Total:\n",
      "\t \ttime: 0h 1m 10s   loss: 0.014276   mae: 0.093135   val_loss: 0.011421   val_mae: 0.082375\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013825   mae: 0.091260   val_loss: 0.011112   val_mae: 0.080769\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013618   mae: 0.090442   val_loss: 0.010683   val_mae: 0.079623\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.014103   mae: 0.092796   val_loss: 0.010791   val_mae: 0.080201\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013538   mae: 0.090196   val_loss: 0.011586   val_mae: 0.082260\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013836   mae: 0.091207   val_loss: 0.010701   val_mae: 0.079446\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013830   mae: 0.091364   val_loss: 0.010207   val_mae: 0.076537\n",
      "Total:\n",
      "\t \ttime: 0h 1m 30s   loss: 0.013792   mae: 0.091211   val_loss: 0.010846   val_mae: 0.079806\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013507   mae: 0.089676   val_loss: 0.010564   val_mae: 0.078428\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013577   mae: 0.090319   val_loss: 0.010610   val_mae: 0.078966\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013664   mae: 0.090797   val_loss: 0.010243   val_mae: 0.076650\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013270   mae: 0.089158   val_loss: 0.011591   val_mae: 0.081758\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013609   mae: 0.090189   val_loss: 0.010415   val_mae: 0.078092\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013658   mae: 0.090593   val_loss: 0.009997   val_mae: 0.075378\n",
      "Total:\n",
      "\t \ttime: 0h 1m 51s   loss: 0.013547   mae: 0.090122   val_loss: 0.010570   val_mae: 0.078212\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013486   mae: 0.089954   val_loss: 0.010574   val_mae: 0.078184\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013503   mae: 0.089876   val_loss: 0.010586   val_mae: 0.079029\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013549   mae: 0.090327   val_loss: 0.010278   val_mae: 0.076485\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013212   mae: 0.088912   val_loss: 0.011650   val_mae: 0.081694\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013783   mae: 0.091248   val_loss: 0.010742   val_mae: 0.079397\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013577   mae: 0.090207   val_loss: 0.009935   val_mae: 0.074928\n",
      "Total:\n",
      "\t \ttime: 0h 2m 13s   loss: 0.013518   mae: 0.090087   val_loss: 0.010628   val_mae: 0.078286\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.018040   mae: 0.105313   val_loss: 0.014738   val_mae: 0.095544\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.018022   mae: 0.105478   val_loss: 0.015925   val_mae: 0.098797\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.023254   mae: 0.123292   val_loss: 0.020391   val_mae: 0.115806\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.017213   mae: 0.103132   val_loss: 0.015449   val_mae: 0.097146\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.018908   mae: 0.109236   val_loss: 0.015339   val_mae: 0.097682\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.016969   mae: 0.102936   val_loss: 0.013359   val_mae: 0.089161\n",
      "Total:\n",
      "\t \ttime: 0h 0m 34s   loss: 0.018734   mae: 0.108231   val_loss: 0.015867   val_mae: 0.099023\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014976   mae: 0.095351   val_loss: 0.012281   val_mae: 0.086051\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.015285   mae: 0.096373   val_loss: 0.013150   val_mae: 0.089745\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.015264   mae: 0.096405   val_loss: 0.011956   val_mae: 0.084899\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.015039   mae: 0.095411   val_loss: 0.013547   val_mae: 0.090439\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014982   mae: 0.095724   val_loss: 0.011776   val_mae: 0.084303\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.015331   mae: 0.096953   val_loss: 0.011961   val_mae: 0.083377\n",
      "Total:\n",
      "\t \ttime: 0h 0m 46s   loss: 0.015146   mae: 0.096036   val_loss: 0.012445   val_mae: 0.086469\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014048   mae: 0.092224   val_loss: 0.010947   val_mae: 0.080758\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014043   mae: 0.092350   val_loss: 0.011276   val_mae: 0.082856\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014329   mae: 0.093260   val_loss: 0.010943   val_mae: 0.080897\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013773   mae: 0.091253   val_loss: 0.011883   val_mae: 0.083667\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013831   mae: 0.091357   val_loss: 0.010975   val_mae: 0.080786\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014493   mae: 0.094128   val_loss: 0.010716   val_mae: 0.079566\n",
      "Total:\n",
      "\t \ttime: 0h 0m 58s   loss: 0.014086   mae: 0.092429   val_loss: 0.011123   val_mae: 0.081422\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013745   mae: 0.090947   val_loss: 0.010834   val_mae: 0.079613\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013690   mae: 0.090729   val_loss: 0.010884   val_mae: 0.080350\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013915   mae: 0.091929   val_loss: 0.010534   val_mae: 0.078590\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013645   mae: 0.090528   val_loss: 0.011717   val_mae: 0.082657\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014033   mae: 0.092238   val_loss: 0.010885   val_mae: 0.080741\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013892   mae: 0.091709   val_loss: 0.010317   val_mae: 0.077266\n",
      "Total:\n",
      "\t \ttime: 0h 1m 10s   loss: 0.013820   mae: 0.091347   val_loss: 0.010862   val_mae: 0.079870\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013543   mae: 0.089991   val_loss: 0.010635   val_mae: 0.078440\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013807   mae: 0.091228   val_loss: 0.011045   val_mae: 0.081075\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013895   mae: 0.091780   val_loss: 0.010664   val_mae: 0.079455\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013458   mae: 0.089895   val_loss: 0.011545   val_mae: 0.081939\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013611   mae: 0.090672   val_loss: 0.010471   val_mae: 0.078734\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013790   mae: 0.091266   val_loss: 0.010024   val_mae: 0.075799\n",
      "Total:\n",
      "\t \ttime: 0h 1m 22s   loss: 0.013684   mae: 0.090805   val_loss: 0.010731   val_mae: 0.079240\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014139   mae: 0.091659   val_loss: 0.011944   val_mae: 0.084079\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014124   mae: 0.092187   val_loss: 0.011208   val_mae: 0.080338\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014198   mae: 0.092510   val_loss: 0.011374   val_mae: 0.081898\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013901   mae: 0.091429   val_loss: 0.011679   val_mae: 0.081901\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014229   mae: 0.092528   val_loss: 0.011537   val_mae: 0.081372\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014408   mae: 0.092929   val_loss: 0.010941   val_mae: 0.079441\n",
      "Total:\n",
      "\t \ttime: 0h 1m 4s   loss: 0.014166   mae: 0.092207   val_loss: 0.011447   val_mae: 0.081505\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013796   mae: 0.090574   val_loss: 0.010397   val_mae: 0.077753\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013811   mae: 0.090909   val_loss: 0.010912   val_mae: 0.080184\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013866   mae: 0.091289   val_loss: 0.010428   val_mae: 0.077143\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013502   mae: 0.089912   val_loss: 0.011635   val_mae: 0.082074\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013869   mae: 0.091161   val_loss: 0.010854   val_mae: 0.079662\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013922   mae: 0.091629   val_loss: 0.009945   val_mae: 0.074949\n",
      "Total:\n",
      "\t \ttime: 0h 1m 48s   loss: 0.013794   mae: 0.090912   val_loss: 0.010695   val_mae: 0.078628\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013551   mae: 0.089847   val_loss: 0.010712   val_mae: 0.078078\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 27s   loss: 0.013511   mae: 0.090112   val_loss: 0.011550   val_mae: 0.082107\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 25s   loss: 0.013725   mae: 0.090843   val_loss: 0.010126   val_mae: 0.075692\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013458   mae: 0.089650   val_loss: 0.011493   val_mae: 0.081634\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013636   mae: 0.090313   val_loss: 0.010437   val_mae: 0.077439\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013626   mae: 0.090415   val_loss: 0.010326   val_mae: 0.076699\n",
      "Total:\n",
      "\t \ttime: 0h 2m 31s   loss: 0.013584   mae: 0.090197   val_loss: 0.010774   val_mae: 0.078608\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013567   mae: 0.089975   val_loss: 0.010880   val_mae: 0.079616\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013492   mae: 0.089757   val_loss: 0.011150   val_mae: 0.081337\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 33s   loss: 0.013649   mae: 0.090403   val_loss: 0.010682   val_mae: 0.077803\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013200   mae: 0.088823   val_loss: 0.011360   val_mae: 0.080863\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013513   mae: 0.089840   val_loss: 0.010596   val_mae: 0.078111\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013754   mae: 0.090850   val_loss: 0.010071   val_mae: 0.075622\n",
      "Total:\n",
      "\t \ttime: 0h 3m 17s   loss: 0.013529   mae: 0.089941   val_loss: 0.010790   val_mae: 0.078892\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 40s   loss: 0.013440   mae: 0.089544   val_loss: 0.011309   val_mae: 0.081021\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013417   mae: 0.089540   val_loss: 0.010669   val_mae: 0.079163\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013476   mae: 0.089920   val_loss: 0.010479   val_mae: 0.077158\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 40s   loss: 0.013191   mae: 0.088796   val_loss: 0.011395   val_mae: 0.080794\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013385   mae: 0.089520   val_loss: 0.010415   val_mae: 0.077560\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013470   mae: 0.089961   val_loss: 0.010151   val_mae: 0.075738\n",
      "Total:\n",
      "\t \ttime: 0h 3m 56s   loss: 0.013396   mae: 0.089547   val_loss: 0.010736   val_mae: 0.078572\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014122   mae: 0.091891   val_loss: 0.010733   val_mae: 0.078268\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014188   mae: 0.092147   val_loss: 0.011160   val_mae: 0.080768\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014184   mae: 0.092430   val_loss: 0.010437   val_mae: 0.077014\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013967   mae: 0.091548   val_loss: 0.012019   val_mae: 0.083758\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014021   mae: 0.091760   val_loss: 0.011406   val_mae: 0.081671\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014230   mae: 0.092539   val_loss: 0.010217   val_mae: 0.075751\n",
      "Total:\n",
      "\t \ttime: 0h 0m 44s   loss: 0.014119   mae: 0.092052   val_loss: 0.010995   val_mae: 0.079538\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013740   mae: 0.090498   val_loss: 0.010592   val_mae: 0.078424\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013787   mae: 0.091067   val_loss: 0.010634   val_mae: 0.078873\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013859   mae: 0.091280   val_loss: 0.010127   val_mae: 0.075775\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013554   mae: 0.089893   val_loss: 0.011640   val_mae: 0.082055\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013793   mae: 0.090891   val_loss: 0.010646   val_mae: 0.078608\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013947   mae: 0.091635   val_loss: 0.010046   val_mae: 0.076030\n",
      "Total:\n",
      "\t \ttime: 0h 1m 6s   loss: 0.013780   mae: 0.090877   val_loss: 0.010614   val_mae: 0.078294\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013590   mae: 0.089976   val_loss: 0.011050   val_mae: 0.079912\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013658   mae: 0.090375   val_loss: 0.010483   val_mae: 0.078606\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013699   mae: 0.090653   val_loss: 0.010191   val_mae: 0.075986\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013417   mae: 0.089216   val_loss: 0.011359   val_mae: 0.080130\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013630   mae: 0.090298   val_loss: 0.010486   val_mae: 0.078064\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013840   mae: 0.091317   val_loss: 0.009968   val_mae: 0.075430\n",
      "Total:\n",
      "\t \ttime: 0h 1m 29s   loss: 0.013639   mae: 0.090306   val_loss: 0.010589   val_mae: 0.078021\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013468   mae: 0.089709   val_loss: 0.010564   val_mae: 0.079070\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013588   mae: 0.090141   val_loss: 0.010513   val_mae: 0.078292\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013584   mae: 0.090256   val_loss: 0.010026   val_mae: 0.075754\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013276   mae: 0.089003   val_loss: 0.011796   val_mae: 0.082779\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013523   mae: 0.089976   val_loss: 0.010469   val_mae: 0.077867\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013636   mae: 0.090394   val_loss: 0.010844   val_mae: 0.078950\n",
      "Total:\n",
      "\t \ttime: 0h 1m 51s   loss: 0.013512   mae: 0.089913   val_loss: 0.010702   val_mae: 0.078785\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013564   mae: 0.089872   val_loss: 0.010506   val_mae: 0.078010\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013314   mae: 0.089183   val_loss: 0.010458   val_mae: 0.078187\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013477   mae: 0.089913   val_loss: 0.010176   val_mae: 0.075722\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013163   mae: 0.088703   val_loss: 0.011589   val_mae: 0.081682\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013478   mae: 0.089695   val_loss: 0.010757   val_mae: 0.078821\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013518   mae: 0.090040   val_loss: 0.010168   val_mae: 0.076073\n",
      "Total:\n",
      "\t \ttime: 0h 2m 15s   loss: 0.013419   mae: 0.089568   val_loss: 0.010609   val_mae: 0.078083\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014139   mae: 0.091995   val_loss: 0.010655   val_mae: 0.078101\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014204   mae: 0.092433   val_loss: 0.010892   val_mae: 0.080431\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014057   mae: 0.091814   val_loss: 0.010351   val_mae: 0.077349\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013837   mae: 0.091169   val_loss: 0.011575   val_mae: 0.081469\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014078   mae: 0.091940   val_loss: 0.010776   val_mae: 0.079660\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014192   mae: 0.092636   val_loss: 0.010228   val_mae: 0.075925\n",
      "Total:\n",
      "\t \ttime: 0h 0m 34s   loss: 0.014085   mae: 0.091998   val_loss: 0.010746   val_mae: 0.078822\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013694   mae: 0.090602   val_loss: 0.010717   val_mae: 0.078609\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013648   mae: 0.090337   val_loss: 0.010668   val_mae: 0.078830\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013760   mae: 0.090850   val_loss: 0.010157   val_mae: 0.076380\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013567   mae: 0.090177   val_loss: 0.011682   val_mae: 0.081977\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013834   mae: 0.090933   val_loss: 0.010282   val_mae: 0.077505\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013896   mae: 0.091371   val_loss: 0.010414   val_mae: 0.077628\n",
      "Total:\n",
      "\t \ttime: 0h 0m 46s   loss: 0.013733   mae: 0.090712   val_loss: 0.010653   val_mae: 0.078488\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013513   mae: 0.089884   val_loss: 0.011112   val_mae: 0.080352\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013550   mae: 0.090069   val_loss: 0.010447   val_mae: 0.078280\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013813   mae: 0.090983   val_loss: 0.010250   val_mae: 0.076280\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013289   mae: 0.089069   val_loss: 0.011861   val_mae: 0.082558\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013534   mae: 0.089779   val_loss: 0.010813   val_mae: 0.079779\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013588   mae: 0.090431   val_loss: 0.009969   val_mae: 0.074903\n",
      "Total:\n",
      "\t \ttime: 0h 0m 57s   loss: 0.013548   mae: 0.090036   val_loss: 0.010742   val_mae: 0.078692\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013517   mae: 0.089927   val_loss: 0.010551   val_mae: 0.077743\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013599   mae: 0.090005   val_loss: 0.010918   val_mae: 0.079526\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013549   mae: 0.090273   val_loss: 0.010119   val_mae: 0.075537\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013274   mae: 0.088858   val_loss: 0.011429   val_mae: 0.081128\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013629   mae: 0.090262   val_loss: 0.010233   val_mae: 0.077590\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013600   mae: 0.090317   val_loss: 0.011770   val_mae: 0.082365\n",
      "Total:\n",
      "\t \ttime: 0h 1m 11s   loss: 0.013528   mae: 0.089940   val_loss: 0.010837   val_mae: 0.078981\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013522   mae: 0.090058   val_loss: 0.010922   val_mae: 0.079556\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013486   mae: 0.089700   val_loss: 0.010367   val_mae: 0.077950\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013418   mae: 0.089814   val_loss: 0.010103   val_mae: 0.075991\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013191   mae: 0.088669   val_loss: 0.011364   val_mae: 0.080434\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013368   mae: 0.089381   val_loss: 0.010498   val_mae: 0.077923\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013482   mae: 0.090039   val_loss: 0.010128   val_mae: 0.075395\n",
      "Total:\n",
      "\t \ttime: 0h 1m 22s   loss: 0.013411   mae: 0.089610   val_loss: 0.010564   val_mae: 0.077875\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014337   mae: 0.092550   val_loss: 0.010898   val_mae: 0.080984\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014591   mae: 0.093542   val_loss: 0.012711   val_mae: 0.087399\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014393   mae: 0.093132   val_loss: 0.011767   val_mae: 0.082657\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014204   mae: 0.092354   val_loss: 0.012456   val_mae: 0.085028\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014482   mae: 0.093310   val_loss: 0.010783   val_mae: 0.078958\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014551   mae: 0.093864   val_loss: 0.011045   val_mae: 0.081382\n",
      "Total:\n",
      "\t \ttime: 0h 1m 3s   loss: 0.014426   mae: 0.093125   val_loss: 0.011610   val_mae: 0.082735\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.014244   mae: 0.092454   val_loss: 0.011303   val_mae: 0.082091\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014161   mae: 0.092127   val_loss: 0.011264   val_mae: 0.082039\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.014225   mae: 0.092528   val_loss: 0.010700   val_mae: 0.078227\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013976   mae: 0.091280   val_loss: 0.011855   val_mae: 0.082361\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014135   mae: 0.092022   val_loss: 0.010613   val_mae: 0.079076\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014204   mae: 0.092445   val_loss: 0.010209   val_mae: 0.075485\n",
      "Total:\n",
      "\t \ttime: 0h 1m 47s   loss: 0.014157   mae: 0.092143   val_loss: 0.010991   val_mae: 0.079880\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 25s   loss: 0.014121   mae: 0.091682   val_loss: 0.010867   val_mae: 0.079678\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 25s   loss: 0.013969   mae: 0.091441   val_loss: 0.011103   val_mae: 0.081269\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 25s   loss: 0.014169   mae: 0.092192   val_loss: 0.010923   val_mae: 0.078945\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013828   mae: 0.090963   val_loss: 0.011913   val_mae: 0.083562\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014060   mae: 0.091803   val_loss: 0.010623   val_mae: 0.078346\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014220   mae: 0.092143   val_loss: 0.010460   val_mae: 0.077248\n",
      "Total:\n",
      "\t \ttime: 0h 2m 30s   loss: 0.014061   mae: 0.091704   val_loss: 0.010981   val_mae: 0.079841\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.014052   mae: 0.091563   val_loss: 0.011147   val_mae: 0.082383\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013852   mae: 0.090958   val_loss: 0.010494   val_mae: 0.078051\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 33s   loss: 0.014034   mae: 0.091651   val_loss: 0.010398   val_mae: 0.076700\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013661   mae: 0.090327   val_loss: 0.011862   val_mae: 0.082240\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013986   mae: 0.091596   val_loss: 0.010921   val_mae: 0.079781\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 33s   loss: 0.013988   mae: 0.091665   val_loss: 0.009862   val_mae: 0.075029\n",
      "Total:\n",
      "\t \ttime: 0h 3m 15s   loss: 0.013929   mae: 0.091293   val_loss: 0.010781   val_mae: 0.079031\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013880   mae: 0.090995   val_loss: 0.010770   val_mae: 0.078957\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013830   mae: 0.091118   val_loss: 0.010458   val_mae: 0.078015\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 41s   loss: 0.014245   mae: 0.092622   val_loss: 0.010102   val_mae: 0.075041\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 41s   loss: 0.013592   mae: 0.090344   val_loss: 0.011995   val_mae: 0.083453\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013896   mae: 0.091306   val_loss: 0.010529   val_mae: 0.077968\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013994   mae: 0.091545   val_loss: 0.010536   val_mae: 0.078333\n",
      "Total:\n",
      "\t \ttime: 0h 4m 0s   loss: 0.013906   mae: 0.091321   val_loss: 0.010732   val_mae: 0.078628\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014383   mae: 0.093043   val_loss: 0.010914   val_mae: 0.079843\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014294   mae: 0.092558   val_loss: 0.011400   val_mae: 0.082189\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014402   mae: 0.093236   val_loss: 0.010595   val_mae: 0.078446\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014014   mae: 0.091682   val_loss: 0.012045   val_mae: 0.084546\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014443   mae: 0.093225   val_loss: 0.011988   val_mae: 0.084196\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014418   mae: 0.093315   val_loss: 0.011678   val_mae: 0.082984\n",
      "Total:\n",
      "\t \ttime: 0h 0m 43s   loss: 0.014326   mae: 0.092843   val_loss: 0.011437   val_mae: 0.082034\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013972   mae: 0.091108   val_loss: 0.011121   val_mae: 0.080679\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013994   mae: 0.091434   val_loss: 0.010795   val_mae: 0.078790\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014122   mae: 0.092317   val_loss: 0.011251   val_mae: 0.080612\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013828   mae: 0.091064   val_loss: 0.011842   val_mae: 0.082788\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013970   mae: 0.091262   val_loss: 0.010631   val_mae: 0.078683\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014252   mae: 0.092609   val_loss: 0.010946   val_mae: 0.080454\n",
      "Total:\n",
      "\t \ttime: 0h 1m 6s   loss: 0.014023   mae: 0.091632   val_loss: 0.011098   val_mae: 0.080334\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013824   mae: 0.090965   val_loss: 0.011278   val_mae: 0.080478\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013949   mae: 0.091391   val_loss: 0.010601   val_mae: 0.078644\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013944   mae: 0.091482   val_loss: 0.010513   val_mae: 0.077355\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013619   mae: 0.090299   val_loss: 0.011702   val_mae: 0.082008\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013842   mae: 0.090904   val_loss: 0.010561   val_mae: 0.078815\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.014088   mae: 0.091958   val_loss: 0.010545   val_mae: 0.078558\n",
      "Total:\n",
      "\t \ttime: 0h 1m 28s   loss: 0.013878   mae: 0.091167   val_loss: 0.010867   val_mae: 0.079310\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013859   mae: 0.090808   val_loss: 0.010730   val_mae: 0.078730\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013833   mae: 0.090906   val_loss: 0.010558   val_mae: 0.078565\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013932   mae: 0.091423   val_loss: 0.010164   val_mae: 0.075624\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013587   mae: 0.090192   val_loss: 0.011485   val_mae: 0.081131\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013825   mae: 0.090963   val_loss: 0.011494   val_mae: 0.081527\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013830   mae: 0.091309   val_loss: 0.010284   val_mae: 0.075602\n",
      "Total:\n",
      "\t \ttime: 0h 1m 52s   loss: 0.013811   mae: 0.090933   val_loss: 0.010786   val_mae: 0.078530\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013782   mae: 0.090678   val_loss: 0.010796   val_mae: 0.079075\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013647   mae: 0.090289   val_loss: 0.010751   val_mae: 0.078766\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013896   mae: 0.091324   val_loss: 0.010039   val_mae: 0.075188\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013463   mae: 0.089802   val_loss: 0.011456   val_mae: 0.081363\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013692   mae: 0.090540   val_loss: 0.010945   val_mae: 0.080334\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013767   mae: 0.090604   val_loss: 0.010044   val_mae: 0.075225\n",
      "Total:\n",
      "\t \ttime: 0h 2m 14s   loss: 0.013708   mae: 0.090539   val_loss: 0.010672   val_mae: 0.078325\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014742   mae: 0.094130   val_loss: 0.010951   val_mae: 0.079671\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014307   mae: 0.092509   val_loss: 0.010978   val_mae: 0.079043\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014215   mae: 0.092443   val_loss: 0.011437   val_mae: 0.081480\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013940   mae: 0.091250   val_loss: 0.011950   val_mae: 0.083494\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014154   mae: 0.092152   val_loss: 0.010901   val_mae: 0.080112\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014193   mae: 0.092478   val_loss: 0.010353   val_mae: 0.077376\n",
      "Total:\n",
      "\t \ttime: 0h 0m 34s   loss: 0.014258   mae: 0.092494   val_loss: 0.011095   val_mae: 0.080196\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014030   mae: 0.091724   val_loss: 0.011103   val_mae: 0.080907\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013879   mae: 0.091043   val_loss: 0.011012   val_mae: 0.080801\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014044   mae: 0.091917   val_loss: 0.011030   val_mae: 0.081148\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013705   mae: 0.090417   val_loss: 0.011341   val_mae: 0.080488\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014137   mae: 0.092041   val_loss: 0.011026   val_mae: 0.080425\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014108   mae: 0.092179   val_loss: 0.010211   val_mae: 0.075088\n",
      "Total:\n",
      "\t \ttime: 0h 0m 46s   loss: 0.013984   mae: 0.091553   val_loss: 0.010954   val_mae: 0.079810\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013786   mae: 0.090753   val_loss: 0.010642   val_mae: 0.078869\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013702   mae: 0.090308   val_loss: 0.011586   val_mae: 0.082282\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013815   mae: 0.091101   val_loss: 0.010317   val_mae: 0.077151\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013515   mae: 0.089926   val_loss: 0.011641   val_mae: 0.081794\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013841   mae: 0.090855   val_loss: 0.010686   val_mae: 0.079282\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013848   mae: 0.091303   val_loss: 0.010451   val_mae: 0.076577\n",
      "Total:\n",
      "\t \ttime: 0h 0m 57s   loss: 0.013751   mae: 0.090708   val_loss: 0.010887   val_mae: 0.079326\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013784   mae: 0.090922   val_loss: 0.011024   val_mae: 0.080425\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013606   mae: 0.090074   val_loss: 0.010625   val_mae: 0.079408\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013851   mae: 0.091347   val_loss: 0.010189   val_mae: 0.075861\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013400   mae: 0.089573   val_loss: 0.011638   val_mae: 0.081794\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013672   mae: 0.090435   val_loss: 0.010844   val_mae: 0.080593\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013755   mae: 0.090797   val_loss: 0.010193   val_mae: 0.076607\n",
      "Total:\n",
      "\t \ttime: 0h 1m 9s   loss: 0.013678   mae: 0.090525   val_loss: 0.010752   val_mae: 0.079115\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 96   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013617   mae: 0.090256   val_loss: 0.010707   val_mae: 0.078599\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013569   mae: 0.090200   val_loss: 0.010677   val_mae: 0.079000\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013695   mae: 0.090553   val_loss: 0.010023   val_mae: 0.075338\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013364   mae: 0.089502   val_loss: 0.011533   val_mae: 0.081280\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013616   mae: 0.090142   val_loss: 0.010740   val_mae: 0.079358\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013729   mae: 0.090903   val_loss: 0.010540   val_mae: 0.078230\n",
      "Total:\n",
      "\t \ttime: 0h 1m 23s   loss: 0.013598   mae: 0.090259   val_loss: 0.010703   val_mae: 0.078634\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.015248   mae: 0.096673   val_loss: 0.012505   val_mae: 0.087262\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.015292   mae: 0.096502   val_loss: 0.012941   val_mae: 0.088747\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.015640   mae: 0.097859   val_loss: 0.012991   val_mae: 0.088702\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014809   mae: 0.094780   val_loss: 0.012932   val_mae: 0.088646\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.015380   mae: 0.097123   val_loss: 0.012165   val_mae: 0.085762\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.015634   mae: 0.098405   val_loss: 0.012444   val_mae: 0.085814\n",
      "Total:\n",
      "\t \ttime: 0h 0m 54s   loss: 0.015334   mae: 0.096890   val_loss: 0.012663   val_mae: 0.087489\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014208   mae: 0.092695   val_loss: 0.011234   val_mae: 0.081987\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014177   mae: 0.092595   val_loss: 0.011423   val_mae: 0.083060\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014381   mae: 0.093662   val_loss: 0.010891   val_mae: 0.080564\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013786   mae: 0.091367   val_loss: 0.011939   val_mae: 0.084050\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014238   mae: 0.092826   val_loss: 0.011182   val_mae: 0.081693\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014292   mae: 0.093434   val_loss: 0.010582   val_mae: 0.078362\n",
      "Total:\n",
      "\t \ttime: 0h 1m 32s   loss: 0.014180   mae: 0.092763   val_loss: 0.011208   val_mae: 0.081619\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013862   mae: 0.091394   val_loss: 0.010736   val_mae: 0.079736\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013817   mae: 0.091098   val_loss: 0.011018   val_mae: 0.080731\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013911   mae: 0.091808   val_loss: 0.010639   val_mae: 0.079285\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013466   mae: 0.089710   val_loss: 0.011420   val_mae: 0.081271\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013816   mae: 0.091234   val_loss: 0.010965   val_mae: 0.080699\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.014033   mae: 0.092332   val_loss: 0.010248   val_mae: 0.077100\n",
      "Total:\n",
      "\t \ttime: 0h 2m 12s   loss: 0.013818   mae: 0.091262   val_loss: 0.010838   val_mae: 0.079804\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013667   mae: 0.090559   val_loss: 0.011053   val_mae: 0.080677\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013612   mae: 0.090278   val_loss: 0.010734   val_mae: 0.079743\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013655   mae: 0.090691   val_loss: 0.010316   val_mae: 0.077217\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013421   mae: 0.089631   val_loss: 0.011415   val_mae: 0.081560\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013639   mae: 0.090697   val_loss: 0.010584   val_mae: 0.078802\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013766   mae: 0.091194   val_loss: 0.010143   val_mae: 0.076279\n",
      "Total:\n",
      "\t \ttime: 0h 2m 52s   loss: 0.013627   mae: 0.090509   val_loss: 0.010708   val_mae: 0.079047\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013550   mae: 0.089993   val_loss: 0.010581   val_mae: 0.078855\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013648   mae: 0.090470   val_loss: 0.010800   val_mae: 0.079991\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013647   mae: 0.090588   val_loss: 0.010307   val_mae: 0.077089\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013412   mae: 0.089604   val_loss: 0.011471   val_mae: 0.081730\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013532   mae: 0.089902   val_loss: 0.010544   val_mae: 0.078534\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013689   mae: 0.090885   val_loss: 0.010207   val_mae: 0.076731\n",
      "Total:\n",
      "\t \ttime: 0h 3m 35s   loss: 0.013580   mae: 0.090240   val_loss: 0.010652   val_mae: 0.078822\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.016332   mae: 0.100229   val_loss: 0.013296   val_mae: 0.089861\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.016307   mae: 0.099955   val_loss: 0.014484   val_mae: 0.093894\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.016581   mae: 0.101298   val_loss: 0.013883   val_mae: 0.092753\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.016689   mae: 0.100859   val_loss: 0.015057   val_mae: 0.095255\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.016383   mae: 0.100129   val_loss: 0.013420   val_mae: 0.090437\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.016248   mae: 0.100578   val_loss: 0.012787   val_mae: 0.087699\n",
      "Total:\n",
      "\t \ttime: 0h 0m 33s   loss: 0.016423   mae: 0.100508   val_loss: 0.013821   val_mae: 0.091650\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014429   mae: 0.093630   val_loss: 0.011367   val_mae: 0.082960\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014417   mae: 0.093481   val_loss: 0.011926   val_mae: 0.085214\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014527   mae: 0.094130   val_loss: 0.011244   val_mae: 0.081943\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014284   mae: 0.093256   val_loss: 0.012495   val_mae: 0.086884\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014504   mae: 0.094077   val_loss: 0.011503   val_mae: 0.083273\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014704   mae: 0.095101   val_loss: 0.011298   val_mae: 0.081610\n",
      "Total:\n",
      "\t \ttime: 0h 0m 54s   loss: 0.014477   mae: 0.093946   val_loss: 0.011639   val_mae: 0.083647\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.014139   mae: 0.092698   val_loss: 0.011376   val_mae: 0.082262\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014035   mae: 0.092100   val_loss: 0.011355   val_mae: 0.082622\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014161   mae: 0.092855   val_loss: 0.011064   val_mae: 0.081322\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013995   mae: 0.091980   val_loss: 0.012220   val_mae: 0.085397\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014035   mae: 0.092163   val_loss: 0.011036   val_mae: 0.080747\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014197   mae: 0.093049   val_loss: 0.010572   val_mae: 0.078450\n",
      "Total:\n",
      "\t \ttime: 0h 1m 14s   loss: 0.014094   mae: 0.092474   val_loss: 0.011271   val_mae: 0.081800\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013878   mae: 0.091174   val_loss: 0.010866   val_mae: 0.080219\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013869   mae: 0.091414   val_loss: 0.011026   val_mae: 0.080939\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013858   mae: 0.091827   val_loss: 0.010775   val_mae: 0.079553\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013560   mae: 0.090318   val_loss: 0.011803   val_mae: 0.083370\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013801   mae: 0.091261   val_loss: 0.010776   val_mae: 0.079741\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013941   mae: 0.092043   val_loss: 0.010279   val_mae: 0.077199\n",
      "Total:\n",
      "\t \ttime: 0h 1m 35s   loss: 0.013818   mae: 0.091339   val_loss: 0.010921   val_mae: 0.080170\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013536   mae: 0.090099   val_loss: 0.010548   val_mae: 0.078419\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013671   mae: 0.090650   val_loss: 0.010692   val_mae: 0.079521\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013758   mae: 0.091167   val_loss: 0.010600   val_mae: 0.078887\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013398   mae: 0.089697   val_loss: 0.011653   val_mae: 0.082363\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013621   mae: 0.090483   val_loss: 0.010695   val_mae: 0.079208\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013802   mae: 0.091478   val_loss: 0.010033   val_mae: 0.076156\n",
      "Total:\n",
      "\t \ttime: 0h 1m 56s   loss: 0.013631   mae: 0.090596   val_loss: 0.010704   val_mae: 0.079092\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.019444   mae: 0.110532   val_loss: 0.016991   val_mae: 0.103630\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.017838   mae: 0.105370   val_loss: 0.016365   val_mae: 0.100274\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.018593   mae: 0.107146   val_loss: 0.016300   val_mae: 0.100156\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.018186   mae: 0.106098   val_loss: 0.016425   val_mae: 0.100193\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.019162   mae: 0.109655   val_loss: 0.016049   val_mae: 0.099913\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.018421   mae: 0.107321   val_loss: 0.015428   val_mae: 0.096099\n",
      "Total:\n",
      "\t \ttime: 0h 0m 24s   loss: 0.018607   mae: 0.107687   val_loss: 0.016260   val_mae: 0.100044\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.015426   mae: 0.096763   val_loss: 0.012768   val_mae: 0.087532\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.015262   mae: 0.096340   val_loss: 0.013231   val_mae: 0.089580\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.015772   mae: 0.098534   val_loss: 0.013248   val_mae: 0.090108\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.015420   mae: 0.096771   val_loss: 0.013780   val_mae: 0.091579\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.015764   mae: 0.098422   val_loss: 0.012700   val_mae: 0.088410\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.015446   mae: 0.097840   val_loss: 0.011838   val_mae: 0.084167\n",
      "Total:\n",
      "\t \ttime: 0h 0m 34s   loss: 0.015515   mae: 0.097445   val_loss: 0.012927   val_mae: 0.088563\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014382   mae: 0.093486   val_loss: 0.011551   val_mae: 0.083254\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014360   mae: 0.093320   val_loss: 0.012017   val_mae: 0.085899\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014791   mae: 0.095064   val_loss: 0.011747   val_mae: 0.084271\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014186   mae: 0.092851   val_loss: 0.012484   val_mae: 0.086846\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014437   mae: 0.093818   val_loss: 0.011505   val_mae: 0.083216\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014407   mae: 0.093993   val_loss: 0.010832   val_mae: 0.079664\n",
      "Total:\n",
      "\t \ttime: 0h 0m 45s   loss: 0.014427   mae: 0.093755   val_loss: 0.011689   val_mae: 0.083858\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014248   mae: 0.093000   val_loss: 0.011435   val_mae: 0.082715\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014075   mae: 0.092373   val_loss: 0.011586   val_mae: 0.083676\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014058   mae: 0.092369   val_loss: 0.010883   val_mae: 0.080562\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013995   mae: 0.092411   val_loss: 0.012377   val_mae: 0.086136\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014091   mae: 0.092443   val_loss: 0.011145   val_mae: 0.081856\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014372   mae: 0.093638   val_loss: 0.010780   val_mae: 0.079402\n",
      "Total:\n",
      "\t \ttime: 0h 0m 56s   loss: 0.014140   mae: 0.092706   val_loss: 0.011367   val_mae: 0.082391\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013979   mae: 0.091873   val_loss: 0.011052   val_mae: 0.080826\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013941   mae: 0.091524   val_loss: 0.011188   val_mae: 0.081895\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013893   mae: 0.091894   val_loss: 0.010518   val_mae: 0.078888\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013586   mae: 0.090444   val_loss: 0.011740   val_mae: 0.083433\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013889   mae: 0.091817   val_loss: 0.010904   val_mae: 0.080657\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014056   mae: 0.092320   val_loss: 0.010304   val_mae: 0.077548\n",
      "Total:\n",
      "\t \ttime: 0h 1m 8s   loss: 0.013891   mae: 0.091645   val_loss: 0.010951   val_mae: 0.080541\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014183   mae: 0.092113   val_loss: 0.010602   val_mae: 0.078923\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014227   mae: 0.092328   val_loss: 0.010679   val_mae: 0.079073\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014108   mae: 0.092227   val_loss: 0.010333   val_mae: 0.076142\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013914   mae: 0.091204   val_loss: 0.011743   val_mae: 0.082190\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014055   mae: 0.091623   val_loss: 0.010729   val_mae: 0.078935\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014273   mae: 0.092333   val_loss: 0.010187   val_mae: 0.076059\n",
      "Total:\n",
      "\t \ttime: 0h 0m 52s   loss: 0.014127   mae: 0.091971   val_loss: 0.010712   val_mae: 0.078554\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013766   mae: 0.090767   val_loss: 0.010555   val_mae: 0.077951\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013764   mae: 0.090755   val_loss: 0.010816   val_mae: 0.079078\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013852   mae: 0.091154   val_loss: 0.010290   val_mae: 0.076754\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013533   mae: 0.090022   val_loss: 0.011644   val_mae: 0.081771\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013784   mae: 0.090799   val_loss: 0.010671   val_mae: 0.078904\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013834   mae: 0.091147   val_loss: 0.009844   val_mae: 0.074761\n",
      "Total:\n",
      "\t \ttime: 0h 1m 31s   loss: 0.013756   mae: 0.090774   val_loss: 0.010637   val_mae: 0.078203\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013608   mae: 0.089907   val_loss: 0.011013   val_mae: 0.079865\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013610   mae: 0.090042   val_loss: 0.010518   val_mae: 0.077464\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013606   mae: 0.090420   val_loss: 0.010718   val_mae: 0.078427\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013375   mae: 0.089249   val_loss: 0.011639   val_mae: 0.081682\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013679   mae: 0.090520   val_loss: 0.010595   val_mae: 0.078293\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013718   mae: 0.090592   val_loss: 0.010457   val_mae: 0.077215\n",
      "Total:\n",
      "\t \ttime: 0h 2m 12s   loss: 0.013599   mae: 0.090122   val_loss: 0.010823   val_mae: 0.078824\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.013474   mae: 0.089561   val_loss: 0.010405   val_mae: 0.077542\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013397   mae: 0.089343   val_loss: 0.010924   val_mae: 0.079767\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013608   mae: 0.090449   val_loss: 0.010305   val_mae: 0.076548\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013304   mae: 0.089193   val_loss: 0.011478   val_mae: 0.081679\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013470   mae: 0.089622   val_loss: 0.010607   val_mae: 0.078164\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013649   mae: 0.090523   val_loss: 0.010000   val_mae: 0.075182\n",
      "Total:\n",
      "\t \ttime: 0h 2m 56s   loss: 0.013484   mae: 0.089782   val_loss: 0.010620   val_mae: 0.078147\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013413   mae: 0.089525   val_loss: 0.010885   val_mae: 0.079548\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013410   mae: 0.089360   val_loss: 0.010576   val_mae: 0.078344\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013425   mae: 0.089642   val_loss: 0.010465   val_mae: 0.077083\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013141   mae: 0.088591   val_loss: 0.011859   val_mae: 0.082457\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013405   mae: 0.089389   val_loss: 0.010718   val_mae: 0.079219\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013556   mae: 0.090154   val_loss: 0.010087   val_mae: 0.075983\n",
      "Total:\n",
      "\t \ttime: 0h 3m 36s   loss: 0.013392   mae: 0.089444   val_loss: 0.010765   val_mae: 0.078772\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014249   mae: 0.092349   val_loss: 0.011488   val_mae: 0.082217\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014087   mae: 0.092022   val_loss: 0.011130   val_mae: 0.080496\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014490   mae: 0.093548   val_loss: 0.010740   val_mae: 0.079092\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013930   mae: 0.091440   val_loss: 0.012068   val_mae: 0.083822\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014235   mae: 0.092098   val_loss: 0.011811   val_mae: 0.084205\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014433   mae: 0.093359   val_loss: 0.010134   val_mae: 0.076312\n",
      "Total:\n",
      "\t \ttime: 0h 0m 33s   loss: 0.014237   mae: 0.092469   val_loss: 0.011228   val_mae: 0.081024\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013721   mae: 0.090316   val_loss: 0.010543   val_mae: 0.078357\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013763   mae: 0.090628   val_loss: 0.011135   val_mae: 0.080486\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013945   mae: 0.091371   val_loss: 0.012227   val_mae: 0.084573\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013430   mae: 0.089489   val_loss: 0.011642   val_mae: 0.082029\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013870   mae: 0.091037   val_loss: 0.011001   val_mae: 0.080516\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013909   mae: 0.091561   val_loss: 0.010020   val_mae: 0.075547\n",
      "Total:\n",
      "\t \ttime: 0h 0m 53s   loss: 0.013773   mae: 0.090734   val_loss: 0.011094   val_mae: 0.080251\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013621   mae: 0.090146   val_loss: 0.010847   val_mae: 0.079684\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013705   mae: 0.090517   val_loss: 0.010582   val_mae: 0.078727\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013741   mae: 0.090740   val_loss: 0.010210   val_mae: 0.076038\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013415   mae: 0.089492   val_loss: 0.011606   val_mae: 0.082065\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013672   mae: 0.090292   val_loss: 0.010409   val_mae: 0.077600\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013697   mae: 0.090607   val_loss: 0.010005   val_mae: 0.075074\n",
      "Total:\n",
      "\t \ttime: 0h 1m 13s   loss: 0.013642   mae: 0.090299   val_loss: 0.010610   val_mae: 0.078198\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013515   mae: 0.089826   val_loss: 0.010790   val_mae: 0.079217\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013529   mae: 0.089845   val_loss: 0.010719   val_mae: 0.079208\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013636   mae: 0.090555   val_loss: 0.010011   val_mae: 0.075451\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013243   mae: 0.088778   val_loss: 0.011472   val_mae: 0.081194\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013507   mae: 0.089792   val_loss: 0.010919   val_mae: 0.079846\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013702   mae: 0.091026   val_loss: 0.009984   val_mae: 0.075125\n",
      "Total:\n",
      "\t \ttime: 0h 1m 36s   loss: 0.013522   mae: 0.089970   val_loss: 0.010649   val_mae: 0.078340\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013478   mae: 0.089585   val_loss: 0.011511   val_mae: 0.081506\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013420   mae: 0.089509   val_loss: 0.010392   val_mae: 0.077264\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013499   mae: 0.089900   val_loss: 0.010151   val_mae: 0.075796\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013184   mae: 0.088617   val_loss: 0.011530   val_mae: 0.081165\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013388   mae: 0.089438   val_loss: 0.010448   val_mae: 0.077913\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013528   mae: 0.090020   val_loss: 0.009962   val_mae: 0.075059\n",
      "Total:\n",
      "\t \ttime: 0h 1m 57s   loss: 0.013416   mae: 0.089511   val_loss: 0.010666   val_mae: 0.078117\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014202   mae: 0.092177   val_loss: 0.010637   val_mae: 0.078881\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014292   mae: 0.092887   val_loss: 0.010728   val_mae: 0.079843\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014296   mae: 0.093045   val_loss: 0.010546   val_mae: 0.077904\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.013658   mae: 0.090550   val_loss: 0.011925   val_mae: 0.082865\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.013964   mae: 0.091520   val_loss: 0.010516   val_mae: 0.078914\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014240   mae: 0.092672   val_loss: 0.010539   val_mae: 0.077651\n",
      "Total:\n",
      "\t \ttime: 0h 0m 23s   loss: 0.014109   mae: 0.092142   val_loss: 0.010815   val_mae: 0.079343\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013927   mae: 0.091493   val_loss: 0.013150   val_mae: 0.088804\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013741   mae: 0.090603   val_loss: 0.011534   val_mae: 0.082860\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013769   mae: 0.090874   val_loss: 0.010465   val_mae: 0.077510\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013504   mae: 0.089833   val_loss: 0.011481   val_mae: 0.081528\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013905   mae: 0.091388   val_loss: 0.010981   val_mae: 0.080983\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013776   mae: 0.091084   val_loss: 0.010091   val_mae: 0.075653\n",
      "Total:\n",
      "\t \ttime: 0h 0m 33s   loss: 0.013770   mae: 0.090879   val_loss: 0.011284   val_mae: 0.081223\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013608   mae: 0.090224   val_loss: 0.010816   val_mae: 0.078878\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013544   mae: 0.089996   val_loss: 0.010579   val_mae: 0.078449\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013567   mae: 0.090125   val_loss: 0.010244   val_mae: 0.076292\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013354   mae: 0.089347   val_loss: 0.011479   val_mae: 0.081057\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013751   mae: 0.090522   val_loss: 0.010254   val_mae: 0.077629\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013798   mae: 0.091011   val_loss: 0.010045   val_mae: 0.075126\n",
      "Total:\n",
      "\t \ttime: 0h 0m 45s   loss: 0.013604   mae: 0.090204   val_loss: 0.010570   val_mae: 0.077905\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013475   mae: 0.089662   val_loss: 0.010663   val_mae: 0.078468\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013536   mae: 0.089949   val_loss: 0.010429   val_mae: 0.078038\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013578   mae: 0.090267   val_loss: 0.010352   val_mae: 0.077120\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013351   mae: 0.089182   val_loss: 0.011486   val_mae: 0.080801\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013603   mae: 0.090008   val_loss: 0.010394   val_mae: 0.078002\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013668   mae: 0.090368   val_loss: 0.010210   val_mae: 0.075655\n",
      "Total:\n",
      "\t \ttime: 0h 0m 57s   loss: 0.013535   mae: 0.089906   val_loss: 0.010589   val_mae: 0.078014\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013446   mae: 0.089566   val_loss: 0.010554   val_mae: 0.077724\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013377   mae: 0.089354   val_loss: 0.010500   val_mae: 0.078007\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013532   mae: 0.090031   val_loss: 0.010090   val_mae: 0.075721\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013280   mae: 0.089024   val_loss: 0.011479   val_mae: 0.080999\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013461   mae: 0.089739   val_loss: 0.010547   val_mae: 0.078589\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013561   mae: 0.090161   val_loss: 0.009865   val_mae: 0.074367\n",
      "Total:\n",
      "\t \ttime: 0h 1m 8s   loss: 0.013443   mae: 0.089646   val_loss: 0.010506   val_mae: 0.077568\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014433   mae: 0.092922   val_loss: 0.013283   val_mae: 0.089416\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014395   mae: 0.092960   val_loss: 0.012360   val_mae: 0.085972\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014472   mae: 0.093221   val_loss: 0.011507   val_mae: 0.082609\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014301   mae: 0.092620   val_loss: 0.011972   val_mae: 0.083757\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014397   mae: 0.092909   val_loss: 0.010632   val_mae: 0.079195\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014587   mae: 0.093752   val_loss: 0.010046   val_mae: 0.075038\n",
      "Total:\n",
      "\t \ttime: 0h 0m 53s   loss: 0.014431   mae: 0.093064   val_loss: 0.011633   val_mae: 0.082665\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014039   mae: 0.091679   val_loss: 0.011631   val_mae: 0.083929\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014003   mae: 0.091470   val_loss: 0.010841   val_mae: 0.079715\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014265   mae: 0.092567   val_loss: 0.010754   val_mae: 0.078793\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013995   mae: 0.091312   val_loss: 0.011600   val_mae: 0.081236\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014118   mae: 0.091669   val_loss: 0.010943   val_mae: 0.079369\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.014228   mae: 0.092518   val_loss: 0.010229   val_mae: 0.075926\n",
      "Total:\n",
      "\t \ttime: 0h 1m 31s   loss: 0.014108   mae: 0.091869   val_loss: 0.011000   val_mae: 0.079828\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013925   mae: 0.091116   val_loss: 0.010650   val_mae: 0.078017\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013931   mae: 0.091116   val_loss: 0.010959   val_mae: 0.079316\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014002   mae: 0.091582   val_loss: 0.011820   val_mae: 0.083278\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013786   mae: 0.090592   val_loss: 0.011249   val_mae: 0.080394\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014007   mae: 0.091682   val_loss: 0.010726   val_mae: 0.078711\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.014021   mae: 0.092100   val_loss: 0.009938   val_mae: 0.074982\n",
      "Total:\n",
      "\t \ttime: 0h 2m 13s   loss: 0.013945   mae: 0.091365   val_loss: 0.010891   val_mae: 0.079117\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013964   mae: 0.091371   val_loss: 0.010471   val_mae: 0.078081\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013902   mae: 0.091195   val_loss: 0.010805   val_mae: 0.080032\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013916   mae: 0.091272   val_loss: 0.010782   val_mae: 0.079359\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013605   mae: 0.090105   val_loss: 0.011695   val_mae: 0.082862\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.013766   mae: 0.090668   val_loss: 0.010460   val_mae: 0.077537\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013999   mae: 0.091611   val_loss: 0.010259   val_mae: 0.076513\n",
      "Total:\n",
      "\t \ttime: 0h 2m 54s   loss: 0.013859   mae: 0.091037   val_loss: 0.010745   val_mae: 0.079064\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013852   mae: 0.091120   val_loss: 0.010898   val_mae: 0.079330\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013749   mae: 0.090613   val_loss: 0.010897   val_mae: 0.080239\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013836   mae: 0.091014   val_loss: 0.010373   val_mae: 0.076422\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013566   mae: 0.089811   val_loss: 0.011471   val_mae: 0.081494\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013789   mae: 0.090722   val_loss: 0.010781   val_mae: 0.078971\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013895   mae: 0.091058   val_loss: 0.010350   val_mae: 0.077523\n",
      "Total:\n",
      "\t \ttime: 0h 3m 32s   loss: 0.013781   mae: 0.090723   val_loss: 0.010795   val_mae: 0.078996\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014423   mae: 0.092801   val_loss: 0.010939   val_mae: 0.080478\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014252   mae: 0.092494   val_loss: 0.010692   val_mae: 0.079103\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014427   mae: 0.093183   val_loss: 0.011210   val_mae: 0.080854\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014042   mae: 0.091787   val_loss: 0.011524   val_mae: 0.081032\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014373   mae: 0.092811   val_loss: 0.010848   val_mae: 0.079368\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014498   mae: 0.093561   val_loss: 0.010982   val_mae: 0.078740\n",
      "Total:\n",
      "\t \ttime: 0h 0m 32s   loss: 0.014336   mae: 0.092773   val_loss: 0.011032   val_mae: 0.079929\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014082   mae: 0.091601   val_loss: 0.010842   val_mae: 0.080177\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014007   mae: 0.091518   val_loss: 0.011133   val_mae: 0.080261\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014208   mae: 0.092501   val_loss: 0.010890   val_mae: 0.079310\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013928   mae: 0.091310   val_loss: 0.011718   val_mae: 0.083044\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014089   mae: 0.091772   val_loss: 0.010742   val_mae: 0.079285\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014141   mae: 0.092233   val_loss: 0.010137   val_mae: 0.076528\n",
      "Total:\n",
      "\t \ttime: 0h 0m 52s   loss: 0.014076   mae: 0.091823   val_loss: 0.010910   val_mae: 0.079768\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013873   mae: 0.091158   val_loss: 0.010959   val_mae: 0.080636\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013880   mae: 0.091175   val_loss: 0.012257   val_mae: 0.086635\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014056   mae: 0.091902   val_loss: 0.010565   val_mae: 0.078112\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013662   mae: 0.090246   val_loss: 0.011586   val_mae: 0.081522\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013951   mae: 0.091215   val_loss: 0.010688   val_mae: 0.078830\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014069   mae: 0.091842   val_loss: 0.010178   val_mae: 0.075314\n",
      "Total:\n",
      "\t \ttime: 0h 1m 14s   loss: 0.013915   mae: 0.091256   val_loss: 0.011039   val_mae: 0.080175\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013711   mae: 0.090262   val_loss: 0.010764   val_mae: 0.078974\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013743   mae: 0.090711   val_loss: 0.011101   val_mae: 0.080352\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013778   mae: 0.090763   val_loss: 0.010063   val_mae: 0.075476\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013490   mae: 0.089624   val_loss: 0.011637   val_mae: 0.081905\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013813   mae: 0.090986   val_loss: 0.010483   val_mae: 0.078566\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013942   mae: 0.091302   val_loss: 0.010328   val_mae: 0.077406\n",
      "Total:\n",
      "\t \ttime: 0h 1m 34s   loss: 0.013746   mae: 0.090608   val_loss: 0.010730   val_mae: 0.078780\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013725   mae: 0.090400   val_loss: 0.010464   val_mae: 0.078180\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013756   mae: 0.090718   val_loss: 0.010694   val_mae: 0.079702\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013724   mae: 0.090648   val_loss: 0.010123   val_mae: 0.075656\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013378   mae: 0.089369   val_loss: 0.011429   val_mae: 0.080944\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013686   mae: 0.090484   val_loss: 0.010606   val_mae: 0.079002\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013746   mae: 0.090664   val_loss: 0.010681   val_mae: 0.077470\n",
      "Total:\n",
      "\t \ttime: 0h 1m 54s   loss: 0.013669   mae: 0.090380   val_loss: 0.010666   val_mae: 0.078492\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014220   mae: 0.092056   val_loss: 0.012395   val_mae: 0.085116\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014033   mae: 0.091696   val_loss: 0.010772   val_mae: 0.079136\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014164   mae: 0.092368   val_loss: 0.010409   val_mae: 0.076794\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.013986   mae: 0.091620   val_loss: 0.012251   val_mae: 0.084432\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014158   mae: 0.092071   val_loss: 0.010804   val_mae: 0.079517\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 3s   loss: 0.014177   mae: 0.092346   val_loss: 0.010663   val_mae: 0.078818\n",
      "Total:\n",
      "\t \ttime: 0h 0m 22s   loss: 0.014123   mae: 0.092026   val_loss: 0.011216   val_mae: 0.080636\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013850   mae: 0.090952   val_loss: 0.011112   val_mae: 0.081016\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014026   mae: 0.091554   val_loss: 0.010692   val_mae: 0.079311\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013998   mae: 0.091849   val_loss: 0.010576   val_mae: 0.077178\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013968   mae: 0.091580   val_loss: 0.011547   val_mae: 0.081110\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013977   mae: 0.091459   val_loss: 0.010331   val_mae: 0.078310\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013951   mae: 0.091431   val_loss: 0.010336   val_mae: 0.076963\n",
      "Total:\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013962   mae: 0.091471   val_loss: 0.010766   val_mae: 0.078981\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013670   mae: 0.090368   val_loss: 0.010885   val_mae: 0.080039\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013712   mae: 0.090514   val_loss: 0.010786   val_mae: 0.078560\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013829   mae: 0.091054   val_loss: 0.010612   val_mae: 0.078358\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013594   mae: 0.090483   val_loss: 0.012164   val_mae: 0.083290\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013829   mae: 0.091157   val_loss: 0.010530   val_mae: 0.078460\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013934   mae: 0.091670   val_loss: 0.010342   val_mae: 0.076521\n",
      "Total:\n",
      "\t \ttime: 0h 0m 46s   loss: 0.013761   mae: 0.090874   val_loss: 0.010886   val_mae: 0.079205\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013672   mae: 0.090267   val_loss: 0.010849   val_mae: 0.079590\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013659   mae: 0.090429   val_loss: 0.010884   val_mae: 0.079883\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013828   mae: 0.091135   val_loss: 0.010094   val_mae: 0.075314\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013396   mae: 0.089327   val_loss: 0.011618   val_mae: 0.082529\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013745   mae: 0.090332   val_loss: 0.010456   val_mae: 0.078675\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013804   mae: 0.090823   val_loss: 0.010293   val_mae: 0.077212\n",
      "Total:\n",
      "\t \ttime: 0h 0m 57s   loss: 0.013684   mae: 0.090385   val_loss: 0.010699   val_mae: 0.078867\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 2   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013634   mae: 0.090161   val_loss: 0.010642   val_mae: 0.077732\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013655   mae: 0.090354   val_loss: 0.010677   val_mae: 0.078616\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013752   mae: 0.090888   val_loss: 0.010392   val_mae: 0.077398\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013361   mae: 0.089127   val_loss: 0.011639   val_mae: 0.081719\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013656   mae: 0.090118   val_loss: 0.010626   val_mae: 0.078500\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013678   mae: 0.090812   val_loss: 0.010390   val_mae: 0.077285\n",
      "Total:\n",
      "\t \ttime: 0h 1m 7s   loss: 0.013623   mae: 0.090243   val_loss: 0.010728   val_mae: 0.078542\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014678   mae: 0.094305   val_loss: 0.011549   val_mae: 0.083357\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014972   mae: 0.095499   val_loss: 0.012832   val_mae: 0.088337\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.015077   mae: 0.096059   val_loss: 0.011886   val_mae: 0.084418\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014550   mae: 0.094097   val_loss: 0.012667   val_mae: 0.087637\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014641   mae: 0.094570   val_loss: 0.011599   val_mae: 0.083293\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014984   mae: 0.095635   val_loss: 0.011120   val_mae: 0.081077\n",
      "Total:\n",
      "\t \ttime: 0h 0m 57s   loss: 0.014817   mae: 0.095027   val_loss: 0.011942   val_mae: 0.084686\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013848   mae: 0.091459   val_loss: 0.010938   val_mae: 0.079914\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013970   mae: 0.091711   val_loss: 0.011090   val_mae: 0.081274\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013934   mae: 0.091788   val_loss: 0.010669   val_mae: 0.079407\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013580   mae: 0.090430   val_loss: 0.011865   val_mae: 0.083123\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013890   mae: 0.091617   val_loss: 0.010822   val_mae: 0.079860\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014091   mae: 0.092455   val_loss: 0.010428   val_mae: 0.078025\n",
      "Total:\n",
      "\t \ttime: 0h 1m 38s   loss: 0.013885   mae: 0.091577   val_loss: 0.010969   val_mae: 0.080267\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013750   mae: 0.090741   val_loss: 0.010679   val_mae: 0.079174\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013627   mae: 0.090146   val_loss: 0.010495   val_mae: 0.078817\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013691   mae: 0.090847   val_loss: 0.010597   val_mae: 0.077710\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013550   mae: 0.090240   val_loss: 0.011596   val_mae: 0.082311\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013602   mae: 0.090605   val_loss: 0.010651   val_mae: 0.078520\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013712   mae: 0.090860   val_loss: 0.010037   val_mae: 0.075355\n",
      "Total:\n",
      "\t \ttime: 0h 2m 19s   loss: 0.013655   mae: 0.090573   val_loss: 0.010676   val_mae: 0.078648\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.013560   mae: 0.090065   val_loss: 0.010872   val_mae: 0.079818\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013489   mae: 0.089981   val_loss: 0.010497   val_mae: 0.078295\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.013470   mae: 0.090026   val_loss: 0.010200   val_mae: 0.076014\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 33s   loss: 0.013189   mae: 0.088660   val_loss: 0.011315   val_mae: 0.080516\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013478   mae: 0.089998   val_loss: 0.010471   val_mae: 0.078315\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 29s   loss: 0.013669   mae: 0.090917   val_loss: 0.010096   val_mae: 0.075986\n",
      "Total:\n",
      "\t \ttime: 0h 3m 5s   loss: 0.013476   mae: 0.089941   val_loss: 0.010575   val_mae: 0.078157\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013381   mae: 0.089481   val_loss: 0.010340   val_mae: 0.077530\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013521   mae: 0.089939   val_loss: 0.010686   val_mae: 0.079259\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013572   mae: 0.090414   val_loss: 0.010691   val_mae: 0.078957\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013258   mae: 0.088942   val_loss: 0.011463   val_mae: 0.080984\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013444   mae: 0.089578   val_loss: 0.010442   val_mae: 0.077731\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 36s   loss: 0.013548   mae: 0.089944   val_loss: 0.009946   val_mae: 0.074886\n",
      "Total:\n",
      "\t \ttime: 0h 3m 45s   loss: 0.013454   mae: 0.089716   val_loss: 0.010595   val_mae: 0.078225\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.015062   mae: 0.095675   val_loss: 0.011708   val_mae: 0.084313\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.015618   mae: 0.097671   val_loss: 0.013476   val_mae: 0.090799\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.015690   mae: 0.097799   val_loss: 0.012842   val_mae: 0.087828\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.015939   mae: 0.098360   val_loss: 0.014026   val_mae: 0.092208\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.015639   mae: 0.097576   val_loss: 0.012909   val_mae: 0.087672\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.015712   mae: 0.098304   val_loss: 0.012365   val_mae: 0.085118\n",
      "Total:\n",
      "\t \ttime: 0h 0m 37s   loss: 0.015610   mae: 0.097564   val_loss: 0.012888   val_mae: 0.087990\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014235   mae: 0.092747   val_loss: 0.011489   val_mae: 0.082904\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014349   mae: 0.093222   val_loss: 0.011767   val_mae: 0.084215\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013840   mae: 0.091629   val_loss: 0.010522   val_mae: 0.078557\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013997   mae: 0.092155   val_loss: 0.011870   val_mae: 0.084052\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014014   mae: 0.092065   val_loss: 0.010790   val_mae: 0.080211\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014211   mae: 0.092992   val_loss: 0.010341   val_mae: 0.077289\n",
      "Total:\n",
      "\t \ttime: 0h 0m 59s   loss: 0.014107   mae: 0.092468   val_loss: 0.011130   val_mae: 0.081205\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013766   mae: 0.091046   val_loss: 0.010887   val_mae: 0.080300\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013762   mae: 0.090998   val_loss: 0.011164   val_mae: 0.081370\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013659   mae: 0.090572   val_loss: 0.010274   val_mae: 0.076786\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013450   mae: 0.089721   val_loss: 0.011640   val_mae: 0.082323\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013860   mae: 0.091479   val_loss: 0.010665   val_mae: 0.079230\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013804   mae: 0.091408   val_loss: 0.010369   val_mae: 0.077239\n",
      "Total:\n",
      "\t \ttime: 0h 1m 20s   loss: 0.013717   mae: 0.090871   val_loss: 0.010833   val_mae: 0.079541\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013552   mae: 0.090085   val_loss: 0.010554   val_mae: 0.078724\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013585   mae: 0.090188   val_loss: 0.010811   val_mae: 0.079728\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013647   mae: 0.090629   val_loss: 0.010228   val_mae: 0.076640\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013241   mae: 0.089038   val_loss: 0.011553   val_mae: 0.081815\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013542   mae: 0.090060   val_loss: 0.010505   val_mae: 0.078363\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013750   mae: 0.091059   val_loss: 0.010102   val_mae: 0.075901\n",
      "Total:\n",
      "\t \ttime: 0h 1m 41s   loss: 0.013553   mae: 0.090176   val_loss: 0.010625   val_mae: 0.078528\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013397   mae: 0.089409   val_loss: 0.010834   val_mae: 0.079154\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013425   mae: 0.089659   val_loss: 0.010575   val_mae: 0.078733\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013481   mae: 0.089881   val_loss: 0.010302   val_mae: 0.076750\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013292   mae: 0.089285   val_loss: 0.011478   val_mae: 0.081479\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013506   mae: 0.090067   val_loss: 0.010910   val_mae: 0.080058\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013636   mae: 0.090796   val_loss: 0.010242   val_mae: 0.076831\n",
      "Total:\n",
      "\t \ttime: 0h 2m 3s   loss: 0.013456   mae: 0.089849   val_loss: 0.010723   val_mae: 0.078834\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.017543   mae: 0.103969   val_loss: 0.014790   val_mae: 0.094836\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.017536   mae: 0.103291   val_loss: 0.015415   val_mae: 0.096652\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.016818   mae: 0.101685   val_loss: 0.013916   val_mae: 0.092116\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.017740   mae: 0.103912   val_loss: 0.015878   val_mae: 0.098818\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.016755   mae: 0.101838   val_loss: 0.013944   val_mae: 0.092358\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.017293   mae: 0.103187   val_loss: 0.014196   val_mae: 0.091916\n",
      "Total:\n",
      "\t \ttime: 0h 0m 28s   loss: 0.017281   mae: 0.102980   val_loss: 0.014690   val_mae: 0.094449\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.015229   mae: 0.095788   val_loss: 0.012131   val_mae: 0.085617\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014817   mae: 0.095044   val_loss: 0.012230   val_mae: 0.086469\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014686   mae: 0.094590   val_loss: 0.011675   val_mae: 0.083588\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.015039   mae: 0.095592   val_loss: 0.013532   val_mae: 0.090862\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.015329   mae: 0.096577   val_loss: 0.012317   val_mae: 0.086246\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014909   mae: 0.095870   val_loss: 0.011443   val_mae: 0.082146\n",
      "Total:\n",
      "\t \ttime: 0h 0m 38s   loss: 0.015001   mae: 0.095577   val_loss: 0.012221   val_mae: 0.085821\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013997   mae: 0.092148   val_loss: 0.011073   val_mae: 0.080776\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014231   mae: 0.092929   val_loss: 0.011481   val_mae: 0.083567\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013963   mae: 0.092206   val_loss: 0.010857   val_mae: 0.080092\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013898   mae: 0.091505   val_loss: 0.012061   val_mae: 0.084846\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014406   mae: 0.093619   val_loss: 0.011244   val_mae: 0.082155\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014271   mae: 0.093116   val_loss: 0.010551   val_mae: 0.078345\n",
      "Total:\n",
      "\t \ttime: 0h 0m 50s   loss: 0.014128   mae: 0.092587   val_loss: 0.011211   val_mae: 0.081630\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013693   mae: 0.090840   val_loss: 0.010908   val_mae: 0.079795\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013824   mae: 0.091441   val_loss: 0.011070   val_mae: 0.081247\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013649   mae: 0.090720   val_loss: 0.010259   val_mae: 0.077444\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013653   mae: 0.090608   val_loss: 0.011688   val_mae: 0.082943\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013569   mae: 0.090448   val_loss: 0.010575   val_mae: 0.079011\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013882   mae: 0.091848   val_loss: 0.010117   val_mae: 0.076577\n",
      "Total:\n",
      "\t \ttime: 0h 1m 1s   loss: 0.013712   mae: 0.090984   val_loss: 0.010769   val_mae: 0.079503\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013535   mae: 0.090028   val_loss: 0.010627   val_mae: 0.078508\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013602   mae: 0.090341   val_loss: 0.010700   val_mae: 0.079566\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013581   mae: 0.090633   val_loss: 0.010334   val_mae: 0.077438\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013385   mae: 0.089403   val_loss: 0.011585   val_mae: 0.081949\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013593   mae: 0.090498   val_loss: 0.010430   val_mae: 0.078522\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013642   mae: 0.090532   val_loss: 0.010001   val_mae: 0.075331\n",
      "Total:\n",
      "\t \ttime: 0h 1m 12s   loss: 0.013556   mae: 0.090239   val_loss: 0.010613   val_mae: 0.078552\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014149   mae: 0.091772   val_loss: 0.011081   val_mae: 0.080269\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014173   mae: 0.092474   val_loss: 0.010745   val_mae: 0.079032\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014338   mae: 0.093053   val_loss: 0.010417   val_mae: 0.076604\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013948   mae: 0.091296   val_loss: 0.012043   val_mae: 0.083742\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014062   mae: 0.091606   val_loss: 0.012021   val_mae: 0.084144\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014296   mae: 0.092856   val_loss: 0.010340   val_mae: 0.077884\n",
      "Total:\n",
      "\t \ttime: 0h 0m 58s   loss: 0.014161   mae: 0.092176   val_loss: 0.011108   val_mae: 0.080279\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013798   mae: 0.090724   val_loss: 0.010575   val_mae: 0.078310\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013748   mae: 0.090579   val_loss: 0.011265   val_mae: 0.081522\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013911   mae: 0.091229   val_loss: 0.011212   val_mae: 0.080229\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013538   mae: 0.089935   val_loss: 0.011564   val_mae: 0.081582\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013848   mae: 0.090749   val_loss: 0.010601   val_mae: 0.078213\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013969   mae: 0.091827   val_loss: 0.010144   val_mae: 0.076238\n",
      "Total:\n",
      "\t \ttime: 0h 1m 39s   loss: 0.013802   mae: 0.090840   val_loss: 0.010894   val_mae: 0.079349\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013667   mae: 0.090624   val_loss: 0.011832   val_mae: 0.083980\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013615   mae: 0.090205   val_loss: 0.010708   val_mae: 0.079763\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013736   mae: 0.090829   val_loss: 0.010267   val_mae: 0.076463\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013367   mae: 0.089156   val_loss: 0.011510   val_mae: 0.081096\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013648   mae: 0.090272   val_loss: 0.010737   val_mae: 0.079821\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013799   mae: 0.091266   val_loss: 0.010089   val_mae: 0.075375\n",
      "Total:\n",
      "\t \ttime: 0h 2m 22s   loss: 0.013639   mae: 0.090392   val_loss: 0.010857   val_mae: 0.079416\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013558   mae: 0.089757   val_loss: 0.010616   val_mae: 0.078302\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013488   mae: 0.089730   val_loss: 0.010492   val_mae: 0.077627\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013573   mae: 0.090272   val_loss: 0.010181   val_mae: 0.075548\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.013278   mae: 0.089026   val_loss: 0.011600   val_mae: 0.081324\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.013521   mae: 0.089850   val_loss: 0.010411   val_mae: 0.077422\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.013611   mae: 0.090546   val_loss: 0.010034   val_mae: 0.075348\n",
      "Total:\n",
      "\t \ttime: 0h 3m 6s   loss: 0.013505   mae: 0.089864   val_loss: 0.010556   val_mae: 0.077595\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013317   mae: 0.089127   val_loss: 0.010370   val_mae: 0.077484\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013375   mae: 0.089229   val_loss: 0.010586   val_mae: 0.078543\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013396   mae: 0.089640   val_loss: 0.010274   val_mae: 0.076316\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013121   mae: 0.088192   val_loss: 0.011273   val_mae: 0.080196\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013321   mae: 0.089180   val_loss: 0.010896   val_mae: 0.079329\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013473   mae: 0.089841   val_loss: 0.010020   val_mae: 0.075423\n",
      "Total:\n",
      "\t \ttime: 0h 3m 47s   loss: 0.013334   mae: 0.089201   val_loss: 0.010570   val_mae: 0.077882\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014076   mae: 0.091890   val_loss: 0.010801   val_mae: 0.079294\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014281   mae: 0.092366   val_loss: 0.010926   val_mae: 0.080683\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014263   mae: 0.092744   val_loss: 0.010818   val_mae: 0.079488\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013966   mae: 0.091184   val_loss: 0.011718   val_mae: 0.081918\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014102   mae: 0.091788   val_loss: 0.010604   val_mae: 0.079205\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014313   mae: 0.092757   val_loss: 0.009929   val_mae: 0.075362\n",
      "Total:\n",
      "\t \ttime: 0h 0m 37s   loss: 0.014167   mae: 0.092121   val_loss: 0.010799   val_mae: 0.079325\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013803   mae: 0.090673   val_loss: 0.010955   val_mae: 0.079389\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013730   mae: 0.090714   val_loss: 0.011801   val_mae: 0.083098\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013830   mae: 0.091247   val_loss: 0.010038   val_mae: 0.075825\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013574   mae: 0.090204   val_loss: 0.011962   val_mae: 0.082932\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013750   mae: 0.090813   val_loss: 0.010680   val_mae: 0.078770\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013996   mae: 0.091716   val_loss: 0.010400   val_mae: 0.076715\n",
      "Total:\n",
      "\t \ttime: 0h 0m 59s   loss: 0.013780   mae: 0.090894   val_loss: 0.010973   val_mae: 0.079455\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013593   mae: 0.090107   val_loss: 0.010819   val_mae: 0.079321\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013564   mae: 0.089898   val_loss: 0.010623   val_mae: 0.078634\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013670   mae: 0.090586   val_loss: 0.010074   val_mae: 0.075378\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013477   mae: 0.089611   val_loss: 0.011636   val_mae: 0.081995\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013617   mae: 0.090154   val_loss: 0.010531   val_mae: 0.078553\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013738   mae: 0.090905   val_loss: 0.010092   val_mae: 0.075588\n",
      "Total:\n",
      "\t \ttime: 0h 1m 22s   loss: 0.013610   mae: 0.090210   val_loss: 0.010629   val_mae: 0.078245\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013443   mae: 0.089358   val_loss: 0.010866   val_mae: 0.079328\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013531   mae: 0.089950   val_loss: 0.010647   val_mae: 0.078583\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013649   mae: 0.090453   val_loss: 0.010622   val_mae: 0.078172\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013221   mae: 0.088809   val_loss: 0.011427   val_mae: 0.080904\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013562   mae: 0.090056   val_loss: 0.010936   val_mae: 0.079927\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013625   mae: 0.090391   val_loss: 0.009965   val_mae: 0.075000\n",
      "Total:\n",
      "\t \ttime: 0h 1m 43s   loss: 0.013505   mae: 0.089836   val_loss: 0.010744   val_mae: 0.078652\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013391   mae: 0.089332   val_loss: 0.010462   val_mae: 0.077924\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013417   mae: 0.089452   val_loss: 0.010680   val_mae: 0.078987\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013544   mae: 0.090124   val_loss: 0.010218   val_mae: 0.076103\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013213   mae: 0.088797   val_loss: 0.011700   val_mae: 0.081569\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013434   mae: 0.089462   val_loss: 0.010418   val_mae: 0.077824\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013511   mae: 0.089961   val_loss: 0.009970   val_mae: 0.075294\n",
      "Total:\n",
      "\t \ttime: 0h 2m 3s   loss: 0.013418   mae: 0.089521   val_loss: 0.010575   val_mae: 0.077950\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014073   mae: 0.091739   val_loss: 0.010625   val_mae: 0.077965\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.013984   mae: 0.091747   val_loss: 0.011391   val_mae: 0.082435\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014155   mae: 0.092135   val_loss: 0.010642   val_mae: 0.078283\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.013816   mae: 0.090735   val_loss: 0.011857   val_mae: 0.082849\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.013935   mae: 0.091354   val_loss: 0.010356   val_mae: 0.078087\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014196   mae: 0.092314   val_loss: 0.013546   val_mae: 0.090030\n",
      "Total:\n",
      "\t \ttime: 0h 0m 27s   loss: 0.014026   mae: 0.091670   val_loss: 0.011403   val_mae: 0.081608\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013691   mae: 0.090345   val_loss: 0.011274   val_mae: 0.080479\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013761   mae: 0.090861   val_loss: 0.011982   val_mae: 0.084093\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013779   mae: 0.090931   val_loss: 0.010387   val_mae: 0.077522\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013699   mae: 0.090431   val_loss: 0.011577   val_mae: 0.081319\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013642   mae: 0.090449   val_loss: 0.010240   val_mae: 0.077772\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013842   mae: 0.091374   val_loss: 0.010379   val_mae: 0.076951\n",
      "Total:\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013736   mae: 0.090732   val_loss: 0.010973   val_mae: 0.079689\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013522   mae: 0.089807   val_loss: 0.010497   val_mae: 0.077919\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013590   mae: 0.090117   val_loss: 0.010876   val_mae: 0.080329\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013648   mae: 0.090610   val_loss: 0.010311   val_mae: 0.077023\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013384   mae: 0.089505   val_loss: 0.011731   val_mae: 0.082317\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013634   mae: 0.090301   val_loss: 0.010578   val_mae: 0.078562\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013689   mae: 0.090488   val_loss: 0.010056   val_mae: 0.075832\n",
      "Total:\n",
      "\t \ttime: 0h 0m 51s   loss: 0.013578   mae: 0.090138   val_loss: 0.010675   val_mae: 0.078664\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013601   mae: 0.090156   val_loss: 0.011364   val_mae: 0.081001\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013550   mae: 0.089902   val_loss: 0.010626   val_mae: 0.078995\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013527   mae: 0.090017   val_loss: 0.010244   val_mae: 0.075836\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013360   mae: 0.089071   val_loss: 0.011280   val_mae: 0.080451\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013545   mae: 0.089960   val_loss: 0.010365   val_mae: 0.077739\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013686   mae: 0.090510   val_loss: 0.009948   val_mae: 0.075135\n",
      "Total:\n",
      "\t \ttime: 0h 1m 2s   loss: 0.013545   mae: 0.089936   val_loss: 0.010638   val_mae: 0.078193\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013354   mae: 0.089137   val_loss: 0.010644   val_mae: 0.078441\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013278   mae: 0.088935   val_loss: 0.010458   val_mae: 0.078160\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013487   mae: 0.089958   val_loss: 0.010136   val_mae: 0.075712\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013341   mae: 0.089183   val_loss: 0.011484   val_mae: 0.080486\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013447   mae: 0.089589   val_loss: 0.010599   val_mae: 0.078464\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013516   mae: 0.090190   val_loss: 0.010029   val_mae: 0.075783\n",
      "Total:\n",
      "\t \ttime: 0h 1m 14s   loss: 0.013404   mae: 0.089499   val_loss: 0.010558   val_mae: 0.077841\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014452   mae: 0.093152   val_loss: 0.011711   val_mae: 0.085433\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014498   mae: 0.093362   val_loss: 0.011289   val_mae: 0.081272\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014540   mae: 0.093354   val_loss: 0.010891   val_mae: 0.079013\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014222   mae: 0.092221   val_loss: 0.014400   val_mae: 0.094236\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014534   mae: 0.093534   val_loss: 0.011334   val_mae: 0.081410\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014548   mae: 0.093611   val_loss: 0.010553   val_mae: 0.078697\n",
      "Total:\n",
      "\t \ttime: 0h 0m 57s   loss: 0.014466   mae: 0.093206   val_loss: 0.011696   val_mae: 0.083343\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013985   mae: 0.091627   val_loss: 0.011820   val_mae: 0.084095\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014104   mae: 0.091860   val_loss: 0.010474   val_mae: 0.077528\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014302   mae: 0.092980   val_loss: 0.010707   val_mae: 0.078323\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013855   mae: 0.090864   val_loss: 0.011807   val_mae: 0.082805\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.014135   mae: 0.092030   val_loss: 0.011270   val_mae: 0.081241\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.014216   mae: 0.092418   val_loss: 0.010172   val_mae: 0.075982\n",
      "Total:\n",
      "\t \ttime: 0h 1m 40s   loss: 0.014099   mae: 0.091963   val_loss: 0.011042   val_mae: 0.079996\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013851   mae: 0.090735   val_loss: 0.010978   val_mae: 0.080614\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013922   mae: 0.091451   val_loss: 0.011387   val_mae: 0.080198\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014226   mae: 0.092642   val_loss: 0.010801   val_mae: 0.079208\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013794   mae: 0.090923   val_loss: 0.011302   val_mae: 0.080553\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 26s   loss: 0.014045   mae: 0.091579   val_loss: 0.011340   val_mae: 0.081076\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.014151   mae: 0.092423   val_loss: 0.010260   val_mae: 0.076505\n",
      "Total:\n",
      "\t \ttime: 0h 2m 25s   loss: 0.013998   mae: 0.091625   val_loss: 0.011011   val_mae: 0.079692\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.013908   mae: 0.091197   val_loss: 0.010884   val_mae: 0.079485\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.013922   mae: 0.091312   val_loss: 0.010936   val_mae: 0.080599\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.013918   mae: 0.091308   val_loss: 0.010158   val_mae: 0.075860\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 31s   loss: 0.013613   mae: 0.090077   val_loss: 0.011649   val_mae: 0.081292\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 30s   loss: 0.013889   mae: 0.091027   val_loss: 0.011044   val_mae: 0.080224\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.014038   mae: 0.091809   val_loss: 0.010273   val_mae: 0.076433\n",
      "Total:\n",
      "\t \ttime: 0h 3m 6s   loss: 0.013881   mae: 0.091122   val_loss: 0.010824   val_mae: 0.078982\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013852   mae: 0.090970   val_loss: 0.011043   val_mae: 0.080235\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 38s   loss: 0.013821   mae: 0.090702   val_loss: 0.010700   val_mae: 0.079644\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013885   mae: 0.091293   val_loss: 0.011067   val_mae: 0.079747\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 40s   loss: 0.013622   mae: 0.090274   val_loss: 0.011840   val_mae: 0.083475\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013911   mae: 0.091491   val_loss: 0.010544   val_mae: 0.077990\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 37s   loss: 0.013874   mae: 0.091185   val_loss: 0.010214   val_mae: 0.077129\n",
      "Total:\n",
      "\t \ttime: 0h 3m 48s   loss: 0.013828   mae: 0.090986   val_loss: 0.010901   val_mae: 0.079703\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014184   mae: 0.091919   val_loss: 0.011348   val_mae: 0.082879\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014246   mae: 0.092485   val_loss: 0.011997   val_mae: 0.085594\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014321   mae: 0.092819   val_loss: 0.010576   val_mae: 0.078171\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013994   mae: 0.091458   val_loss: 0.011745   val_mae: 0.082937\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014298   mae: 0.092635   val_loss: 0.010729   val_mae: 0.079089\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014447   mae: 0.093361   val_loss: 0.011081   val_mae: 0.079220\n",
      "Total:\n",
      "\t \ttime: 0h 0m 37s   loss: 0.014248   mae: 0.092446   val_loss: 0.011246   val_mae: 0.081315\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013997   mae: 0.091290   val_loss: 0.010761   val_mae: 0.078978\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014193   mae: 0.092139   val_loss: 0.010578   val_mae: 0.078672\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014173   mae: 0.092142   val_loss: 0.010624   val_mae: 0.078061\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013984   mae: 0.091511   val_loss: 0.011842   val_mae: 0.082275\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014015   mae: 0.091441   val_loss: 0.010731   val_mae: 0.078964\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014166   mae: 0.092418   val_loss: 0.010322   val_mae: 0.075679\n",
      "Total:\n",
      "\t \ttime: 0h 0m 59s   loss: 0.014088   mae: 0.091824   val_loss: 0.010810   val_mae: 0.078772\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013896   mae: 0.090910   val_loss: 0.010675   val_mae: 0.077988\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013765   mae: 0.090917   val_loss: 0.010855   val_mae: 0.079642\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.014227   mae: 0.092643   val_loss: 0.010656   val_mae: 0.079070\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013732   mae: 0.090540   val_loss: 0.011737   val_mae: 0.082093\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013924   mae: 0.091414   val_loss: 0.010504   val_mae: 0.077962\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.014016   mae: 0.091833   val_loss: 0.010160   val_mae: 0.075492\n",
      "Total:\n",
      "\t \ttime: 0h 1m 21s   loss: 0.013927   mae: 0.091376   val_loss: 0.010765   val_mae: 0.078708\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013683   mae: 0.090430   val_loss: 0.011541   val_mae: 0.081678\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013834   mae: 0.090777   val_loss: 0.010622   val_mae: 0.078765\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013866   mae: 0.090937   val_loss: 0.010106   val_mae: 0.075903\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013495   mae: 0.089914   val_loss: 0.011496   val_mae: 0.080783\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013877   mae: 0.091135   val_loss: 0.010902   val_mae: 0.081288\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013935   mae: 0.091529   val_loss: 0.010015   val_mae: 0.074941\n",
      "Total:\n",
      "\t \ttime: 0h 1m 42s   loss: 0.013782   mae: 0.090787   val_loss: 0.010780   val_mae: 0.078893\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013699   mae: 0.090534   val_loss: 0.010668   val_mae: 0.078385\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013643   mae: 0.090257   val_loss: 0.010949   val_mae: 0.080025\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013810   mae: 0.090897   val_loss: 0.010253   val_mae: 0.076358\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013435   mae: 0.089685   val_loss: 0.011444   val_mae: 0.081024\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013916   mae: 0.091093   val_loss: 0.011021   val_mae: 0.080454\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013745   mae: 0.090719   val_loss: 0.010202   val_mae: 0.075987\n",
      "Total:\n",
      "\t \ttime: 0h 2m 4s   loss: 0.013708   mae: 0.090531   val_loss: 0.010756   val_mae: 0.078706\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014168   mae: 0.092046   val_loss: 0.013066   val_mae: 0.087216\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014126   mae: 0.091983   val_loss: 0.011023   val_mae: 0.080138\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014180   mae: 0.092389   val_loss: 0.010212   val_mae: 0.076262\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014027   mae: 0.091797   val_loss: 0.011784   val_mae: 0.083181\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014159   mae: 0.092198   val_loss: 0.010677   val_mae: 0.079547\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 4s   loss: 0.014387   mae: 0.092971   val_loss: 0.010147   val_mae: 0.076552\n",
      "Total:\n",
      "\t \ttime: 0h 0m 28s   loss: 0.014175   mae: 0.092231   val_loss: 0.011152   val_mae: 0.080483\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013835   mae: 0.091086   val_loss: 0.010917   val_mae: 0.079453\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013897   mae: 0.091311   val_loss: 0.011637   val_mae: 0.083073\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014145   mae: 0.092151   val_loss: 0.010743   val_mae: 0.078723\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013722   mae: 0.090576   val_loss: 0.011849   val_mae: 0.081927\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.013707   mae: 0.090235   val_loss: 0.011035   val_mae: 0.080779\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014073   mae: 0.092097   val_loss: 0.010978   val_mae: 0.079886\n",
      "Total:\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013896   mae: 0.091243   val_loss: 0.011193   val_mae: 0.080640\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013702   mae: 0.090519   val_loss: 0.010632   val_mae: 0.078169\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013888   mae: 0.091154   val_loss: 0.010741   val_mae: 0.079781\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013828   mae: 0.091177   val_loss: 0.010770   val_mae: 0.078987\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013675   mae: 0.090360   val_loss: 0.011818   val_mae: 0.082312\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013802   mae: 0.090930   val_loss: 0.010451   val_mae: 0.078874\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013734   mae: 0.091011   val_loss: 0.010169   val_mae: 0.075795\n",
      "Total:\n",
      "\t \ttime: 0h 0m 51s   loss: 0.013772   mae: 0.090858   val_loss: 0.010763   val_mae: 0.078986\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013734   mae: 0.090789   val_loss: 0.010760   val_mae: 0.078966\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013611   mae: 0.090185   val_loss: 0.010503   val_mae: 0.078381\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013797   mae: 0.091096   val_loss: 0.011201   val_mae: 0.081129\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013367   mae: 0.089193   val_loss: 0.011493   val_mae: 0.081194\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013687   mae: 0.090451   val_loss: 0.010344   val_mae: 0.078306\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013671   mae: 0.090504   val_loss: 0.010350   val_mae: 0.077379\n",
      "Total:\n",
      "\t \ttime: 0h 1m 2s   loss: 0.013645   mae: 0.090370   val_loss: 0.010775   val_mae: 0.079226\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 3   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013751   mae: 0.090479   val_loss: 0.011082   val_mae: 0.081123\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013531   mae: 0.089756   val_loss: 0.010514   val_mae: 0.078254\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013752   mae: 0.090906   val_loss: 0.010317   val_mae: 0.076927\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013483   mae: 0.089594   val_loss: 0.011673   val_mae: 0.081652\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013581   mae: 0.090099   val_loss: 0.010436   val_mae: 0.078398\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013767   mae: 0.090752   val_loss: 0.009930   val_mae: 0.075197\n",
      "Total:\n",
      "\t \ttime: 0h 1m 14s   loss: 0.013644   mae: 0.090264   val_loss: 0.010659   val_mae: 0.078592\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014571   mae: 0.093938   val_loss: 0.011719   val_mae: 0.084265\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014469   mae: 0.093734   val_loss: 0.012339   val_mae: 0.086332\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014727   mae: 0.094568   val_loss: 0.011336   val_mae: 0.082173\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014519   mae: 0.093898   val_loss: 0.012331   val_mae: 0.086004\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014383   mae: 0.093265   val_loss: 0.011153   val_mae: 0.081219\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014681   mae: 0.095008   val_loss: 0.010795   val_mae: 0.079747\n",
      "Total:\n",
      "\t \ttime: 0h 1m 5s   loss: 0.014558   mae: 0.094068   val_loss: 0.011612   val_mae: 0.083290\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013833   mae: 0.091172   val_loss: 0.010586   val_mae: 0.078975\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013816   mae: 0.091101   val_loss: 0.010809   val_mae: 0.079846\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013869   mae: 0.091445   val_loss: 0.010383   val_mae: 0.077214\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013745   mae: 0.091140   val_loss: 0.011847   val_mae: 0.083629\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013792   mae: 0.091135   val_loss: 0.010708   val_mae: 0.078862\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.014002   mae: 0.092059   val_loss: 0.010162   val_mae: 0.076377\n",
      "Total:\n",
      "\t \ttime: 0h 1m 53s   loss: 0.013843   mae: 0.091342   val_loss: 0.010749   val_mae: 0.079150\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 27s   loss: 0.013627   mae: 0.090439   val_loss: 0.010841   val_mae: 0.079492\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 26s   loss: 0.013663   mae: 0.090471   val_loss: 0.010732   val_mae: 0.080008\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 26s   loss: 0.013577   mae: 0.090331   val_loss: 0.010235   val_mae: 0.076457\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 25s   loss: 0.013402   mae: 0.089202   val_loss: 0.011556   val_mae: 0.081324\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 26s   loss: 0.013634   mae: 0.090480   val_loss: 0.010943   val_mae: 0.079924\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 26s   loss: 0.013663   mae: 0.090531   val_loss: 0.010120   val_mae: 0.076198\n",
      "Total:\n",
      "\t \ttime: 0h 2m 39s   loss: 0.013595   mae: 0.090242   val_loss: 0.010738   val_mae: 0.078901\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 33s   loss: 0.013523   mae: 0.089951   val_loss: 0.010660   val_mae: 0.079098\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013471   mae: 0.089774   val_loss: 0.010458   val_mae: 0.078233\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 33s   loss: 0.013613   mae: 0.090412   val_loss: 0.010348   val_mae: 0.076859\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013300   mae: 0.089379   val_loss: 0.011504   val_mae: 0.081541\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013489   mae: 0.089885   val_loss: 0.010654   val_mae: 0.079098\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013611   mae: 0.090553   val_loss: 0.009892   val_mae: 0.074948\n",
      "Total:\n",
      "\t \ttime: 0h 3m 26s   loss: 0.013501   mae: 0.089992   val_loss: 0.010586   val_mae: 0.078296\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 42s   loss: 0.013519   mae: 0.089681   val_loss: 0.010788   val_mae: 0.079412\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 41s   loss: 0.013344   mae: 0.089355   val_loss: 0.010612   val_mae: 0.078531\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 40s   loss: 0.013503   mae: 0.089894   val_loss: 0.010275   val_mae: 0.076571\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 40s   loss: 0.013174   mae: 0.088717   val_loss: 0.011416   val_mae: 0.080864\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013397   mae: 0.089581   val_loss: 0.010530   val_mae: 0.077768\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 40s   loss: 0.013577   mae: 0.090295   val_loss: 0.009906   val_mae: 0.074937\n",
      "Total:\n",
      "\t \ttime: 0h 4m 5s   loss: 0.013419   mae: 0.089587   val_loss: 0.010588   val_mae: 0.078014\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.015327   mae: 0.096332   val_loss: 0.012281   val_mae: 0.085497\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.015126   mae: 0.096240   val_loss: 0.012420   val_mae: 0.086973\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.015278   mae: 0.096826   val_loss: 0.012349   val_mae: 0.086722\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.015169   mae: 0.096209   val_loss: 0.013136   val_mae: 0.089179\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014923   mae: 0.095424   val_loss: 0.011823   val_mae: 0.084362\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.015754   mae: 0.098243   val_loss: 0.012397   val_mae: 0.085710\n",
      "Total:\n",
      "\t \ttime: 0h 0m 45s   loss: 0.015263   mae: 0.096546   val_loss: 0.012401   val_mae: 0.086407\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013911   mae: 0.091557   val_loss: 0.010954   val_mae: 0.080604\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014114   mae: 0.092528   val_loss: 0.011523   val_mae: 0.083218\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014059   mae: 0.092312   val_loss: 0.010847   val_mae: 0.080012\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013857   mae: 0.091466   val_loss: 0.011883   val_mae: 0.083726\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014147   mae: 0.092800   val_loss: 0.010804   val_mae: 0.080215\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013976   mae: 0.092143   val_loss: 0.010274   val_mae: 0.077357\n",
      "Total:\n",
      "\t \ttime: 0h 1m 7s   loss: 0.014011   mae: 0.092134   val_loss: 0.011048   val_mae: 0.080855\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013657   mae: 0.090405   val_loss: 0.010744   val_mae: 0.079427\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013536   mae: 0.090179   val_loss: 0.010732   val_mae: 0.079146\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013893   mae: 0.091709   val_loss: 0.010393   val_mae: 0.077671\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013301   mae: 0.089210   val_loss: 0.011348   val_mae: 0.080174\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013656   mae: 0.090575   val_loss: 0.010669   val_mae: 0.079110\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013719   mae: 0.090956   val_loss: 0.010076   val_mae: 0.075790\n",
      "Total:\n",
      "\t \ttime: 0h 1m 31s   loss: 0.013627   mae: 0.090506   val_loss: 0.010660   val_mae: 0.078553\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013536   mae: 0.090007   val_loss: 0.010575   val_mae: 0.078413\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013547   mae: 0.090056   val_loss: 0.010549   val_mae: 0.078556\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013584   mae: 0.090310   val_loss: 0.010310   val_mae: 0.077243\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013242   mae: 0.089034   val_loss: 0.011286   val_mae: 0.080410\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013668   mae: 0.090691   val_loss: 0.010745   val_mae: 0.079524\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013570   mae: 0.090299   val_loss: 0.010331   val_mae: 0.076763\n",
      "Total:\n",
      "\t \ttime: 0h 1m 53s   loss: 0.013525   mae: 0.090066   val_loss: 0.010633   val_mae: 0.078485\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013555   mae: 0.090056   val_loss: 0.010676   val_mae: 0.079083\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013440   mae: 0.089730   val_loss: 0.010717   val_mae: 0.079727\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013433   mae: 0.089740   val_loss: 0.010208   val_mae: 0.076136\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013154   mae: 0.088671   val_loss: 0.011413   val_mae: 0.081012\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013398   mae: 0.089407   val_loss: 0.010195   val_mae: 0.076864\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 22s   loss: 0.013528   mae: 0.090169   val_loss: 0.010021   val_mae: 0.076050\n",
      "Total:\n",
      "\t \ttime: 0h 2m 13s   loss: 0.013418   mae: 0.089629   val_loss: 0.010538   val_mae: 0.078145\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.016646   mae: 0.100728   val_loss: 0.013817   val_mae: 0.091615\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.018285   mae: 0.105767   val_loss: 0.016865   val_mae: 0.100353\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.018378   mae: 0.105732   val_loss: 0.015450   val_mae: 0.095724\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.016696   mae: 0.101001   val_loss: 0.014586   val_mae: 0.095191\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.016151   mae: 0.099616   val_loss: 0.013143   val_mae: 0.089478\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.016906   mae: 0.101524   val_loss: 0.013961   val_mae: 0.090477\n",
      "Total:\n",
      "\t \ttime: 0h 0m 34s   loss: 0.017177   mae: 0.102395   val_loss: 0.014637   val_mae: 0.093806\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014125   mae: 0.092639   val_loss: 0.011412   val_mae: 0.082690\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014427   mae: 0.093778   val_loss: 0.011967   val_mae: 0.085099\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014387   mae: 0.093561   val_loss: 0.011229   val_mae: 0.082296\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014177   mae: 0.093083   val_loss: 0.012393   val_mae: 0.087006\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014580   mae: 0.094330   val_loss: 0.011660   val_mae: 0.083630\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014598   mae: 0.094320   val_loss: 0.011003   val_mae: 0.080414\n",
      "Total:\n",
      "\t \ttime: 0h 0m 46s   loss: 0.014382   mae: 0.093619   val_loss: 0.011610   val_mae: 0.083523\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013707   mae: 0.090597   val_loss: 0.010929   val_mae: 0.080035\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014266   mae: 0.093004   val_loss: 0.011732   val_mae: 0.084606\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.014105   mae: 0.092762   val_loss: 0.010704   val_mae: 0.079347\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013468   mae: 0.089780   val_loss: 0.011576   val_mae: 0.081720\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013821   mae: 0.091311   val_loss: 0.010715   val_mae: 0.079654\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013805   mae: 0.091351   val_loss: 0.009979   val_mae: 0.075342\n",
      "Total:\n",
      "\t \ttime: 0h 0m 59s   loss: 0.013862   mae: 0.091468   val_loss: 0.010939   val_mae: 0.080117\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013574   mae: 0.090365   val_loss: 0.010953   val_mae: 0.079978\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013640   mae: 0.090546   val_loss: 0.010631   val_mae: 0.079506\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013663   mae: 0.090821   val_loss: 0.010242   val_mae: 0.076843\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013440   mae: 0.089954   val_loss: 0.011648   val_mae: 0.082344\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013576   mae: 0.090486   val_loss: 0.010505   val_mae: 0.079046\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013703   mae: 0.090997   val_loss: 0.010340   val_mae: 0.076606\n",
      "Total:\n",
      "\t \ttime: 0h 1m 11s   loss: 0.013599   mae: 0.090528   val_loss: 0.010720   val_mae: 0.079054\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.0001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013745   mae: 0.091002   val_loss: 0.010781   val_mae: 0.079369\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013493   mae: 0.089916   val_loss: 0.010643   val_mae: 0.079044\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013606   mae: 0.090444   val_loss: 0.010175   val_mae: 0.076392\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013261   mae: 0.089173   val_loss: 0.011599   val_mae: 0.081966\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013534   mae: 0.090177   val_loss: 0.010499   val_mae: 0.078546\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013640   mae: 0.090630   val_loss: 0.010096   val_mae: 0.075953\n",
      "Total:\n",
      "\t \ttime: 0h 1m 21s   loss: 0.013547   mae: 0.090224   val_loss: 0.010632   val_mae: 0.078545\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014228   mae: 0.092283   val_loss: 0.011368   val_mae: 0.081336\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014106   mae: 0.092080   val_loss: 0.010963   val_mae: 0.080097\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014173   mae: 0.092398   val_loss: 0.012114   val_mae: 0.086014\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013999   mae: 0.091518   val_loss: 0.012837   val_mae: 0.086962\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014138   mae: 0.092268   val_loss: 0.011351   val_mae: 0.081569\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.014232   mae: 0.092614   val_loss: 0.011262   val_mae: 0.080024\n",
      "Total:\n",
      "\t \ttime: 0h 1m 3s   loss: 0.014146   mae: 0.092194   val_loss: 0.011649   val_mae: 0.082667\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013843   mae: 0.090831   val_loss: 0.010519   val_mae: 0.078972\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013777   mae: 0.090669   val_loss: 0.011215   val_mae: 0.081239\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013815   mae: 0.091166   val_loss: 0.010345   val_mae: 0.077610\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013630   mae: 0.090017   val_loss: 0.011810   val_mae: 0.082750\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 17s   loss: 0.013866   mae: 0.091099   val_loss: 0.010849   val_mae: 0.079168\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013953   mae: 0.091577   val_loss: 0.010293   val_mae: 0.076448\n",
      "Total:\n",
      "\t \ttime: 0h 1m 50s   loss: 0.013814   mae: 0.090893   val_loss: 0.010838   val_mae: 0.079364\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 26s   loss: 0.013614   mae: 0.090107   val_loss: 0.010700   val_mae: 0.079003\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 25s   loss: 0.013589   mae: 0.090125   val_loss: 0.010820   val_mae: 0.079553\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 25s   loss: 0.013768   mae: 0.090865   val_loss: 0.010321   val_mae: 0.076930\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 26s   loss: 0.013521   mae: 0.089862   val_loss: 0.011623   val_mae: 0.081357\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 25s   loss: 0.013652   mae: 0.090554   val_loss: 0.010712   val_mae: 0.079106\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 25s   loss: 0.013777   mae: 0.090975   val_loss: 0.010397   val_mae: 0.077138\n",
      "Total:\n",
      "\t \ttime: 0h 2m 35s   loss: 0.013654   mae: 0.090415   val_loss: 0.010762   val_mae: 0.078848\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013573   mae: 0.090045   val_loss: 0.010529   val_mae: 0.078274\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013510   mae: 0.089868   val_loss: 0.010542   val_mae: 0.078023\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013585   mae: 0.090128   val_loss: 0.010373   val_mae: 0.076653\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 32s   loss: 0.013290   mae: 0.089212   val_loss: 0.011746   val_mae: 0.082225\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013478   mae: 0.089710   val_loss: 0.010443   val_mae: 0.077573\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.013572   mae: 0.090214   val_loss: 0.010167   val_mae: 0.075973\n",
      "Total:\n",
      "\t \ttime: 0h 3m 19s   loss: 0.013501   mae: 0.089863   val_loss: 0.010633   val_mae: 0.078120\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 41s   loss: 0.013463   mae: 0.089628   val_loss: 0.010392   val_mae: 0.077689\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 40s   loss: 0.013330   mae: 0.089222   val_loss: 0.010858   val_mae: 0.080297\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 40s   loss: 0.013430   mae: 0.089789   val_loss: 0.010066   val_mae: 0.075526\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 39s   loss: 0.013165   mae: 0.088739   val_loss: 0.011524   val_mae: 0.081478\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 41s   loss: 0.013402   mae: 0.089543   val_loss: 0.010648   val_mae: 0.078521\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 40s   loss: 0.013536   mae: 0.090170   val_loss: 0.009930   val_mae: 0.075146\n",
      "Total:\n",
      "\t \ttime: 0h 4m 4s   loss: 0.013388   mae: 0.089515   val_loss: 0.010570   val_mae: 0.078109\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014063   mae: 0.091406   val_loss: 0.011145   val_mae: 0.081219\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014104   mae: 0.092213   val_loss: 0.011160   val_mae: 0.080541\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014175   mae: 0.092274   val_loss: 0.010341   val_mae: 0.076592\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013842   mae: 0.091006   val_loss: 0.011599   val_mae: 0.082005\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014196   mae: 0.092301   val_loss: 0.011236   val_mae: 0.080964\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014257   mae: 0.092726   val_loss: 0.009954   val_mae: 0.075443\n",
      "Total:\n",
      "\t \ttime: 0h 0m 45s   loss: 0.014106   mae: 0.091988   val_loss: 0.010906   val_mae: 0.079461\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013770   mae: 0.090545   val_loss: 0.010865   val_mae: 0.079359\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013752   mae: 0.090838   val_loss: 0.010772   val_mae: 0.079836\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013828   mae: 0.091133   val_loss: 0.010400   val_mae: 0.076939\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013615   mae: 0.090216   val_loss: 0.011626   val_mae: 0.082046\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013833   mae: 0.090961   val_loss: 0.010655   val_mae: 0.079546\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013834   mae: 0.091100   val_loss: 0.010227   val_mae: 0.076523\n",
      "Total:\n",
      "\t \ttime: 0h 1m 9s   loss: 0.013772   mae: 0.090799   val_loss: 0.010758   val_mae: 0.079041\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013582   mae: 0.090097   val_loss: 0.010619   val_mae: 0.078893\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013606   mae: 0.090223   val_loss: 0.010777   val_mae: 0.079735\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013668   mae: 0.090579   val_loss: 0.010412   val_mae: 0.077153\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013394   mae: 0.089458   val_loss: 0.011570   val_mae: 0.080970\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013630   mae: 0.090301   val_loss: 0.010571   val_mae: 0.078371\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013739   mae: 0.090773   val_loss: 0.010471   val_mae: 0.077027\n",
      "Total:\n",
      "\t \ttime: 0h 1m 35s   loss: 0.013603   mae: 0.090238   val_loss: 0.010737   val_mae: 0.078692\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013516   mae: 0.089652   val_loss: 0.010568   val_mae: 0.078398\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013541   mae: 0.089852   val_loss: 0.010695   val_mae: 0.078747\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 18s   loss: 0.013631   mae: 0.090509   val_loss: 0.010216   val_mae: 0.076305\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013360   mae: 0.089236   val_loss: 0.011743   val_mae: 0.082604\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013407   mae: 0.089552   val_loss: 0.010429   val_mae: 0.078171\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013578   mae: 0.090177   val_loss: 0.010084   val_mae: 0.075269\n",
      "Total:\n",
      "\t \ttime: 0h 1m 58s   loss: 0.013506   mae: 0.089830   val_loss: 0.010623   val_mae: 0.078249\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013443   mae: 0.089366   val_loss: 0.010496   val_mae: 0.077957\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013450   mae: 0.089597   val_loss: 0.010561   val_mae: 0.078783\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013490   mae: 0.089903   val_loss: 0.010094   val_mae: 0.075824\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 25s   loss: 0.013177   mae: 0.088683   val_loss: 0.011680   val_mae: 0.082082\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013367   mae: 0.089395   val_loss: 0.010454   val_mae: 0.077829\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013662   mae: 0.090445   val_loss: 0.010713   val_mae: 0.079028\n",
      "Total:\n",
      "\t \ttime: 0h 2m 24s   loss: 0.013431   mae: 0.089565   val_loss: 0.010666   val_mae: 0.078584\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014277   mae: 0.092425   val_loss: 0.010637   val_mae: 0.078953\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014016   mae: 0.091732   val_loss: 0.010724   val_mae: 0.079231\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014080   mae: 0.092266   val_loss: 0.010523   val_mae: 0.078106\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.013918   mae: 0.091192   val_loss: 0.012156   val_mae: 0.084876\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014451   mae: 0.093097   val_loss: 0.010914   val_mae: 0.080001\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014219   mae: 0.092490   val_loss: 0.010158   val_mae: 0.075391\n",
      "Total:\n",
      "\t \ttime: 0h 0m 36s   loss: 0.014160   mae: 0.092200   val_loss: 0.010852   val_mae: 0.079426\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013607   mae: 0.090232   val_loss: 0.010705   val_mae: 0.078796\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013599   mae: 0.090082   val_loss: 0.011760   val_mae: 0.083882\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013866   mae: 0.091129   val_loss: 0.010432   val_mae: 0.076497\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013521   mae: 0.090183   val_loss: 0.011881   val_mae: 0.082433\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013695   mae: 0.090736   val_loss: 0.010266   val_mae: 0.077566\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013988   mae: 0.091803   val_loss: 0.010370   val_mae: 0.077215\n",
      "Total:\n",
      "\t \ttime: 0h 0m 48s   loss: 0.013713   mae: 0.090694   val_loss: 0.010902   val_mae: 0.079398\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013631   mae: 0.090254   val_loss: 0.010619   val_mae: 0.078274\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013560   mae: 0.089808   val_loss: 0.010748   val_mae: 0.079606\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013684   mae: 0.090290   val_loss: 0.010906   val_mae: 0.079690\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013417   mae: 0.089388   val_loss: 0.012235   val_mae: 0.084628\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013606   mae: 0.090134   val_loss: 0.010382   val_mae: 0.078031\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013693   mae: 0.090725   val_loss: 0.010047   val_mae: 0.075332\n",
      "Total:\n",
      "\t \ttime: 0h 1m 0s   loss: 0.013598   mae: 0.090100   val_loss: 0.010823   val_mae: 0.079260\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013402   mae: 0.089345   val_loss: 0.010592   val_mae: 0.077777\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013429   mae: 0.089586   val_loss: 0.010600   val_mae: 0.079311\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013554   mae: 0.090314   val_loss: 0.010212   val_mae: 0.076012\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013253   mae: 0.088784   val_loss: 0.011429   val_mae: 0.080807\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013449   mae: 0.089853   val_loss: 0.010387   val_mae: 0.077723\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013566   mae: 0.090383   val_loss: 0.009965   val_mae: 0.074856\n",
      "Total:\n",
      "\t \ttime: 0h 1m 14s   loss: 0.013442   mae: 0.089711   val_loss: 0.010531   val_mae: 0.077748\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.001   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013520   mae: 0.089882   val_loss: 0.010665   val_mae: 0.078788\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013369   mae: 0.089288   val_loss: 0.010928   val_mae: 0.080245\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013559   mae: 0.090128   val_loss: 0.010119   val_mae: 0.075828\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013105   mae: 0.088392   val_loss: 0.011564   val_mae: 0.081378\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013468   mae: 0.089766   val_loss: 0.010485   val_mae: 0.078550\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013545   mae: 0.090174   val_loss: 0.010122   val_mae: 0.075606\n",
      "Total:\n",
      "\t \ttime: 0h 1m 26s   loss: 0.013428   mae: 0.089605   val_loss: 0.010647   val_mae: 0.078399\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014338   mae: 0.092936   val_loss: 0.011175   val_mae: 0.080557\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014403   mae: 0.093092   val_loss: 0.010483   val_mae: 0.078034\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014403   mae: 0.093127   val_loss: 0.011018   val_mae: 0.080415\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014217   mae: 0.092354   val_loss: 0.012241   val_mae: 0.084946\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014400   mae: 0.092913   val_loss: 0.010986   val_mae: 0.080472\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014557   mae: 0.093963   val_loss: 0.011002   val_mae: 0.080587\n",
      "Total:\n",
      "\t \ttime: 0h 1m 8s   loss: 0.014386   mae: 0.093064   val_loss: 0.011151   val_mae: 0.080835\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.014237   mae: 0.092416   val_loss: 0.011544   val_mae: 0.082537\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.014253   mae: 0.092585   val_loss: 0.010794   val_mae: 0.078903\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.014254   mae: 0.092426   val_loss: 0.010662   val_mae: 0.077129\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.013927   mae: 0.091254   val_loss: 0.013636   val_mae: 0.091212\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.014080   mae: 0.091846   val_loss: 0.011376   val_mae: 0.081372\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 19s   loss: 0.014259   mae: 0.092700   val_loss: 0.010830   val_mae: 0.077893\n",
      "Total:\n",
      "\t \ttime: 0h 1m 58s   loss: 0.014168   mae: 0.092205   val_loss: 0.011474   val_mae: 0.081508\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 28s   loss: 0.014136   mae: 0.091899   val_loss: 0.011071   val_mae: 0.081143\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 27s   loss: 0.014032   mae: 0.091524   val_loss: 0.010899   val_mae: 0.079628\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 26s   loss: 0.014129   mae: 0.092015   val_loss: 0.010726   val_mae: 0.080085\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 27s   loss: 0.013833   mae: 0.090877   val_loss: 0.011544   val_mae: 0.081324\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 26s   loss: 0.013966   mae: 0.091438   val_loss: 0.010468   val_mae: 0.077417\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 26s   loss: 0.014160   mae: 0.092242   val_loss: 0.010002   val_mae: 0.075105\n",
      "Total:\n",
      "\t \ttime: 0h 2m 43s   loss: 0.014043   mae: 0.091666   val_loss: 0.010785   val_mae: 0.079117\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 35s   loss: 0.013861   mae: 0.091136   val_loss: 0.011082   val_mae: 0.082338\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 34s   loss: 0.014014   mae: 0.091633   val_loss: 0.010893   val_mae: 0.079478\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 33s   loss: 0.013995   mae: 0.091741   val_loss: 0.010211   val_mae: 0.075660\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 33s   loss: 0.013785   mae: 0.090684   val_loss: 0.012148   val_mae: 0.084140\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 33s   loss: 0.013794   mae: 0.090841   val_loss: 0.011374   val_mae: 0.081034\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 33s   loss: 0.014028   mae: 0.091822   val_loss: 0.009972   val_mae: 0.075430\n",
      "Total:\n",
      "\t \ttime: 0h 3m 24s   loss: 0.013913   mae: 0.091309   val_loss: 0.010947   val_mae: 0.079680\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 16   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 42s   loss: 0.013891   mae: 0.090964   val_loss: 0.011555   val_mae: 0.082210\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 41s   loss: 0.013785   mae: 0.090943   val_loss: 0.011126   val_mae: 0.080254\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 41s   loss: 0.014059   mae: 0.091994   val_loss: 0.010284   val_mae: 0.076049\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 40s   loss: 0.013625   mae: 0.089998   val_loss: 0.012688   val_mae: 0.085652\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 40s   loss: 0.013729   mae: 0.090483   val_loss: 0.010792   val_mae: 0.080050\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 40s   loss: 0.013979   mae: 0.091670   val_loss: 0.010172   val_mae: 0.075850\n",
      "Total:\n",
      "\t \ttime: 0h 4m 6s   loss: 0.013845   mae: 0.091009   val_loss: 0.011103   val_mae: 0.080011\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014193   mae: 0.092446   val_loss: 0.010909   val_mae: 0.079970\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014218   mae: 0.092575   val_loss: 0.011633   val_mae: 0.083946\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014270   mae: 0.092759   val_loss: 0.011098   val_mae: 0.080716\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014121   mae: 0.092113   val_loss: 0.011819   val_mae: 0.082417\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014185   mae: 0.092394   val_loss: 0.011770   val_mae: 0.083003\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.014538   mae: 0.093738   val_loss: 0.010683   val_mae: 0.079113\n",
      "Total:\n",
      "\t \ttime: 0h 0m 45s   loss: 0.014254   mae: 0.092671   val_loss: 0.011319   val_mae: 0.081528\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013951   mae: 0.091431   val_loss: 0.010504   val_mae: 0.077582\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013939   mae: 0.091461   val_loss: 0.010895   val_mae: 0.079082\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014064   mae: 0.091932   val_loss: 0.010272   val_mae: 0.076838\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.013736   mae: 0.090646   val_loss: 0.011578   val_mae: 0.081849\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.014010   mae: 0.091735   val_loss: 0.011359   val_mae: 0.081147\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 11s   loss: 0.014179   mae: 0.092642   val_loss: 0.010075   val_mae: 0.075894\n",
      "Total:\n",
      "\t \ttime: 0h 1m 11s   loss: 0.013980   mae: 0.091641   val_loss: 0.010780   val_mae: 0.078732\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013908   mae: 0.091273   val_loss: 0.011140   val_mae: 0.081831\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013860   mae: 0.091194   val_loss: 0.011034   val_mae: 0.079899\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013973   mae: 0.091728   val_loss: 0.010623   val_mae: 0.077456\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013673   mae: 0.090503   val_loss: 0.011536   val_mae: 0.081678\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013837   mae: 0.091132   val_loss: 0.010552   val_mae: 0.078857\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 16s   loss: 0.013960   mae: 0.091553   val_loss: 0.010906   val_mae: 0.078348\n",
      "Total:\n",
      "\t \ttime: 0h 1m 37s   loss: 0.013869   mae: 0.091230   val_loss: 0.010965   val_mae: 0.079678\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013855   mae: 0.091005   val_loss: 0.010916   val_mae: 0.080991\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013803   mae: 0.090705   val_loss: 0.011058   val_mae: 0.080694\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.014028   mae: 0.091606   val_loss: 0.010540   val_mae: 0.078238\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.013494   mae: 0.089829   val_loss: 0.011583   val_mae: 0.081889\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 20s   loss: 0.013766   mae: 0.090778   val_loss: 0.010588   val_mae: 0.078843\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 21s   loss: 0.014005   mae: 0.091898   val_loss: 0.010954   val_mae: 0.079371\n",
      "Total:\n",
      "\t \ttime: 0h 2m 7s   loss: 0.013825   mae: 0.090970   val_loss: 0.010940   val_mae: 0.080005\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 32   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013695   mae: 0.090472   val_loss: 0.010531   val_mae: 0.077762\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 23s   loss: 0.013767   mae: 0.090660   val_loss: 0.012098   val_mae: 0.083829\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013774   mae: 0.090974   val_loss: 0.010127   val_mae: 0.075481\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013597   mae: 0.089865   val_loss: 0.011558   val_mae: 0.081539\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 24s   loss: 0.013724   mae: 0.090622   val_loss: 0.010838   val_mae: 0.079361\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 25s   loss: 0.013804   mae: 0.091277   val_loss: 0.010094   val_mae: 0.076531\n",
      "Total:\n",
      "\t \ttime: 0h 2m 26s   loss: 0.013727   mae: 0.090645   val_loss: 0.010874   val_mae: 0.079084\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 5   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014132   mae: 0.092123   val_loss: 0.010737   val_mae: 0.078749\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014022   mae: 0.091800   val_loss: 0.010772   val_mae: 0.079665\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014358   mae: 0.093062   val_loss: 0.010523   val_mae: 0.077867\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014086   mae: 0.091665   val_loss: 0.011898   val_mae: 0.083166\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 5s   loss: 0.014176   mae: 0.092238   val_loss: 0.010714   val_mae: 0.078930\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 6s   loss: 0.014158   mae: 0.092549   val_loss: 0.009996   val_mae: 0.075073\n",
      "Total:\n",
      "\t \ttime: 0h 0m 37s   loss: 0.014155   mae: 0.092239   val_loss: 0.010774   val_mae: 0.078908\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 10   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013888   mae: 0.091086   val_loss: 0.011134   val_mae: 0.080043\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013965   mae: 0.091501   val_loss: 0.010655   val_mae: 0.079384\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.014039   mae: 0.091989   val_loss: 0.010504   val_mae: 0.077160\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 8s   loss: 0.013781   mae: 0.090752   val_loss: 0.011519   val_mae: 0.080876\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 7s   loss: 0.013856   mae: 0.091001   val_loss: 0.011092   val_mae: 0.080714\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013886   mae: 0.091283   val_loss: 0.010113   val_mae: 0.075386\n",
      "Total:\n",
      "\t \ttime: 0h 0m 49s   loss: 0.013902   mae: 0.091269   val_loss: 0.010836   val_mae: 0.078927\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 15   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013879   mae: 0.091204   val_loss: 0.010860   val_mae: 0.079564\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013782   mae: 0.090807   val_loss: 0.011170   val_mae: 0.081243\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013937   mae: 0.091684   val_loss: 0.010669   val_mae: 0.078092\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 9s   loss: 0.013607   mae: 0.090167   val_loss: 0.012237   val_mae: 0.084470\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013900   mae: 0.091435   val_loss: 0.010632   val_mae: 0.079390\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 10s   loss: 0.013883   mae: 0.091359   val_loss: 0.010353   val_mae: 0.075870\n",
      "Total:\n",
      "\t \ttime: 0h 1m 2s   loss: 0.013831   mae: 0.091109   val_loss: 0.010987   val_mae: 0.079771\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 20   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013792   mae: 0.090938   val_loss: 0.010609   val_mae: 0.078049\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013653   mae: 0.090474   val_loss: 0.010676   val_mae: 0.079628\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013762   mae: 0.090966   val_loss: 0.010819   val_mae: 0.077948\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013502   mae: 0.090004   val_loss: 0.011587   val_mae: 0.081627\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 13s   loss: 0.013776   mae: 0.090606   val_loss: 0.010432   val_mae: 0.077967\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 12s   loss: 0.013708   mae: 0.090825   val_loss: 0.010231   val_mae: 0.076990\n",
      "Total:\n",
      "\t \ttime: 0h 1m 16s   loss: 0.013699   mae: 0.090635   val_loss: 0.010726   val_mae: 0.078701\n",
      "Hyperparameters:\n",
      "\t input_dim: 10   neurons: 128   deep: 4   optimizer: Adam   learning_rate: 0.01   activation: relu   initializer: uniform   batch_size: 64   epochs: 25   batch_normalization: False   regularization: None   dropout: False   regularization_factor: 0.0   dropout_rate: 0.0\n",
      "Fold 1/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013642   mae: 0.090167   val_loss: 0.011236   val_mae: 0.080451\n",
      "Fold 2/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013650   mae: 0.090405   val_loss: 0.011450   val_mae: 0.081668\n",
      "Fold 3/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013783   mae: 0.090909   val_loss: 0.010035   val_mae: 0.075886\n",
      "Fold 4/6 ...\n",
      "\t \ttime: 0h 0m 14s   loss: 0.013528   mae: 0.089848   val_loss: 0.011335   val_mae: 0.080088\n",
      "Fold 5/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013499   mae: 0.089814   val_loss: 0.010419   val_mae: 0.078413\n",
      "Fold 6/6 ...\n",
      "\t \ttime: 0h 0m 15s   loss: 0.013683   mae: 0.090798   val_loss: 0.010294   val_mae: 0.077010\n",
      "Total:\n",
      "\t \ttime: 0h 1m 28s   loss: 0.013631   mae: 0.090324   val_loss: 0.010795   val_mae: 0.078919\n"
     ]
    }
   ],
   "source": [
    "data = load_object('data/covid/classification/datasets/graves_train-1.1.pkl')\n",
    "\n",
    "\n",
    "foldify = Foldify(len(data['x']),\n",
    "                  nfolds=6,\n",
    "                  val_prop=0.2,\n",
    "                  ftype='random',\n",
    "                  sorted=True,\n",
    "                  seed=555,\n",
    "                  weight=data['sample'],\n",
    "                  label=data['label'],\n",
    "                  datasets=(data['x'], data['y']))\n",
    "\n",
    "memory = Memory(load_object(\n",
    "    'data/covid/classification/gridsearch/memory_graves-1.0.pkl'))\n",
    "\n",
    "output_file = 'data/covid/classification/gridsearch/output.pkl'\n",
    "origin = 'dell inspiron'\n",
    "\n",
    "grid = make_grid(hparams=dict(input_dim=10,\n",
    "                              neurons=[16, 32, 64, 96, 128],\n",
    "                              deep=[2, 3, 4],\n",
    "                              optimizer='Adam',\n",
    "                              learning_rate=[0.0001, 0.001, 0.01],\n",
    "                              activation='relu',\n",
    "                              initializer='uniform',\n",
    "                              batch_size=[16, 32, 64],\n",
    "                              epochs=[5, 10, 15, 20, 25],\n",
    "                              batch_normalization=False,\n",
    "                              regularization='None',\n",
    "                              dropout=False),\n",
    "                 validation=validate_classification_model_hparams)\n",
    "\n",
    "for hparam in grid:\n",
    "    eval_model(model=classification_model,\n",
    "               hparam=hparam,\n",
    "               foldify=foldify,\n",
    "               memory=memory,\n",
    "               output_file=output_file,\n",
    "               origin=origin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "col = 'learning_rate'\n",
    "groups = memory.groups(col, 'val_mae')\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "for subdata in groups.subdata:\n",
    "    plt.plot(subdata[col], subdata['val_mae'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = dict(input_dim=10,\n",
    "               neurons=[16, 32, 64],\n",
    "               deep=[2, 3, 4],\n",
    "               optimizer=['Adam', 'RMSprop', 'Nadam', 'SGD'],\n",
    "               learning_rate=[0.0001, 0.001, 0.01],\n",
    "               activation=['relu', 'elu', 'LeakyReLU'],\n",
    "               initializer=['uniform', 'normal'],\n",
    "               batch_size=[16, 32, 64],\n",
    "               epochs=[5, 10, 15],\n",
    "               batch_normalization=[False, True],\n",
    "               regularization=['None', 'l1', 'l2'],\n",
    "               regularization_factor=[0.001, 0.01, 0.1],\n",
    "               dropout=[False, True],\n",
    "               dropout_rate=[0.1, 0.3, 0.5])\n",
    "\n",
    "hparams = dict(input_dim=10,\n",
    "               neurons=[16, 32, 64, 96],\n",
    "               deep=[2, 3, 4],\n",
    "               optimizer=['Adam', 'RMSprop', 'Nadam', 'SGD'],\n",
    "               learning_rate=[0.0001, 0.001, 0.01],\n",
    "               activation=['relu', 'elu', 'LeakyReLU'],\n",
    "               initializer=['uniform', 'normal'],\n",
    "               batch_size=[16, 32, 64],\n",
    "               epochs=[5, 10, 15, 20],\n",
    "               batch_normalization=False,\n",
    "               regularization='None',\n",
    "               dropout=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
